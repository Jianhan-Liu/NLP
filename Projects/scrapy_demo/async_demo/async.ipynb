{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Reference1](https://zhuanlan.zhihu.com/p/25228075)\n",
    "- [Reference2](https://zhuanlan.zhihu.com/p/27258289)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 肖申克的救赎\n",
      "2 霸王别姬\n",
      "3 阿甘正传\n",
      "4 这个杀手不太冷\n",
      "5 美丽人生\n",
      "6 泰坦尼克号\n",
      "7 千与千寻\n",
      "8 辛德勒的名单\n",
      "9 盗梦空间\n",
      "10 忠犬八公的故事\n",
      "11 机器人总动员\n",
      "12 三傻大闹宝莱坞\n",
      "13 放牛班的春天\n",
      "14 楚门的世界\n",
      "15 海上钢琴师\n",
      "16 星际穿越\n",
      "17 大话西游之大圣娶亲\n",
      "18 龙猫\n",
      "19 熔炉\n",
      "20 无间道\n",
      "21 教父\n",
      "22 疯狂动物城\n",
      "23 当幸福来敲门\n",
      "24 怦然心动\n",
      "25 触不可及\n",
      "26 蝙蝠侠：黑暗骑士\n",
      "27 活着\n",
      "28 控方证人\n",
      "29 乱世佳人\n",
      "30 少年派的奇幻漂流\n",
      "31 摔跤吧！爸爸\n",
      "32 指环王3：王者无敌\n",
      "33 飞屋环游记\n",
      "34 鬼子来了\n",
      "35 十二怒汉\n",
      "36 天空之城\n",
      "37 天堂电影院\n",
      "38 寻梦环游记\n",
      "39 大话西游之月光宝盒\n",
      "40 末代皇帝\n",
      "41 哈尔的移动城堡\n",
      "42 罗马假日\n",
      "43 搏击俱乐部\n",
      "44 闻香识女人\n",
      "45 素媛\n",
      "46 辩护人\n",
      "47 窃听风暴\n",
      "48 何以为家\n",
      "49 死亡诗社\n",
      "50 两杆大烟枪\n",
      "51 教父2\n",
      "52 指环王2：双塔奇兵\n",
      "53 飞越疯人院\n",
      "54 狮子王\n",
      "55 指环王1：魔戒再现\n",
      "56 V字仇杀队\n",
      "57 美丽心灵\n",
      "58 饮食男女\n",
      "59 大闹天宫\n",
      "60 哈利·波特与魔法石\n",
      "61 海豚湾\n",
      "62 钢琴家\n",
      "63 本杰明·巴顿奇事\n",
      "64 情书\n",
      "65 黑客帝国\n",
      "66 看不见的客人\n",
      "67 让子弹飞\n",
      "68 西西里的美丽传说\n",
      "69 小鞋子\n",
      "70 拯救大兵瑞恩\n",
      "71 猫鼠游戏\n",
      "72 美国往事\n",
      "73 音乐之声\n",
      "74 我不是药神\n",
      "75 致命魔术\n",
      "76 七宗罪\n",
      "77 低俗小说\n",
      "78 被嫌弃的松子的一生\n",
      "79 穿条纹睡衣的男孩\n",
      "80 沉默的羔羊\n",
      "81 蝴蝶效应\n",
      "82 春光乍泄\n",
      "83 心灵捕手\n",
      "84 禁闭岛\n",
      "85 勇敢的心\n",
      "86 天使爱美丽\n",
      "87 剪刀手爱德华\n",
      "88 布达佩斯大饭店\n",
      "89 阿凡达\n",
      "90 摩登时代\n",
      "91 加勒比海盗\n",
      "92 幽灵公主\n",
      "93 入殓师\n",
      "94 致命ID\n",
      "95 断背山\n",
      "96 阳光灿烂的日子\n",
      "97 喜剧之王\n",
      "98 重庆森林\n",
      "99 第六感\n",
      "100 狩猎\n",
      "101 玛丽和马克思\n",
      "102 海蒂和爷爷\n",
      "103 杀人回忆\n",
      "104 消失的爱人\n",
      "105 小森林 夏秋篇\n",
      "106 告白\n",
      "107 请以你的名字呼唤我\n",
      "108 大鱼\n",
      "109 一一\n",
      "110 爱在黎明破晓前\n",
      "111 阳光姐妹淘\n",
      "112 红辣椒\n",
      "113 侧耳倾听\n",
      "114 射雕英雄传之东成西就\n",
      "115 甜蜜蜜\n",
      "116 7号房的礼物\n",
      "117 倩女幽魂\n",
      "118 超脱\n",
      "119 哈利·波特与死亡圣器(下)\n",
      "120 驯龙高手\n",
      "121 小森林 冬春篇\n",
      "122 蝙蝠侠：黑暗骑士崛起\n",
      "123 菊次郎的夏天\n",
      "124 恐怖直播\n",
      "125 爱在日落黄昏时\n",
      "126 唐伯虎点秋香\n",
      "127 萤火之森\n",
      "128 幸福终点站\n",
      "129 超能陆战队\n",
      "130 风之谷\n",
      "131 借东西的小人阿莉埃蒂\n",
      "132 无人知晓\n",
      "133 上帝之城\n",
      "134 神偷奶爸\n",
      "135 怪兽电力公司\n",
      "136 玩具总动员3\n",
      "137 血战钢锯岭\n",
      "138 电锯惊魂\n",
      "139 岁月神偷\n",
      "140 谍影重重3\n",
      "141 七武士\n",
      "142 英雄本色\n",
      "143 喜宴\n",
      "144 时空恋旅人\n",
      "145 傲慢与偏见\n",
      "146 疯狂原始人\n",
      "147 完美的世界\n",
      "148 萤火虫之墓\n",
      "149 东邪西毒\n",
      "150 真爱至上\n",
      "151 贫民窟的百万富翁\n",
      "152 教父3\n",
      "153 纵横四海\n",
      "154 心迷宫\n",
      "155 记忆碎片\n",
      "156 黑天鹅\n",
      "157 被解救的姜戈\n",
      "158 三块广告牌\n",
      "159 荒蛮故事\n",
      "160 达拉斯买家俱乐部\n",
      "161 花样年华\n",
      "162 哪吒闹海\n",
      "163 我是山姆\n",
      "164 雨人\n",
      "165 你的名字。\n",
      "166 绿皮书\n",
      "167 卢旺达饭店\n",
      "168 头脑特工队\n",
      "169 你看起来好像很好吃\n",
      "170 天书奇谭\n",
      "171 海边的曼彻斯特\n",
      "172 无敌破坏王\n",
      "173 恋恋笔记本\n",
      "174 头号玩家\n",
      "175 冰川时代\n",
      "176 未麻的部屋\n",
      "177 模仿游戏\n",
      "178 一个叫欧维的男人决定去死\n",
      "179 二十二\n",
      "180 忠犬八公物语\n",
      "181 虎口脱险\n",
      "182 爆裂鼓手\n",
      "183 功夫\n",
      "184 雨中曲\n",
      "185 黑客帝国3：矩阵革命\n",
      "186 海洋\n",
      "187 人工智能\n",
      "188 房间\n",
      "189 魔女宅急便\n",
      "190 燃情岁月\n",
      "191 海街日记\n",
      "192 恐怖游轮\n",
      "193 穿越时空的少女\n",
      "194 惊魂记\n",
      "195 罗生门\n",
      "196 魂断蓝桥\n",
      "197 完美陌生人\n",
      "198 猜火车\n",
      "199 釜山行\n",
      "200 阿飞正传\n",
      "201 疯狂的石头\n",
      "202 香水\n",
      "203 奇迹男孩\n",
      "204 终结者2：审判日\n",
      "205 可可西里\n",
      "206 牯岭街少年杀人事件\n",
      "207 初恋这件小事\n",
      "208 谍影重重2\n",
      "209 谍影重重\n",
      "210 战争之王\n",
      "211 新世界\n",
      "212 朗读者\n",
      "213 浪潮\n",
      "214 地球上的星星\n",
      "215 青蛇\n",
      "216 2001太空漫游\n",
      "217 爱在午夜降临前\n",
      "218 新龙门客栈\n",
      "219 人生果实\n",
      "220 无耻混蛋\n",
      "221 源代码\n",
      "222 步履不停\n",
      "223 绿里奇迹\n",
      "224 小萝莉的猴神大叔\n",
      "225 再次出发之纽约遇见你\n",
      "226 追随\n",
      "227 血钻\n",
      "228 彗星来的那一夜\n",
      "229 一次别离\n",
      "230 城市之光\n",
      "231 哈利·波特与阿兹卡班的囚徒\n",
      "232 疯狂的麦克斯4：狂暴之路\n",
      "233 东京物语\n",
      "234 哈利·波特与密室\n",
      "235 撞车\n",
      "236 聚焦\n",
      "237 梦之安魂曲\n",
      "238 发条橙\n",
      "239 遗愿清单\n",
      "240 黑鹰坠落\n",
      "241 E.T. 外星人\n",
      "242 驴得水\n",
      "243 色，戒\n",
      "244 我爱你\n",
      "245 末路狂花\n",
      "246 这个男人来自地球\n",
      "247 变脸\n",
      "248 千钧一发\n",
      "249 国王的演讲\n",
      "250 小偷家族\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "from lxml import etree\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_1)\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = urllib.request.urlopen(url, context=context)\n",
    "    return response\n",
    "\n",
    "def parse(url):\n",
    "    response = fetch_page(url)\n",
    "    page = response.read()\n",
    "    html = etree.HTML(page)\n",
    "    \n",
    "    xpath_movie = '//*[@id=\"content\"]/div/div[1]/ol/li'\n",
    "    xpath_title = './/span[@class=\"title\"]'\n",
    "    xpath_pages = '//*[@id=\"content\"]/div/div[1]/div[2]/a'\n",
    "    \n",
    "    pages = html.xpath(xpath_pages)\n",
    "    fetch_list = []\n",
    "    result = []\n",
    "    \n",
    "    for element_movie in html.xpath(xpath_movie):\n",
    "        result.append(element_movie)\n",
    "    \n",
    "    for p in pages:\n",
    "        fetch_list.append(url+p.get('href'))\n",
    "        \n",
    "    for url in fetch_list:\n",
    "        response = fetch_page(url)\n",
    "        page = response.read()\n",
    "        html = etree.HTML(page)\n",
    "        for element_movie in html.xpath(xpath_movie):\n",
    "            result.append(element_movie)\n",
    "            \n",
    "    for i, movie in enumerate(result,1):\n",
    "        title = movie.find(xpath_title).text\n",
    "        print(i, title)\n",
    "%time parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version2 use requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import ssl\n",
    "from lxml import etree\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    return response\n",
    "\n",
    "def parse(url):\n",
    "    response = fetch_page(url)\n",
    "    page = response.content\n",
    "    html = etree.HTML(page)\n",
    "    \n",
    "    xpath_movie = '//*[@id=\"content\"]/div/div[1]/ol/li'\n",
    "    xpath_title = './/span[@class=\"title\"]'\n",
    "    xpath_pages = '//*[@id=\"content\"]/div/div[1]/div[2]/a'\n",
    "    \n",
    "    pages = html.xpath(xpath_pages)\n",
    "    fetch_list = []\n",
    "    result = []\n",
    "    \n",
    "    for element_movie in html.xpath(xpath_movie):\n",
    "        result.append(element_movie)\n",
    "    \n",
    "    for p in pages:\n",
    "        fetch_list.append(url+p.get('href'))\n",
    "        \n",
    "    for url in fetch_list:\n",
    "        response = fetch_page(url)\n",
    "        page = response.content\n",
    "        html = etree.HTML(page)\n",
    "        for element_movie in html.xpath(xpath_movie):\n",
    "            result.append(element_movie)\n",
    "            \n",
    "    for i, movie in enumerate(result,1):\n",
    "        title = movie.find(xpath_title).text\n",
    "#         print(i, title)\n",
    "%time parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version3 use re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import re\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    return response\n",
    "\n",
    "def parse(url):\n",
    "    response = fetch_page(url)\n",
    "    page = response.content\n",
    "    \n",
    "    fetch_list = set()\n",
    "    result = []\n",
    "\n",
    "    for title in re.findall(rb'<a href=.*\\s.*<span class=\"title\">(.*)</span>', page):\n",
    "        result.append(title)\n",
    "\n",
    "    for postfix in re.findall(rb'<a href=\"(\\?start=.*?)\"', page):\n",
    "        fetch_list.add(url + postfix.decode())\n",
    "\n",
    "    for url in fetch_list:\n",
    "        response = fetch_page(url)\n",
    "        page = response.content\n",
    "        for title in re.findall(rb'<a href=.*\\s.*<span class=\"title\">(.*)</span>', page):\n",
    "            result.append(title)\n",
    "\n",
    "    for i, title in enumerate(result, 1):\n",
    "        title = title.decode()\n",
    "#         print(i, title)\n",
    "%time parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version4 use thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 801 ms\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import re\n",
    "from threading import Thread\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    return response\n",
    "\n",
    "def parse(url):\n",
    "    response = fetch_page(url)\n",
    "    page = response.content\n",
    "    html = etree.HTML(page)\n",
    "\n",
    "    xpath_movie = '//*[@id=\"content\"]/div/div[1]/ol/li'\n",
    "    xpath_title = './/span[@class=\"title\"]'\n",
    "    xpath_pages = '//*[@id=\"content\"]/div/div[1]/div[2]/a'\n",
    "\n",
    "    pages = html.xpath(xpath_pages)\n",
    "    fetch_list = []\n",
    "    result = []\n",
    "\n",
    "    for element_movie in html.xpath(xpath_movie):\n",
    "        result.append(element_movie)\n",
    "\n",
    "    for p in pages:\n",
    "        fetch_list.append(url + p.get('href'))\n",
    "\n",
    "    def fetch_content(url):\n",
    "        response = fetch_page(url)\n",
    "        page = response.content\n",
    "        html = etree.HTML(page)\n",
    "        for element_movie in html.xpath(xpath_movie):\n",
    "            result.append(element_movie)\n",
    "\n",
    "    threads = []\n",
    "    for url in fetch_list:\n",
    "        t = Thread(target=fetch_content, args=[url])\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    for i, movie in enumerate(result, 1):\n",
    "        title = movie.find(xpath_title).text\n",
    "        # print(i, title)\n",
    "%time parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# versin5 more threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-dfbe32799362>\u001b[0m in \u001b[0;36mparse\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch_content\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0melement_movie\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxpath_movie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from time import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    return response\n",
    "\n",
    "def fetch_content(url):\n",
    "    response = fetch_page(url)\n",
    "    page = response.content\n",
    "    return page\n",
    "\n",
    "def parse(url):\n",
    "    page = fetch_content(url)\n",
    "    html = etree.HTML(page)\n",
    "\n",
    "    xpath_movie = '//*[@id=\"content\"]/div/div[1]/ol/li'\n",
    "    xpath_title = './/span[@class=\"title\"]'\n",
    "    xpath_pages = '//*[@id=\"content\"]/div/div[1]/div[2]/a'\n",
    "\n",
    "    pages = html.xpath(xpath_pages)\n",
    "    fetch_list = []\n",
    "    result = []\n",
    "\n",
    "    for element_movie in html.xpath(xpath_movie):\n",
    "        result.append(element_movie)\n",
    "\n",
    "    for p in pages:\n",
    "        fetch_list.append(url + p.get('href'))\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        for page in executor.map(fetch_content, fetch_list):\n",
    "            html = etree.HTML(page)\n",
    "            for element_movie in html.xpath(xpath_movie):\n",
    "                result.append(element_movie)\n",
    "\n",
    "    for i, movie in enumerate(result, 1):\n",
    "        title = movie.find(xpath_title).text\n",
    "        # print(i, title)\n",
    "%time parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version6 use gevent to access async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:6: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.contrib.pyopenssl (C:\\\\Users\\\\Administrator\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\urllib3\\\\contrib\\\\pyopenssl.py)', 'urllib3.util (C:\\\\Users\\\\Administrator\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\urllib3\\\\util\\\\__init__.py)']. \n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 799 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gevent\\hub.py:154: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from time import time\n",
    "import gevent\n",
    "from gevent import monkey\n",
    "monkey.patch_all()\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    return response\n",
    "\n",
    "def fetch_content(url):\n",
    "    response = fetch_page(url)\n",
    "    page = response.content\n",
    "    return page\n",
    "\n",
    "def parse(url):\n",
    "    page = fetch_content(url)\n",
    "    html = etree.HTML(page)\n",
    "\n",
    "    xpath_movie = '//*[@id=\"content\"]/div/div[1]/ol/li'\n",
    "    xpath_title = './/span[@class=\"title\"]'\n",
    "    xpath_pages = '//*[@id=\"content\"]/div/div[1]/div[2]/a'\n",
    "\n",
    "    pages = html.xpath(xpath_pages)\n",
    "    fetch_list = []\n",
    "    result = []\n",
    "\n",
    "    for element_movie in html.xpath(xpath_movie):\n",
    "        result.append(element_movie)\n",
    "\n",
    "    for p in pages:\n",
    "        fetch_list.append(url + p.get('href'))\n",
    "\n",
    "    jobs = [gevent.spawn(fetch_content, url) for url in fetch_list]\n",
    "    gevent.joinall(jobs)\n",
    "    [job.value for job in jobs]\n",
    "\n",
    "    for page in [job.value for job in jobs]:\n",
    "        html = etree.HTML(page)\n",
    "        for element_movie in html.xpath(xpath_movie):\n",
    "            result.append(element_movie)\n",
    "\n",
    "    for i, movie in enumerate(result, 1):\n",
    "        title = movie.find(xpath_title).text\n",
    "        # print(i, title)\n",
    "%time parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version7 asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d7d87fa20171>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Cost {} seconds'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-d7d87fa20171>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Cost {} seconds'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This event loop is already running'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "from time import time\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "url = 'https://movie.douban.com/top250'\n",
    "\n",
    "async def fetch_content(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "async def parse(url):\n",
    "    page = await fetch_content(url)\n",
    "    html = etree.HTML(page)\n",
    "\n",
    "    xpath_movie = '//*[@id=\"content\"]/div/div[1]/ol/li'\n",
    "    xpath_title = './/span[@class=\"title\"]'\n",
    "    xpath_pages = '//*[@id=\"content\"]/div/div[1]/div[2]/a'\n",
    "\n",
    "    pages = html.xpath(xpath_pages)\n",
    "    fetch_list = []\n",
    "    result = []\n",
    "\n",
    "    for element_movie in html.xpath(xpath_movie):\n",
    "        result.append(element_movie)\n",
    "\n",
    "    for p in pages:\n",
    "        fetch_list.append(url + p.get('href'))\n",
    "\n",
    "    tasks = [fetch_content(url) for url in fetch_list]\n",
    "    pages = await asyncio.gather(*tasks)\n",
    "\n",
    "    for page in pages:\n",
    "        html = etree.HTML(page)\n",
    "        for element_movie in html.xpath(xpath_movie):\n",
    "            result.append(element_movie)\n",
    "\n",
    "    for i, movie in enumerate(result, 1):\n",
    "        title = movie.find(xpath_title).text\n",
    "#         print(i, title)\n",
    "\n",
    "def main():\n",
    "    loop = asyncio.get_event_loop()    \n",
    "    start = time()    \n",
    "    for i in range(5):\n",
    "        loop.run_until_complete(parse(url))\n",
    "    end = time()\n",
    "    print ('Cost {} seconds'.format((end - start) / 5))\n",
    "    loop.close()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
