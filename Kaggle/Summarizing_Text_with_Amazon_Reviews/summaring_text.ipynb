{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Credit](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "from numba import jit\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "tqdm.pandas()\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s: %(levelname)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as  plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.corpus import stopwords\n",
    "from attention import AttentionLayer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Reviews.csv', nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'], inplace=True)\n",
    "data.dropna(axis=0, inplace=True, subset=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        0\n",
       "ProductId                 0\n",
       "UserId                    0\n",
       "ProfileName               0\n",
       "HelpfulnessNumerator      0\n",
       "HelpfulnessDenominator    0\n",
       "Score                     0\n",
       "Time                      0\n",
       "Summary                   0\n",
       "Text                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
       "1             Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Good Quality Dog Food\n",
       "1        Not as Advertised\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Summary[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本与摘要清洗\n",
    "- 转小写\n",
    "- 缩写转全写\n",
    "- 删除html标签\n",
    "- 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords=True, bos_and_eos=False):\n",
    "    text = text.lower()\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in contractions:\n",
    "            new_text.append(contractions[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    text = ' '.join(new_text)\n",
    "    \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[>_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'<br', ' ',text)\n",
    "    text = re.sub(r'><br', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words('english'))\n",
    "        text  = [word for word in text if not word in stops]\n",
    "        text = ' '.join(text)\n",
    "    \n",
    "    if bos_and_eos:\n",
    "        text = ' '.join(['bos', text, 'eos'])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 摘要不去除停用词，且前后加上开始与结束标签\n",
    "data['Cleaned_Summary'] = data.Summary.apply(clean_text, args=(False,True))\n",
    "data['Cleaned_Text'] = data.Text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Cleaned_Summary</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>bos good quality dog food eos</td>\n",
       "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>bos not as advertised eos</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>bos  delight  says it all eos</td>\n",
       "      <td>confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      Text  \\\n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...   \n",
       "1           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".   \n",
       "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...   \n",
       "\n",
       "                 Summary                Cleaned_Summary  \\\n",
       "0  Good Quality Dog Food  bos good quality dog food eos   \n",
       "1      Not as Advertised      bos not as advertised eos   \n",
       "2  \"Delight\" says it all  bos  delight  says it all eos   \n",
       "\n",
       "                                                                                                                                                                                              Cleaned_Text  \n",
       "0                                     bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better  \n",
       "1                                                                    product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo  \n",
       "2  confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Text', 'Summary', 'Cleaned_Summary', 'Cleaned_Text']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Cleaned_Summary</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>bos good quality dog food eos</td>\n",
       "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>bos not as advertised eos</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      Text  \\\n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...   \n",
       "1           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".   \n",
       "\n",
       "                 Summary                Cleaned_Summary  \\\n",
       "0  Good Quality Dog Food  bos good quality dog food eos   \n",
       "1      Not as Advertised      bos not as advertised eos   \n",
       "\n",
       "                                                                                                                                                           Cleaned_Text  \n",
       "0  bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better  \n",
       "1                                 product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pure = data[['Text', 'Summary', 'Cleaned_Summary', 'Cleaned_Text']].copy()\n",
    "data_pure.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9513 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      "Text               9513 non-null object\n",
      "Summary            9513 non-null object\n",
      "Cleaned_Summary    9513 non-null object\n",
      "Cleaned_Text       9513 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 371.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_pure.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看长度范围，确定统一长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Cleaned_Summary</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Text_Length</th>\n",
       "      <th>Summary_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>bos good quality dog food eos</td>\n",
       "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>bos not as advertised eos</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>bos  delight  says it all eos</td>\n",
       "      <td>confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      Text  \\\n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...   \n",
       "1           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".   \n",
       "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...   \n",
       "\n",
       "                 Summary                Cleaned_Summary  \\\n",
       "0  Good Quality Dog Food  bos good quality dog food eos   \n",
       "1      Not as Advertised      bos not as advertised eos   \n",
       "2  \"Delight\" says it all  bos  delight  says it all eos   \n",
       "\n",
       "                                                                                                                                                                                              Cleaned_Text  \\\n",
       "0                                     bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better   \n",
       "1                                                                    product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo   \n",
       "2  confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...   \n",
       "\n",
       "   Text_Length  Summary_Length  \n",
       "0           23               6  \n",
       "1           18               5  \n",
       "2           40               6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pure['Text_Length'] = data_pure.Cleaned_Text.apply(lambda x:len(x.split()))\n",
    "data_pure['Summary_Length'] = data_pure.Cleaned_Summary.apply(lambda x:len(x.split()))\n",
    "data_pure.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    9513.000000\n",
       "mean        6.140545\n",
       "std         2.663633\n",
       "min         2.000000\n",
       "25%         4.000000\n",
       "50%         6.000000\n",
       "75%         7.000000\n",
       "max        32.000000\n",
       "Name: Summary_Length, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pure.Summary_Length.plot.box(figsize=(6,6))\n",
    "plt.show()\n",
    "data_pure.Summary_Length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    9513.000000\n",
       "mean       38.003574\n",
       "std        37.029990\n",
       "min         0.000000\n",
       "25%        16.000000\n",
       "50%        27.000000\n",
       "75%        46.000000\n",
       "max       749.000000\n",
       "Name: Text_Length, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pure.Text_Length.plot.box(figsize=(6,6))\n",
    "plt.show()\n",
    "data_pure.Text_Length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text = 80\n",
    "max_len_summary = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分离训练，验证，测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8561,), (952,), (8561,), (952,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, valid_features, train_labels, valid_labels = train_test_split(data_pure.Cleaned_Text,\n",
    "                                                                               data_pure.Cleaned_Summary, test_size=.1,\n",
    "                                                                               random_state=0, shuffle=True)\n",
    "train_features.shape, valid_features.shape, train_labels.shape, valid_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story c lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'bos  delight  says it all eos')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=2\n",
    "train_features[sample], train_labels[sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenizer = Tokenizer()\n",
    "train_tokenizer.fit_on_texts(list(train_features))\n",
    "train_index2word = train_tokenizer.index_word\n",
    "\n",
    "train_seq = train_tokenizer.texts_to_sequences(train_features)\n",
    "valid_seq = train_tokenizer.texts_to_sequences(valid_features)\n",
    "\n",
    "paded_train_seq = pad_sequences(train_seq, maxlen=max_len_text, padding='post')\n",
    "paded_valid_seq = pad_sequences(valid_seq, maxlen=max_len_text, padding='post')\n",
    "\n",
    "train_vocab_size = len(train_word2index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(list(train_labels))\n",
    "label_word2index = label_tokenizer.word_index\n",
    "label_index2word = label_tokenizer.index_word\n",
    "\n",
    "train_label_seq = label_tokenizer.texts_to_sequences(train_labels)\n",
    "valid_label_seq = label_tokenizer.texts_to_sequences(valid_labels)\n",
    "\n",
    "paded_train_label_seq = pad_sequences(train_label_seq, maxlen=max_len_summary, padding='post')\n",
    "paded_valid_label_seq = pad_sequences(valid_label_seq, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "label_vocab_size = len(label_word2index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17306, 4288)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocab_size, label_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  49,  484,  261,  375,  144,  489,   18, 1021,  687, 4859,   54,\n",
       "       5421,  576, 1022,    9,    6,  336,   86, 1250,   17, 3797,   54,\n",
       "         73,   78,  311,  129,  576,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paded_train_seq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love great 100 calorie snack snack throughout day husband 3 year old enjoys eating well']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenizer.sequences_to_texts([paded_train_seq[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'will never buy store bought extract again'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(label_tokenizer.sequences_to_texts([paded_train_label_seq[4]])[0].split()[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 500\n",
    "def build_model(latent_dim):\n",
    "    ops.reset_default_graph()\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_len_text,))\n",
    "    enc_emb = Embedding(train_vocab_size, latent_dim, trainable=True)(encoder_inputs)\n",
    "    \n",
    "    # LSTM1\n",
    "    encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    encoder_outputs1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "    \n",
    "    # LSTM2\n",
    "    encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs1)\n",
    "    \n",
    "    # LSTM3\n",
    "    encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm3(encoder_outputs2)\n",
    "    \n",
    "    # encoder inference\n",
    "    encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    dec_emb_layer = Embedding(label_vocab_size, latent_dim, trainable=True)\n",
    "    dec_emb = dec_emb_layer(decoder_inputs)\n",
    "    \n",
    "    # Using LSTM encoder_state as initial state\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, \n",
    "                                                                          initial_state=[state_h, \n",
    "                                                                                         state_c])\n",
    "    \n",
    "    # decoder inference\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_hidden_state_input = Input(shape=(max_len_text, latent_dim))\n",
    "    dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "    decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, \n",
    "                                                       initial_state=[decoder_state_input_h,\n",
    "                                                                     decoder_state_input_c])\n",
    "    \n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "    \n",
    "    # attention inference\n",
    "    attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "    decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "    \n",
    "    # Concating attention layer output and decoder LSTM output\n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "    \n",
    "    # Dense layer\n",
    "    decoder_dense = TimeDistributed(Dense(label_vocab_size, activation='softmax'))\n",
    "    decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "    \n",
    "    # A dense softmax to generate prob dist. over the target vocabulary\n",
    "    decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "    decoder_model = Model([decoder_inputs]+[decoder_hidden_state_input, \n",
    "                                            decoder_state_input_h,\n",
    "                                           decoder_state_input_c],\n",
    "                         [decoder_outputs2]+[state_h2, state_c2])\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks \n",
    "# lr_schedule = ExponentialDecay(.1,decay_steps=10000,decay_rate=.96,staircase=True)\n",
    "csv_logger = CSVLogger('temp/csv_logger2')\n",
    "stop_callback = EarlyStopping(monitor='val_loss',mode='min',verbose=1)\n",
    "\n",
    "checkpoint_path = 'temp/training_checkpoints/'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = ModelCheckpoint(checkpoint_dir,save_weights_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, *_ = build_model(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 80, 500)      8653000     input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 80, 500), (N 2002000     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 80, 500), (N 2002000     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 500)    2144000     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 80, 500), (N 2002000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 4288)   4292288     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 23,597,788\n",
      "Trainable params: 23,597,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8561 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8192/8561 [===========================>..] - ETA: 11:41 - loss: 2.91 - ETA: 10:55 - loss: 2.87 - ETA: 10:09 - loss: 2.83 - ETA: 9:22 - loss: 2.8248 - ETA: 8:37 - loss: 2.807 - ETA: 7:52 - loss: 2.822 - ETA: 7:09 - loss: 2.821 - ETA: 6:26 - loss: 2.831 - ETA: 5:43 - loss: 2.834 - ETA: 5:01 - loss: 2.826 - ETA: 4:17 - loss: 2.819 - ETA: 3:33 - loss: 2.838 - ETA: 2:48 - loss: 2.844 - ETA: 2:03 - loss: 2.845 - ETA: 1:18 - loss: 2.843 - ETA: 32s - loss: 2.8472 \n",
      "Epoch 00001: saving model to temp/training_checkpoints\n",
      "8561/8561 [==============================] - 776s 91ms/sample - loss: 2.8444 - val_loss: 2.7539\n",
      "Epoch 2/50\n",
      "8192/8561 [===========================>..] - ETA: 10:42 - loss: 2.78 - ETA: 10:29 - loss: 2.76 - ETA: 9:55 - loss: 2.7504 - ETA: 9:14 - loss: 2.757 - ETA: 8:32 - loss: 2.776 - ETA: 7:50 - loss: 2.785 - ETA: 7:07 - loss: 2.781 - ETA: 6:24 - loss: 2.787 - ETA: 5:41 - loss: 2.785 - ETA: 4:58 - loss: 2.792 - ETA: 4:15 - loss: 2.802 - ETA: 3:30 - loss: 2.804 - ETA: 2:46 - loss: 2.816 - ETA: 2:02 - loss: 2.808 - ETA: 1:17 - loss: 2.806 - ETA: 32s - loss: 2.8076 \n",
      "Epoch 00002: saving model to temp/training_checkpoints\n",
      "8561/8561 [==============================] - 764s 89ms/sample - loss: 2.8075 - val_loss: 2.7238\n",
      "Epoch 3/50\n",
      "8192/8561 [===========================>..] - ETA: 10:51 - loss: 2.78 - ETA: 10:34 - loss: 2.78 - ETA: 10:02 - loss: 2.77 - ETA: 9:24 - loss: 2.7434 - ETA: 8:43 - loss: 2.761 - ETA: 7:58 - loss: 2.770 - ETA: 7:14 - loss: 2.782 - ETA: 6:30 - loss: 2.771 - ETA: 5:46 - loss: 2.767 - ETA: 5:01 - loss: 2.763 - ETA: 4:16 - loss: 2.759 - ETA: 3:32 - loss: 2.774 - ETA: 2:47 - loss: 2.764 - ETA: 2:02 - loss: 2.760 - ETA: 1:17 - loss: 2.755 - ETA: 32s - loss: 2.7614 \n",
      "Epoch 00003: saving model to temp/training_checkpoints\n",
      "8561/8561 [==============================] - 766s 90ms/sample - loss: 2.7620 - val_loss: 2.7265\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([paded_train_seq, paded_train_label_seq[:,:-1]], \n",
    "                    paded_train_label_seq.reshape(*paded_train_label_seq.shape, 1)[:, 1:],\n",
    "                    validation_data=([paded_valid_seq, paded_valid_label_seq[:,:-1]], \n",
    "                                     paded_valid_label_seq.reshape(*paded_valid_label_seq.shape, 1)[:,1:]),\n",
    "                    epochs=50, \n",
    "                    batch_size=512,\n",
    "                    callbacks=[csv_logger, stop_callback, cp_callback])\n",
    "logger = pd.DataFrame(history.history)\n",
    "logger.plot(figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.290843</td>\n",
       "      <td>3.180711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.227364</td>\n",
       "      <td>2.927936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.051676</td>\n",
       "      <td>2.814775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.964435</td>\n",
       "      <td>2.792177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.867706</td>\n",
       "      <td>2.747863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.809038</td>\n",
       "      <td>2.772846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.758647</td>\n",
       "      <td>2.728798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.716092</td>\n",
       "      <td>2.733078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.664167</td>\n",
       "      <td>2.706336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.603078</td>\n",
       "      <td>2.701337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch      loss  val_loss\n",
       "0      0  4.290843  3.180711\n",
       "1      1  3.227364  2.927936\n",
       "2      2  3.051676  2.814775\n",
       "3      3  2.964435  2.792177\n",
       "4      4  2.867706  2.747863\n",
       "5      5  2.809038  2.772846\n",
       "6      6  2.758647  2.728798\n",
       "7      7  2.716092  2.733078\n",
       "8      8  2.664167  2.706336\n",
       "9      9  2.603078  2.701337"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = pd.read_csv('temp/csv_logger')\n",
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger[['loss', 'val_loss']].plot(figsize=(6,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存和重新调用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回调函数自动保存与手动保存权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x15abd523668>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get callback's saved checkpoint file\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "new_model = build_model(latent_dim)\n",
    "new_model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights manually\n",
    "model.save_weights('temp/training_checkpoints/manually_checkpoint')\n",
    "\n",
    "# load weights with new model instance\n",
    "new_model = build_model(latent_dim)\n",
    "new_model.load_weights('temp/training_checkpoints/manually_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存全部模型\n",
    "- 如果引入手动实现的网络层，会出错，如此模型中的注意力层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save whole model\n",
    "model.save('saved_model/model.h5')\n",
    "\n",
    "# load whole model from that file\n",
    "new_model = load_model('saved_model/model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x25845cc8dd8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "new_model = build_model(latent_dim)\n",
    "new_model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 80, 500)      8653000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 80, 500), (N 2002000     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 80, 500), (N 2002000     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 500)    2144000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 80, 500), (N 2002000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 4288)   4292288     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 23,597,788\n",
      "Trainable params: 23,597,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 80)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 80, 500)           8653000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 80, 500), (None,  2002000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 80, 500), (None,  2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                [(None, 80, 500), (None,  2002000   \n",
      "=================================================================\n",
      "Total params: 14,659,000\n",
      "Trainable params: 14,659,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 500)    2144000     input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[1][0]                \n",
      "                                                                 input_18[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 80, 500)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      input_20[0][0]                   \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, None, 1000)   0           lstm_3[1][0]                     \n",
      "                                                                 attention_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 4288)   4292288     concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,938,788\n",
      "Trainable params: 8,938,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_2/embeddings:0' shape=(17306, 500) dtype=float32, numpy=\n",
       " array([[-0.039,  0.038, -0.042, ...,  0.019, -0.003,  0.01 ],\n",
       "        [ 0.007,  0.016,  0.001, ..., -0.001, -0.005,  0.045],\n",
       "        [-0.055,  0.047,  0.028, ...,  0.053, -0.036, -0.019],\n",
       "        ...,\n",
       "        [ 0.014, -0.05 ,  0.022, ...,  0.011, -0.036,  0.041],\n",
       "        [ 0.009, -0.021,  0.012, ...,  0.009, -0.007, -0.001],\n",
       "        [ 0.016,  0.02 ,  0.036, ...,  0.014,  0.032,  0.03 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_4/kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.054,  0.032,  0.014, ..., -0.014, -0.014,  0.005],\n",
       "        [-0.041,  0.029, -0.025, ...,  0.033,  0.052, -0.002],\n",
       "        [ 0.031,  0.01 ,  0.009, ...,  0.022, -0.012,  0.037],\n",
       "        ...,\n",
       "        [-0.038,  0.029, -0.049, ..., -0.033,  0.025, -0.   ],\n",
       "        [ 0.015, -0.033, -0.028, ..., -0.02 , -0.02 ,  0.033],\n",
       "        [ 0.028,  0.026, -0.033, ...,  0.038,  0.005, -0.033]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_4/recurrent_kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[-0.002,  0.019,  0.015, ...,  0.03 ,  0.027,  0.004],\n",
       "        [ 0.029,  0.022,  0.036, ...,  0.   ,  0.013,  0.02 ],\n",
       "        [ 0.03 ,  0.03 ,  0.029, ..., -0.042, -0.007,  0.048],\n",
       "        ...,\n",
       "        [ 0.028,  0.02 ,  0.044, ...,  0.031,  0.013,  0.012],\n",
       "        [ 0.012,  0.005, -0.007, ..., -0.006, -0.029, -0.005],\n",
       "        [-0.014, -0.006, -0.027, ...,  0.017,  0.009, -0.02 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_4/bias:0' shape=(2000,) dtype=float32, numpy=array([-0.006, -0.014, -0.002, ..., -0.   , -0.006, -0.003], dtype=float32)>,\n",
       " <tf.Variable 'lstm_1_1/kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.011,  0.022,  0.007, ...,  0.029,  0.028, -0.008],\n",
       "        [ 0.03 , -0.024, -0.039, ..., -0.033, -0.002, -0.023],\n",
       "        [ 0.016, -0.028,  0.031, ...,  0.009,  0.011,  0.003],\n",
       "        ...,\n",
       "        [-0.033, -0.038,  0.044, ...,  0.037,  0.036, -0.023],\n",
       "        [ 0.   , -0.035, -0.   , ..., -0.037,  0.009, -0.043],\n",
       "        [ 0.018, -0.029,  0.008, ...,  0.011,  0.016,  0.01 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_1_1/recurrent_kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.053,  0.019,  0.017, ...,  0.005, -0.047, -0.003],\n",
       "        [ 0.013,  0.03 , -0.011, ...,  0.023,  0.04 , -0.019],\n",
       "        [ 0.   , -0.017,  0.007, ..., -0.034,  0.007,  0.002],\n",
       "        ...,\n",
       "        [-0.008,  0.03 , -0.016, ...,  0.003, -0.023, -0.031],\n",
       "        [ 0.003,  0.01 ,  0.01 , ..., -0.005, -0.009,  0.019],\n",
       "        [ 0.008, -0.005,  0.018, ..., -0.012,  0.014,  0.02 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_1_1/bias:0' shape=(2000,) dtype=float32, numpy=array([-0.001, -0.005, -0.011, ..., -0.011, -0.016, -0.004], dtype=float32)>,\n",
       " <tf.Variable 'embedding_1_1/embeddings:0' shape=(4288, 500) dtype=float32, numpy=\n",
       " array([[ 0.06 , -0.071, -0.05 , ..., -0.057,  0.049,  0.043],\n",
       "        [ 0.022,  0.045,  0.073, ...,  0.06 , -0.033, -0.073],\n",
       "        [ 0.008, -0.091, -0.041, ..., -0.086,  0.044,  0.068],\n",
       "        ...,\n",
       "        [-0.052, -0.019, -0.028, ..., -0.017, -0.055,  0.029],\n",
       "        [-0.058,  0.031,  0.027, ..., -0.034,  0.028,  0.003],\n",
       "        [ 0.017,  0.032, -0.04 , ..., -0.022,  0.061,  0.052]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_2_1/kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.005, -0.02 , -0.012, ..., -0.054,  0.047,  0.026],\n",
       "        [-0.046,  0.011, -0.03 , ..., -0.009,  0.024,  0.033],\n",
       "        [-0.046,  0.001, -0.046, ..., -0.004, -0.007, -0.021],\n",
       "        ...,\n",
       "        [-0.026,  0.003, -0.022, ...,  0.001, -0.006, -0.028],\n",
       "        [ 0.034, -0.004, -0.036, ...,  0.022, -0.036, -0.015],\n",
       "        [ 0.023,  0.032,  0.024, ..., -0.032, -0.016, -0.036]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_2_1/recurrent_kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.04 ,  0.012, -0.006, ..., -0.007, -0.015,  0.034],\n",
       "        [-0.024, -0.027, -0.001, ...,  0.   , -0.034, -0.005],\n",
       "        [ 0.025,  0.005,  0.029, ..., -0.004, -0.013, -0.002],\n",
       "        ...,\n",
       "        [ 0.048, -0.034, -0.025, ..., -0.001, -0.011, -0.027],\n",
       "        [ 0.006, -0.042, -0.006, ...,  0.004, -0.015, -0.014],\n",
       "        [ 0.056,  0.013,  0.029, ..., -0.007,  0.01 ,  0.009]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_2_1/bias:0' shape=(2000,) dtype=float32, numpy=array([ 0.014, -0.008,  0.008, ..., -0.017,  0.004, -0.004], dtype=float32)>,\n",
       " <tf.Variable 'lstm_3_1/kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.008,  0.05 ,  0.024, ...,  0.07 , -0.031,  0.042],\n",
       "        [-0.048,  0.005,  0.014, ..., -0.04 , -0.006, -0.09 ],\n",
       "        [-0.003,  0.015,  0.028, ...,  0.005,  0.039, -0.06 ],\n",
       "        ...,\n",
       "        [ 0.028, -0.082,  0.024, ..., -0.007, -0.051, -0.069],\n",
       "        [ 0.038,  0.037, -0.034, ...,  0.074,  0.059,  0.023],\n",
       "        [ 0.036,  0.037, -0.005, ...,  0.019, -0.03 ,  0.058]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_3_1/recurrent_kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.004,  0.002,  0.015, ...,  0.026, -0.029, -0.005],\n",
       "        [-0.016, -0.001,  0.01 , ...,  0.014, -0.002,  0.007],\n",
       "        [ 0.021, -0.011,  0.002, ...,  0.022, -0.018,  0.013],\n",
       "        ...,\n",
       "        [-0.036,  0.012, -0.011, ..., -0.008, -0.007, -0.01 ],\n",
       "        [-0.014,  0.013, -0.018, ..., -0.005,  0.012, -0.003],\n",
       "        [-0.022,  0.002, -0.033, ..., -0.045, -0.013, -0.007]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_3_1/bias:0' shape=(2000,) dtype=float32, numpy=array([0.014, 0.025, 0.008, ..., 0.016, 0.018, 0.002], dtype=float32)>,\n",
       " <tf.Variable 'attention_layer_1/W_a:0' shape=(500, 500) dtype=float32, numpy=\n",
       " array([[ 0.013, -0.025,  0.006, ..., -0.001,  0.035, -0.012],\n",
       "        [ 0.012, -0.003,  0.024, ...,  0.032,  0.013,  0.028],\n",
       "        [ 0.012,  0.036, -0.028, ...,  0.046, -0.039,  0.025],\n",
       "        ...,\n",
       "        [ 0.019,  0.009,  0.013, ..., -0.023, -0.024,  0.025],\n",
       "        [ 0.036,  0.019,  0.008, ...,  0.054,  0.007,  0.019],\n",
       "        [ 0.02 , -0.002,  0.022, ...,  0.03 ,  0.031, -0.031]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'attention_layer_1/U_a:0' shape=(500, 500) dtype=float32, numpy=\n",
       " array([[-0.02 , -0.011, -0.024, ...,  0.007, -0.027,  0.009],\n",
       "        [-0.022,  0.011, -0.04 , ...,  0.02 , -0.024,  0.048],\n",
       "        [-0.013, -0.031,  0.014, ..., -0.012, -0.049,  0.025],\n",
       "        ...,\n",
       "        [-0.017,  0.025, -0.031, ..., -0.049, -0.016, -0.014],\n",
       "        [-0.025,  0.013,  0.001, ..., -0.013,  0.034,  0.026],\n",
       "        [ 0.059,  0.04 , -0.014, ...,  0.01 ,  0.054, -0.033]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'attention_layer_1/V_a:0' shape=(500, 1) dtype=float32, numpy=\n",
       " array([[-0.035],\n",
       "        [-0.054],\n",
       "        [ 0.03 ],\n",
       "        [-0.037],\n",
       "        [ 0.021],\n",
       "        [-0.007],\n",
       "        [-0.02 ],\n",
       "        [ 0.034],\n",
       "        [ 0.02 ],\n",
       "        [-0.034],\n",
       "        [ 0.011],\n",
       "        [-0.043],\n",
       "        [-0.012],\n",
       "        [-0.001],\n",
       "        [-0.015],\n",
       "        [-0.034],\n",
       "        [ 0.01 ],\n",
       "        [-0.028],\n",
       "        [-0.03 ],\n",
       "        [-0.022],\n",
       "        [ 0.019],\n",
       "        [ 0.02 ],\n",
       "        [-0.045],\n",
       "        [-0.023],\n",
       "        [ 0.   ],\n",
       "        [-0.008],\n",
       "        [-0.015],\n",
       "        [-0.027],\n",
       "        [-0.038],\n",
       "        [-0.015],\n",
       "        [ 0.017],\n",
       "        [ 0.   ],\n",
       "        [ 0.039],\n",
       "        [ 0.012],\n",
       "        [ 0.021],\n",
       "        [ 0.009],\n",
       "        [ 0.024],\n",
       "        [-0.033],\n",
       "        [ 0.021],\n",
       "        [ 0.006],\n",
       "        [ 0.025],\n",
       "        [-0.029],\n",
       "        [ 0.054],\n",
       "        [ 0.018],\n",
       "        [ 0.038],\n",
       "        [ 0.023],\n",
       "        [-0.037],\n",
       "        [ 0.013],\n",
       "        [ 0.033],\n",
       "        [ 0.035],\n",
       "        [-0.056],\n",
       "        [ 0.017],\n",
       "        [ 0.023],\n",
       "        [-0.02 ],\n",
       "        [ 0.042],\n",
       "        [ 0.037],\n",
       "        [ 0.017],\n",
       "        [-0.012],\n",
       "        [-0.04 ],\n",
       "        [-0.044],\n",
       "        [ 0.04 ],\n",
       "        [ 0.044],\n",
       "        [ 0.003],\n",
       "        [ 0.022],\n",
       "        [-0.008],\n",
       "        [ 0.02 ],\n",
       "        [-0.011],\n",
       "        [-0.01 ],\n",
       "        [-0.007],\n",
       "        [-0.018],\n",
       "        [ 0.022],\n",
       "        [ 0.001],\n",
       "        [ 0.035],\n",
       "        [-0.032],\n",
       "        [-0.032],\n",
       "        [-0.013],\n",
       "        [-0.007],\n",
       "        [-0.037],\n",
       "        [-0.039],\n",
       "        [ 0.018],\n",
       "        [ 0.024],\n",
       "        [-0.003],\n",
       "        [-0.028],\n",
       "        [ 0.022],\n",
       "        [-0.037],\n",
       "        [-0.011],\n",
       "        [-0.053],\n",
       "        [-0.008],\n",
       "        [-0.032],\n",
       "        [-0.013],\n",
       "        [-0.024],\n",
       "        [-0.01 ],\n",
       "        [-0.024],\n",
       "        [ 0.003],\n",
       "        [-0.005],\n",
       "        [-0.024],\n",
       "        [-0.014],\n",
       "        [-0.009],\n",
       "        [ 0.016],\n",
       "        [ 0.016],\n",
       "        [-0.021],\n",
       "        [ 0.005],\n",
       "        [ 0.008],\n",
       "        [ 0.01 ],\n",
       "        [ 0.026],\n",
       "        [ 0.029],\n",
       "        [-0.024],\n",
       "        [-0.001],\n",
       "        [-0.007],\n",
       "        [ 0.034],\n",
       "        [ 0.02 ],\n",
       "        [-0.013],\n",
       "        [ 0.051],\n",
       "        [-0.034],\n",
       "        [ 0.049],\n",
       "        [-0.049],\n",
       "        [-0.001],\n",
       "        [-0.001],\n",
       "        [-0.024],\n",
       "        [-0.004],\n",
       "        [-0.04 ],\n",
       "        [ 0.005],\n",
       "        [-0.006],\n",
       "        [ 0.   ],\n",
       "        [ 0.055],\n",
       "        [-0.041],\n",
       "        [-0.022],\n",
       "        [ 0.01 ],\n",
       "        [ 0.05 ],\n",
       "        [ 0.052],\n",
       "        [ 0.03 ],\n",
       "        [-0.027],\n",
       "        [ 0.042],\n",
       "        [ 0.009],\n",
       "        [-0.026],\n",
       "        [ 0.036],\n",
       "        [ 0.042],\n",
       "        [ 0.009],\n",
       "        [-0.009],\n",
       "        [ 0.026],\n",
       "        [-0.038],\n",
       "        [-0.016],\n",
       "        [-0.005],\n",
       "        [-0.001],\n",
       "        [ 0.022],\n",
       "        [-0.017],\n",
       "        [-0.02 ],\n",
       "        [ 0.018],\n",
       "        [-0.02 ],\n",
       "        [ 0.006],\n",
       "        [ 0.032],\n",
       "        [-0.02 ],\n",
       "        [ 0.001],\n",
       "        [-0.001],\n",
       "        [-0.009],\n",
       "        [-0.024],\n",
       "        [-0.019],\n",
       "        [ 0.042],\n",
       "        [-0.015],\n",
       "        [-0.03 ],\n",
       "        [ 0.045],\n",
       "        [-0.027],\n",
       "        [ 0.03 ],\n",
       "        [-0.04 ],\n",
       "        [ 0.017],\n",
       "        [ 0.032],\n",
       "        [-0.03 ],\n",
       "        [ 0.021],\n",
       "        [ 0.   ],\n",
       "        [ 0.008],\n",
       "        [-0.026],\n",
       "        [-0.021],\n",
       "        [ 0.003],\n",
       "        [-0.032],\n",
       "        [ 0.042],\n",
       "        [-0.008],\n",
       "        [ 0.026],\n",
       "        [-0.009],\n",
       "        [ 0.051],\n",
       "        [-0.042],\n",
       "        [ 0.017],\n",
       "        [-0.015],\n",
       "        [-0.03 ],\n",
       "        [ 0.016],\n",
       "        [-0.029],\n",
       "        [-0.035],\n",
       "        [-0.025],\n",
       "        [ 0.043],\n",
       "        [ 0.041],\n",
       "        [-0.052],\n",
       "        [ 0.012],\n",
       "        [-0.051],\n",
       "        [-0.036],\n",
       "        [-0.017],\n",
       "        [ 0.02 ],\n",
       "        [ 0.037],\n",
       "        [ 0.049],\n",
       "        [-0.032],\n",
       "        [ 0.034],\n",
       "        [ 0.041],\n",
       "        [-0.042],\n",
       "        [-0.004],\n",
       "        [-0.045],\n",
       "        [ 0.021],\n",
       "        [-0.045],\n",
       "        [-0.023],\n",
       "        [ 0.019],\n",
       "        [ 0.036],\n",
       "        [-0.054],\n",
       "        [ 0.014],\n",
       "        [ 0.024],\n",
       "        [ 0.016],\n",
       "        [-0.005],\n",
       "        [-0.022],\n",
       "        [ 0.046],\n",
       "        [-0.037],\n",
       "        [-0.023],\n",
       "        [ 0.041],\n",
       "        [ 0.04 ],\n",
       "        [-0.029],\n",
       "        [ 0.052],\n",
       "        [-0.005],\n",
       "        [ 0.033],\n",
       "        [-0.027],\n",
       "        [-0.034],\n",
       "        [ 0.035],\n",
       "        [ 0.016],\n",
       "        [-0.019],\n",
       "        [ 0.015],\n",
       "        [-0.008],\n",
       "        [ 0.055],\n",
       "        [ 0.009],\n",
       "        [-0.049],\n",
       "        [ 0.016],\n",
       "        [ 0.035],\n",
       "        [ 0.014],\n",
       "        [ 0.029],\n",
       "        [-0.032],\n",
       "        [ 0.028],\n",
       "        [ 0.007],\n",
       "        [ 0.019],\n",
       "        [-0.014],\n",
       "        [ 0.006],\n",
       "        [ 0.024],\n",
       "        [ 0.046],\n",
       "        [ 0.005],\n",
       "        [ 0.046],\n",
       "        [ 0.016],\n",
       "        [-0.033],\n",
       "        [-0.029],\n",
       "        [ 0.023],\n",
       "        [-0.012],\n",
       "        [ 0.03 ],\n",
       "        [-0.018],\n",
       "        [-0.028],\n",
       "        [ 0.003],\n",
       "        [-0.016],\n",
       "        [ 0.052],\n",
       "        [-0.027],\n",
       "        [-0.028],\n",
       "        [-0.033],\n",
       "        [ 0.018],\n",
       "        [-0.048],\n",
       "        [ 0.027],\n",
       "        [-0.03 ],\n",
       "        [-0.032],\n",
       "        [-0.013],\n",
       "        [ 0.007],\n",
       "        [-0.048],\n",
       "        [-0.001],\n",
       "        [ 0.037],\n",
       "        [ 0.033],\n",
       "        [ 0.045],\n",
       "        [-0.001],\n",
       "        [ 0.024],\n",
       "        [-0.009],\n",
       "        [-0.009],\n",
       "        [-0.03 ],\n",
       "        [-0.031],\n",
       "        [ 0.054],\n",
       "        [-0.017],\n",
       "        [ 0.037],\n",
       "        [ 0.029],\n",
       "        [-0.029],\n",
       "        [ 0.037],\n",
       "        [ 0.014],\n",
       "        [ 0.017],\n",
       "        [-0.045],\n",
       "        [-0.009],\n",
       "        [-0.037],\n",
       "        [-0.032],\n",
       "        [ 0.037],\n",
       "        [ 0.026],\n",
       "        [ 0.043],\n",
       "        [-0.018],\n",
       "        [ 0.049],\n",
       "        [ 0.042],\n",
       "        [-0.008],\n",
       "        [ 0.016],\n",
       "        [-0.049],\n",
       "        [ 0.022],\n",
       "        [-0.052],\n",
       "        [ 0.047],\n",
       "        [-0.007],\n",
       "        [ 0.019],\n",
       "        [-0.045],\n",
       "        [ 0.024],\n",
       "        [ 0.021],\n",
       "        [-0.01 ],\n",
       "        [ 0.013],\n",
       "        [-0.017],\n",
       "        [ 0.026],\n",
       "        [-0.038],\n",
       "        [ 0.   ],\n",
       "        [-0.046],\n",
       "        [-0.019],\n",
       "        [-0.039],\n",
       "        [ 0.035],\n",
       "        [ 0.047],\n",
       "        [ 0.049],\n",
       "        [ 0.002],\n",
       "        [ 0.048],\n",
       "        [-0.001],\n",
       "        [-0.028],\n",
       "        [ 0.002],\n",
       "        [ 0.023],\n",
       "        [ 0.03 ],\n",
       "        [ 0.046],\n",
       "        [ 0.   ],\n",
       "        [ 0.041],\n",
       "        [-0.025],\n",
       "        [ 0.015],\n",
       "        [-0.028],\n",
       "        [ 0.043],\n",
       "        [-0.007],\n",
       "        [-0.05 ],\n",
       "        [ 0.042],\n",
       "        [ 0.036],\n",
       "        [-0.019],\n",
       "        [ 0.012],\n",
       "        [ 0.043],\n",
       "        [-0.033],\n",
       "        [-0.   ],\n",
       "        [-0.01 ],\n",
       "        [-0.033],\n",
       "        [-0.016],\n",
       "        [ 0.014],\n",
       "        [ 0.015],\n",
       "        [-0.038],\n",
       "        [ 0.025],\n",
       "        [ 0.009],\n",
       "        [ 0.039],\n",
       "        [ 0.028],\n",
       "        [ 0.023],\n",
       "        [ 0.047],\n",
       "        [ 0.013],\n",
       "        [ 0.027],\n",
       "        [-0.009],\n",
       "        [-0.   ],\n",
       "        [ 0.022],\n",
       "        [ 0.033],\n",
       "        [-0.   ],\n",
       "        [ 0.015],\n",
       "        [ 0.048],\n",
       "        [ 0.026],\n",
       "        [-0.018],\n",
       "        [-0.03 ],\n",
       "        [-0.043],\n",
       "        [ 0.021],\n",
       "        [-0.046],\n",
       "        [ 0.002],\n",
       "        [ 0.022],\n",
       "        [ 0.05 ],\n",
       "        [ 0.042],\n",
       "        [-0.04 ],\n",
       "        [ 0.016],\n",
       "        [-0.027],\n",
       "        [ 0.007],\n",
       "        [-0.034],\n",
       "        [-0.022],\n",
       "        [-0.046],\n",
       "        [-0.012],\n",
       "        [ 0.036],\n",
       "        [-0.021],\n",
       "        [-0.053],\n",
       "        [-0.052],\n",
       "        [ 0.012],\n",
       "        [-0.013],\n",
       "        [ 0.024],\n",
       "        [-0.04 ],\n",
       "        [-0.038],\n",
       "        [-0.041],\n",
       "        [ 0.03 ],\n",
       "        [ 0.021],\n",
       "        [-0.038],\n",
       "        [-0.037],\n",
       "        [-0.026],\n",
       "        [-0.015],\n",
       "        [ 0.054],\n",
       "        [ 0.043],\n",
       "        [ 0.049],\n",
       "        [ 0.017],\n",
       "        [-0.045],\n",
       "        [ 0.03 ],\n",
       "        [-0.006],\n",
       "        [-0.033],\n",
       "        [-0.029],\n",
       "        [ 0.047],\n",
       "        [ 0.009],\n",
       "        [-0.033],\n",
       "        [-0.02 ],\n",
       "        [ 0.047],\n",
       "        [-0.019],\n",
       "        [-0.041],\n",
       "        [ 0.01 ],\n",
       "        [-0.018],\n",
       "        [-0.014],\n",
       "        [ 0.038],\n",
       "        [-0.003],\n",
       "        [ 0.046],\n",
       "        [-0.041],\n",
       "        [-0.046],\n",
       "        [ 0.006],\n",
       "        [-0.032],\n",
       "        [-0.018],\n",
       "        [-0.014],\n",
       "        [-0.045],\n",
       "        [-0.009],\n",
       "        [ 0.007],\n",
       "        [ 0.   ],\n",
       "        [ 0.036],\n",
       "        [ 0.015],\n",
       "        [-0.02 ],\n",
       "        [-0.024],\n",
       "        [-0.018],\n",
       "        [-0.035],\n",
       "        [ 0.021],\n",
       "        [-0.029],\n",
       "        [-0.027],\n",
       "        [-0.016],\n",
       "        [-0.021],\n",
       "        [ 0.011],\n",
       "        [-0.008],\n",
       "        [ 0.024],\n",
       "        [ 0.03 ],\n",
       "        [-0.034],\n",
       "        [ 0.028],\n",
       "        [-0.023],\n",
       "        [-0.005],\n",
       "        [-0.048],\n",
       "        [ 0.001],\n",
       "        [ 0.011],\n",
       "        [-0.024],\n",
       "        [ 0.026],\n",
       "        [ 0.028],\n",
       "        [-0.034],\n",
       "        [-0.052],\n",
       "        [ 0.028],\n",
       "        [ 0.034],\n",
       "        [ 0.015],\n",
       "        [ 0.037],\n",
       "        [-0.02 ],\n",
       "        [ 0.044],\n",
       "        [ 0.006],\n",
       "        [ 0.049],\n",
       "        [ 0.027],\n",
       "        [ 0.041],\n",
       "        [-0.013],\n",
       "        [-0.052],\n",
       "        [ 0.046],\n",
       "        [-0.021],\n",
       "        [-0.039],\n",
       "        [-0.034],\n",
       "        [ 0.028],\n",
       "        [-0.043],\n",
       "        [-0.028],\n",
       "        [ 0.033],\n",
       "        [ 0.002],\n",
       "        [ 0.01 ],\n",
       "        [ 0.02 ],\n",
       "        [ 0.045],\n",
       "        [ 0.007],\n",
       "        [-0.047],\n",
       "        [ 0.03 ],\n",
       "        [-0.029],\n",
       "        [ 0.032],\n",
       "        [-0.009],\n",
       "        [ 0.047],\n",
       "        [ 0.03 ],\n",
       "        [-0.037],\n",
       "        [-0.024],\n",
       "        [ 0.004],\n",
       "        [ 0.003],\n",
       "        [-0.01 ],\n",
       "        [-0.033],\n",
       "        [-0.012],\n",
       "        [-0.031],\n",
       "        [-0.009],\n",
       "        [-0.045],\n",
       "        [-0.026]], dtype=float32)>,\n",
       " <tf.Variable 'time_distributed_1/kernel:0' shape=(1000, 4288) dtype=float32, numpy=\n",
       " array([[ 0.021, -0.034, -0.016, ..., -0.008, -0.034,  0.022],\n",
       "        [ 0.039, -0.027,  0.01 , ..., -0.036, -0.021,  0.025],\n",
       "        [ 0.033, -0.007,  0.014, ...,  0.011, -0.003,  0.02 ],\n",
       "        ...,\n",
       "        [ 0.007, -0.009,  0.013, ..., -0.045, -0.027, -0.036],\n",
       "        [ 0.028, -0.048,  0.007, ..., -0.031, -0.019, -0.039],\n",
       "        [-0.004, -0.012, -0.025, ..., -0.011,  0.025,  0.037]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'time_distributed_1/bias:0' shape=(4288,) dtype=float32, numpy=array([ 0.006, -0.021,  0.016, ..., -0.017, -0.017, -0.023], dtype=float32)>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_7/embeddings:0' shape=(17306, 500) dtype=float32, numpy=\n",
       " array([[ 0.013, -0.02 ,  0.029, ...,  0.008,  0.011,  0.028],\n",
       "        [-0.012, -0.05 ,  0.037, ..., -0.004, -0.001,  0.033],\n",
       "        [-0.048, -0.029,  0.036, ...,  0.021,  0.014,  0.009],\n",
       "        ...,\n",
       "        [-0.032, -0.048, -0.03 , ...,  0.025,  0.032, -0.037],\n",
       "        [ 0.003,  0.043,  0.035, ...,  0.019, -0.008,  0.032],\n",
       "        [ 0.048, -0.002,  0.006, ...,  0.021,  0.022, -0.029]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_9/kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.01 ,  0.034,  0.046, ..., -0.048, -0.033, -0.022],\n",
       "        [ 0.023, -0.04 ,  0.047, ..., -0.039, -0.003,  0.007],\n",
       "        [ 0.013,  0.006,  0.046, ..., -0.024,  0.01 ,  0.047],\n",
       "        ...,\n",
       "        [-0.029,  0.015,  0.007, ...,  0.013, -0.018, -0.003],\n",
       "        [ 0.022,  0.006,  0.034, ..., -0.019,  0.007,  0.01 ],\n",
       "        [ 0.004,  0.009, -0.044, ..., -0.017, -0.044, -0.016]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_9/recurrent_kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.014, -0.009, -0.051, ...,  0.035, -0.019, -0.008],\n",
       "        [-0.034,  0.04 , -0.02 , ...,  0.023,  0.046,  0.004],\n",
       "        [ 0.006, -0.028,  0.003, ...,  0.026, -0.016, -0.015],\n",
       "        ...,\n",
       "        [ 0.006,  0.006,  0.012, ...,  0.002,  0.003, -0.002],\n",
       "        [-0.049, -0.007, -0.023, ...,  0.017, -0.019,  0.002],\n",
       "        [-0.022, -0.009,  0.012, ..., -0.012,  0.022,  0.017]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_9/bias:0' shape=(2000,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'lstm_1_6/kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.013,  0.001, -0.012, ..., -0.023,  0.018,  0.034],\n",
       "        [ 0.037,  0.036, -0.022, ..., -0.013,  0.021,  0.038],\n",
       "        [ 0.012,  0.018,  0.008, ..., -0.015, -0.006, -0.007],\n",
       "        ...,\n",
       "        [ 0.045,  0.001,  0.039, ...,  0.002,  0.002,  0.023],\n",
       "        [ 0.006, -0.007, -0.043, ...,  0.019, -0.034,  0.048],\n",
       "        [-0.045, -0.004,  0.014, ..., -0.038, -0.009,  0.029]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_1_6/recurrent_kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[-0.013, -0.031, -0.021, ...,  0.031, -0.007,  0.06 ],\n",
       "        [-0.022,  0.013,  0.015, ...,  0.019, -0.012, -0.028],\n",
       "        [-0.018,  0.017, -0.027, ...,  0.028, -0.002,  0.003],\n",
       "        ...,\n",
       "        [-0.013,  0.012, -0.027, ..., -0.06 ,  0.009, -0.022],\n",
       "        [ 0.011,  0.009, -0.011, ..., -0.008, -0.007, -0.017],\n",
       "        [-0.003, -0.016, -0.02 , ..., -0.013,  0.015,  0.03 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_1_6/bias:0' shape=(2000,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'lstm_2_6/kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.032, -0.021,  0.028, ...,  0.01 , -0.028, -0.038],\n",
       "        [-0.045, -0.014,  0.009, ...,  0.005, -0.007,  0.032],\n",
       "        [-0.015,  0.019, -0.026, ...,  0.016, -0.013,  0.027],\n",
       "        ...,\n",
       "        [ 0.041,  0.026, -0.019, ..., -0.002, -0.034, -0.01 ],\n",
       "        [ 0.027,  0.042, -0.036, ...,  0.014,  0.046, -0.027],\n",
       "        [ 0.033,  0.   ,  0.032, ...,  0.017, -0.037, -0.026]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_2_6/recurrent_kernel:0' shape=(500, 2000) dtype=float32, numpy=\n",
       " array([[ 0.046,  0.041,  0.013, ..., -0.019, -0.028, -0.013],\n",
       "        [-0.002, -0.016, -0.008, ...,  0.029,  0.009, -0.012],\n",
       "        [ 0.012,  0.014, -0.003, ...,  0.022, -0.018, -0.01 ],\n",
       "        ...,\n",
       "        [ 0.021, -0.02 , -0.03 , ...,  0.007,  0.003, -0.006],\n",
       "        [ 0.038,  0.013, -0.002, ...,  0.001,  0.021,  0.014],\n",
       "        [ 0.008,  0.009,  0.002, ...,  0.013, -0.007,  0.019]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'lstm_2_6/bias:0' shape=(2000,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器与解码器的推理模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, encoder_model, decoder_model = build_model(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = label_word2index['bos']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = label_index2word[sampled_token_index]\n",
    "        \n",
    "        if sampled_token != 'eos':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "        if sampled_token == 'eos' or len(decoded_sentence.split()) >= (max_len_summary-1):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        e_h, e_c = h, c\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: percent eating real food along sawdust chicken hearts still feed eating twice day 1 3 cup total eating three times day 5 8 cup total eats morning walks away eats hours later looks dinner twelve hours initial feeding knocking things dad papers desk deliberately spilled water floor incredible feel bad long really thought dramatic whatever genuinely hungry eating real food cat favor buy food made real ingredients things would eat wellness halo innova evo whatever figure please feed cat garbage\n",
      "Original summary: food is empty leaves your cat always more\n",
      "Predict summary:  put them tart grounds tart donuts starting five metallic\n",
      "\n",
      "\n",
      "Review: like smoked sweet paprika better styles sweet paprika came fresh reasonable price\n",
      "Original summary: smoked paprika\n",
      "Predict summary:  completely german sale completely jolokia noisy her her her\n",
      "\n",
      "\n",
      "Review: caribou coffees weak one delicious exception right revv emeril bold van houtte eclipse dark bold coffee without tasting burned bitter\n",
      "Original summary: wonderful dark coffee\n",
      "Predict summary:  completely german sale completely jolokia noisy her her her\n",
      "\n",
      "\n",
      "Review: simple wheat pale malt light ale 1 1 fermented 60 62 give take grain bottle week concerned haze cracked day get taste extremely clean taste every single grain malt hop much maybe 15 tops nice beer blow tube mandatory next project 1 american wheat blew 5 gallons 6 gallon carboy wanted enough space 10 gallons want absolutely crisp clean yeast produces lager like beers tolerate temps 55 seems really malt nice yeast like little yeast profile know love impressed clean\n",
      "Original summary: close to lager from an as it gets\n",
      "Predict summary:  put them grounds tart grounds tart donuts starting five\n",
      "\n",
      "\n",
      "Review: know nothing co2 method decaffeinating thought would give try usually buy swiss water processed wonderful chocolatey taste also claimed 99 9 caffein free hopefully true really best tried decaf\n",
      "Original summary: delicious chocolatey taste\n",
      "Predict summary:  completely her her her cheap said consistent her topping\n",
      "\n",
      "\n",
      "Review: intrigued particular blend got exotic name disappointed ever slight coconut aftertaste makes delicious like strong coffee perfect husband get send regularly one favorites second jamaica crazy wolfgang puck wolfgang much tastier brands\n",
      "Original summary: wonderfully yummy\n",
      "Predict summary:  completely her her her cheap said consistent her topping\n",
      "\n",
      "\n",
      "Review: turned fantastic little sweeter expecting still great may even consider dessert wine nice using cornucopia kits come complete supplies need corks labels toppers etc use distilled water making wine dont want chance anything else always turned great give try\n",
      "Original summary: white pear delight\n",
      "Predict summary:  completely her her her cheap toasty kick vickie vickie\n",
      "\n",
      "\n",
      "Review: best tasting pancake mix market easy make\n",
      "Original summary: great tasting pancake mix\n",
      "Predict summary:  completely german sale completely jolokia german sale bank aware\n",
      "\n",
      "\n",
      "Review: great real coconut young coconut taste usual overwhelming sweet taste seen coconut water canned drinks good environment made brazil even better really taste fruit labelled product besides coconut water taste\n",
      "Original summary: great taste nice fruit flavor serve\n",
      "Predict summary:  completely her her her cheap said consistent strawberry wallop\n",
      "\n",
      "\n",
      "Review: good bars gluten free favorite bar everything carry still good keep around hunger attack really want try something great try coconut cashew incredible like naughty\n",
      "Original summary: good for on the go\n",
      "Predict summary:  completely her her her cheap said consistent her topping\n",
      "\n",
      "\n",
      "Review: best potato chips money buy enough salt taste much lingering awesomeness bag chip perfect thickness teeth get excited every time put one mouth everything chips perfect like made god delivered know amazon carries even leave house buy may never eat anything else\n",
      "Original summary: lightly salted delicious\n",
      "Predict summary:  completely her her her cheap said consistent her topping\n",
      "\n",
      "\n",
      "Review: tastes good fried bad tastes good eat course lot great healthier snacks\n",
      "Original summary: these tastes pretty good\n",
      "Predict summary:  completely german sale completely jolokia german sale pretzels crisco\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, valid in enumerate(paded_valid_seq):\n",
    "    print(f\"Review: {train_tokenizer.sequences_to_texts([valid])[0]}\")\n",
    "    target = label_tokenizer.sequences_to_texts([paded_valid_label_seq[index]])\n",
    "    print(f\"Original summary: {' '.join(target[0].split()[1:-1])}\")\n",
    "    result = decode_sequence(valid.reshape(1, max_len_text))\n",
    "    print(f\"Predict summary: {result}\")\n",
    "    print('\\n')\n",
    "    if index > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
