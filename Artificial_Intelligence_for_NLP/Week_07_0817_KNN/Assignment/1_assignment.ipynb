{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-07 First Step of using machine learning and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from pyltp import Segmentor\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: 数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请在课程的GitHub中下载数据集，然后使用pandas进行读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"D:\\\\Github\\\\NLP\\\\Artificial_Intelligence_for_NLP\\\\Week_05_0803_pyltp\\\\sqlResult_1558435.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fname, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>feature</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>快科技@http://www.kkj.cn/</td>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "      <td>{\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...</td>\n",
       "      <td>小米MIUI 9首批机型曝光：共计15款</td>\n",
       "      <td>http://www.cnbeta.com/articles/tech/623597.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id author                  source  \\\n",
       "0  89617    NaN  快科技@http://www.kkj.cn/   \n",
       "\n",
       "                                             content  \\\n",
       "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...   \n",
       "\n",
       "                                             feature                 title  \\\n",
       "0  {\"type\":\"科技\",\"site\":\"cnbeta\",\"commentNum\":\"37\"...  小米MIUI 9首批机型曝光：共计15款   \n",
       "\n",
       "                                              url  \n",
       "0  http://www.cnbeta.com/articles/tech/623597.htm  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89611"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xinhua_news = data[data.source == '新华社']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8778051801676133"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xinhua_news) / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "报社等相关的机构，往往会遇到一个问题，就是别人家的机构使用自己的文章但是并没有标明来源。 在本次任务中，我们将解决新华社的文章被抄袭引用的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定的数据集合中，存在一些新闻预料，该预料是来自新华社，但是其来源并不是新华社，请设计技巧学习模型解决该问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1566105348906&di=ee9a2de91207767364853d4decc6cca3&imgtype=0&src=http%3A%2F%2Fmmbiz.qpic.cn%2Fmmbiz_png%2FTicO2kbP6Ao5sCsSQDpehZiczLdC6hDCNvoicjcOCEKX2bLxBc9gVOw28zHyFibfIWq9ceRibP6HDTKReGkr6YyTfQQ%2F640%3Fwx_fmt%3Dpng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将pandas中的数据，依据是否是新华社的文章，请改变成新的数据dataframe: <content, y>, 其中，content是文章内容，y是0或者1. 你可能要使用到pandas的dataframe操作。[reference](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = (data.source == '新华社').astype(int)\n",
    "content = data.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.DataFrame({'content':content, 'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>（原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...      0\n",
       "1  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...      0\n",
       "2  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...      0\n",
       "3    这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n      1\n",
       "4  （原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: 使用tfidf进行文本向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新闻内容切词整理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltp_model_path = \"D:\\\\Github\\\\NLP\\\\Projects\\\\data\\\\ltp_data_v3.4.0\"\n",
    "segmentor_model_path = os.path.join(ltp_model_path, 'cws.model')\n",
    "segmentor = Segmentor()\n",
    "segmentor.load(segmentor_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltp_cut(document):\n",
    "    result = ''\n",
    "    if isinstance(document, str):\n",
    "        words = segmentor.segment(document)\n",
    "        words = [re.findall('\\d*\\w+', x) for x in words]\n",
    "        result = ' '.join([x[0] for x in words if x and x[0] !='n'])  # pyltp会把换行符\\n给分开\n",
    "        return result if result else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切词保存数据，这一步还是要花几分钟的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_new['content_cut'] = data_new.content.apply(lambda i: ltp_cut(i))\n",
    "data_new.to_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_col 参数不可省略，否则会出现未命名列\n",
    "df = pd.read_csv('cleaned_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 nan 无数据行\n",
    "df.dropna(inplace=True)\n",
    "# 重置索引为连续\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86863"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>content_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86858</th>\n",
       "      <td>新华社照片，多伦多，2017年6月7日\\n（体育）（2）冰球——国家女子冰球队海外选秀在多伦...</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社 照片 多伦多 2017年 6月 7日 体育 2 冰球 国家 女子 冰球队 海外 选秀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86859</th>\n",
       "      <td>新华社兰州6月3日电（王衡、徐丹）记者从甘肃省交通运输厅获悉，甘肃近日集中开建高速公路、普通...</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社 兰州 6月 3日 电 王衡 徐丹 记者 从 甘肃省 交通 运输厅 获悉 甘肃 近日 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86860</th>\n",
       "      <td>\\n\\n2017年5月29日，在法国巴黎郊外的凡尔赛宫，法国总统马克龙出席新闻发布会。（新华...</td>\n",
       "      <td>1</td>\n",
       "      <td>n2017 年 5月 29日 在 法国 巴黎 郊外 的 凡尔赛宫 法国 总统 马克龙 出席 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86861</th>\n",
       "      <td>\\n\\n2017年5月25日，在美国马萨诸塞州剑桥市，哈佛大学毕业生在毕业典礼上欢呼。（新华...</td>\n",
       "      <td>1</td>\n",
       "      <td>n2017 年 5月 25日 在 美国 马萨诸塞州 剑桥市 哈佛 大学 毕业生 在 毕业 典...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86862</th>\n",
       "      <td>新华社德国杜塞尔多夫６月６日电题：乒乓女球迷　\\n　　新华社记者王子江、张寒\\n　　熊老...</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社 德国 杜塞尔多夫 ６月 ６日 电 题 乒乓 女 球迷 新华社 记者 王子江 张寒 熊...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label  \\\n",
       "86858  新华社照片，多伦多，2017年6月7日\\n（体育）（2）冰球——国家女子冰球队海外选秀在多伦...      1   \n",
       "86859  新华社兰州6月3日电（王衡、徐丹）记者从甘肃省交通运输厅获悉，甘肃近日集中开建高速公路、普通...      1   \n",
       "86860  \\n\\n2017年5月29日，在法国巴黎郊外的凡尔赛宫，法国总统马克龙出席新闻发布会。（新华...      1   \n",
       "86861  \\n\\n2017年5月25日，在美国马萨诸塞州剑桥市，哈佛大学毕业生在毕业典礼上欢呼。（新华...      1   \n",
       "86862  　　新华社德国杜塞尔多夫６月６日电题：乒乓女球迷　\\n　　新华社记者王子江、张寒\\n　　熊老...      1   \n",
       "\n",
       "                                             content_cut  \n",
       "86858  新华社 照片 多伦多 2017年 6月 7日 体育 2 冰球 国家 女子 冰球队 海外 选秀...  \n",
       "86859  新华社 兰州 6月 3日 电 王衡 徐丹 记者 从 甘肃省 交通 运输厅 获悉 甘肃 近日 ...  \n",
       "86860  n2017 年 5月 29日 在 法国 巴黎 郊外 的 凡尔赛宫 法国 总统 马克龙 出席 ...  \n",
       "86861  n2017 年 5月 25日 在 美国 马萨诸塞州 剑桥市 哈佛 大学 毕业生 在 毕业 典...  \n",
       "86862  新华社 德国 杜塞尔多夫 ６月 ６日 电 题 乒乓 女 球迷 新华社 记者 王子江 张寒 熊...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定一定数量的feature，tfidf值小于前该数量的词汇，其tfidf值设置为 0\n",
    "vectorized = TfidfVectorizer(max_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorized.fit_transform(df.content_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86863, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    78472\n",
       "0     8391\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scipy库中consine的实现为：$$cosine(u, v) = 1 - \\frac{u \\cdot v}{||u||_2 ||v||_2}$$  取值范围[0, 2];因此这个函数的结果越小说明越相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: 参考scikit-learning的方法，构建你的第一个机器学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 按照课程讲解的内容，把数据集分割为 traning_data, validation_data, test_data. [reference](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86863,), (86863, 200))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52117, 200), (52117,), (17373, 200), (17373,), (17373, 200), (17373,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain,Xtest, ytrain, ytest = train_test_split(X, y, test_size=.2)\n",
    "Xtrain, Xcv, ytrain, ycv = train_test_split(Xtrain, ytrain, test_size=.25)\n",
    "Xtrain.shape,ytrain.shape, Xcv.shape, ycv.shape, Xtest.shape , ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 参照scikit learning的示例，构建你的第一个KNN机器学习模型。[reference](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5-6: 在traning_data, validation_data, test_data 上观察其相关metric: recall, precision, f1等， 并解释其含义. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision:预测正样本的能力。\n",
    "\n",
    "recall:正确找出正样本的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n",
    "慢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92672537846083"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNC()\n",
    "clf.fit(Xtrain, ytrain)\n",
    "clf.score(Xcv, ycv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59      1651\n",
      "           1       0.95      0.97      0.96     15722\n",
      "\n",
      "    accuracy                           0.93     17373\n",
      "   macro avg       0.80      0.75      0.77     17373\n",
      "weighted avg       0.92      0.93      0.92     17373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非新华社文章的判准率很低，即找出非新华社文章的效果不理想，很多非新华社文章被判为新华社文章。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression\n",
    "快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9717953145685835, 0.9709894664134001)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_clf = LogisticRegression(solver='lbfgs')\n",
    "logi_clf.fit(Xtrain, ytrain)\n",
    "logi_clf.score(Xcv, ycv), logi_clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84      1651\n",
      "           1       0.98      0.99      0.98     15722\n",
      "\n",
      "    accuracy                           0.97     17373\n",
      "   macro avg       0.94      0.88      0.91     17373\n",
      "weighted avg       0.97      0.97      0.97     17373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred_logi = logi_clf.predict(Xtest)\n",
    "print(classification_report(ytest, ypred_logi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表现中等，作备选，如果KNN表现不如意的话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7: 调整不同的参数，观察变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 默认参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92672537846083"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNC()\n",
    "clf.fit(Xtrain, ytrain)\n",
    "clf.score(Xcv, ycv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59      1651\n",
      "           1       0.95      0.97      0.96     15722\n",
      "\n",
      "    accuracy                           0.93     17373\n",
      "   macro avg       0.80      0.75      0.77     17373\n",
      "weighted avg       0.92      0.93      0.92     17373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调整weights 'uniform' --> 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9320209520520347"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNC(weights='distance')\n",
    "clf.fit(Xtrain, ytrain)\n",
    "clf.score(Xcv, ycv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62      1651\n",
      "           1       0.96      0.97      0.96     15722\n",
      "\n",
      "    accuracy                           0.93     17373\n",
      "   macro avg       0.82      0.77      0.79     17373\n",
      "weighted avg       0.93      0.93      0.93     17373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(Xtest)\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非新华社文章的判准率还是很低，比一般LogisticRegression表现都差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调整Tfidf的文章向量数，200 --> 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86863, 800)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定一定数量的feature，tfidf值小于前该数量的词汇，其tfidf值设置为 0\n",
    "vectorized = TfidfVectorizer(max_features=800)\n",
    "X = vectorized.fit_transform(df.content_cut)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存文章向量到df中，供选作部分计算相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_vector'] = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>content_cut</th>\n",
       "      <th>doc_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86858</th>\n",
       "      <td>新华社照片，多伦多，2017年6月7日\\n（体育）（2）冰球——国家女子冰球队海外选秀在多伦...</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社 照片 多伦多 2017年 6月 7日 体育 2 冰球 国家 女子 冰球队 海外 选秀...</td>\n",
       "      <td>(0, 53)\\t0.17924403286136195\\n  (0, 48)\\t0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86859</th>\n",
       "      <td>新华社兰州6月3日电（王衡、徐丹）记者从甘肃省交通运输厅获悉，甘肃近日集中开建高速公路、普通...</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社 兰州 6月 3日 电 王衡 徐丹 记者 从 甘肃省 交通 运输厅 获悉 甘肃 近日 ...</td>\n",
       "      <td>(0, 369)\\t0.189599286645538\\n  (0, 326)\\t0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86860</th>\n",
       "      <td>\\n\\n2017年5月29日，在法国巴黎郊外的凡尔赛宫，法国总统马克龙出席新闻发布会。（新华...</td>\n",
       "      <td>1</td>\n",
       "      <td>n2017 年 5月 29日 在 法国 巴黎 郊外 的 凡尔赛宫 法国 总统 马克龙 出席 ...</td>\n",
       "      <td>(0, 548)\\t0.05804414816418204\\n  (0, 34)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86861</th>\n",
       "      <td>\\n\\n2017年5月25日，在美国马萨诸塞州剑桥市，哈佛大学毕业生在毕业典礼上欢呼。（新华...</td>\n",
       "      <td>1</td>\n",
       "      <td>n2017 年 5月 25日 在 美国 马萨诸塞州 剑桥市 哈佛 大学 毕业生 在 毕业 典...</td>\n",
       "      <td>(0, 519)\\t0.06651730113974776\\n  (0, 48)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86862</th>\n",
       "      <td>新华社德国杜塞尔多夫６月６日电题：乒乓女球迷　\\n　　新华社记者王子江、张寒\\n　　熊老...</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社 德国 杜塞尔多夫 ６月 ６日 电 题 乒乓 女 球迷 新华社 记者 王子江 张寒 熊...</td>\n",
       "      <td>(0, 798)\\t0.0426538919698091\\n  (0, 794)\\t0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label  \\\n",
       "86858  新华社照片，多伦多，2017年6月7日\\n（体育）（2）冰球——国家女子冰球队海外选秀在多伦...      1   \n",
       "86859  新华社兰州6月3日电（王衡、徐丹）记者从甘肃省交通运输厅获悉，甘肃近日集中开建高速公路、普通...      1   \n",
       "86860  \\n\\n2017年5月29日，在法国巴黎郊外的凡尔赛宫，法国总统马克龙出席新闻发布会。（新华...      1   \n",
       "86861  \\n\\n2017年5月25日，在美国马萨诸塞州剑桥市，哈佛大学毕业生在毕业典礼上欢呼。（新华...      1   \n",
       "86862  　　新华社德国杜塞尔多夫６月６日电题：乒乓女球迷　\\n　　新华社记者王子江、张寒\\n　　熊老...      1   \n",
       "\n",
       "                                             content_cut  \\\n",
       "86858  新华社 照片 多伦多 2017年 6月 7日 体育 2 冰球 国家 女子 冰球队 海外 选秀...   \n",
       "86859  新华社 兰州 6月 3日 电 王衡 徐丹 记者 从 甘肃省 交通 运输厅 获悉 甘肃 近日 ...   \n",
       "86860  n2017 年 5月 29日 在 法国 巴黎 郊外 的 凡尔赛宫 法国 总统 马克龙 出席 ...   \n",
       "86861  n2017 年 5月 25日 在 美国 马萨诸塞州 剑桥市 哈佛 大学 毕业生 在 毕业 典...   \n",
       "86862  新华社 德国 杜塞尔多夫 ６月 ６日 电 题 乒乓 女 球迷 新华社 记者 王子江 张寒 熊...   \n",
       "\n",
       "                                              doc_vector  \n",
       "86858    (0, 53)\\t0.17924403286136195\\n  (0, 48)\\t0.1...  \n",
       "86859    (0, 369)\\t0.189599286645538\\n  (0, 326)\\t0.1...  \n",
       "86860    (0, 548)\\t0.05804414816418204\\n  (0, 34)\\t0....  \n",
       "86861    (0, 519)\\t0.06651730113974776\\n  (0, 48)\\t0....  \n",
       "86862    (0, 798)\\t0.0426538919698091\\n  (0, 794)\\t0....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86863, 800), (86863,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = X.toarray()\n",
    "y = df.label\n",
    "X2.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_split(X, y):\n",
    "    Xtrain,Xtest, ytrain, ytest = train_test_split(X, y, test_size=.2)\n",
    "    Xtrain, Xcv, ytrain, ycv = train_test_split(Xtrain, ytrain, test_size=.25)\n",
    "    return Xtrain,ytrain, Xcv, ycv, Xtest , ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52117, 800), (52117,), (17373, 800), (17373,), (17373, 800), (17373,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, ytrain, Xcv, ycv, Xtest, ytest = corpus_split(X2, y)\n",
    "Xtrain.shape,ytrain.shape, Xcv.shape, ycv.shape, Xtest.shape , ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9118747481724515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNC(weights='distance')\n",
    "clf.fit(Xtrain, ytrain)\n",
    "clf.score(Xcv, ycv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.68      0.60      1699\n",
      "           1       0.96      0.94      0.95     15674\n",
      "\n",
      "    accuracy                           0.91     17373\n",
      "   macro avg       0.75      0.81      0.77     17373\n",
      "weighted avg       0.92      0.91      0.92     17373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN实在是太慢了，打算用Logistics进行参数调优。\n",
    "\n",
    "判0准确率低的结果是：如果以步骤9为判断依据即判为1但实际为0则为抄袭者，因为很多0被误判为1，而又以预判结果反推来源，将导致很多文章误判为抄袭。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9711045875784263, 0.9707016635008346)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_clf = LogisticRegression(solver='lbfgs')\n",
    "logi_clf.fit(Xtrain, ytrain)\n",
    "logi_clf.score(Xcv, ycv), logi_clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_logi = logi_clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      1699\n",
      "           1       0.97      0.99      0.98     15674\n",
      "\n",
      "    accuracy                           0.97     17373\n",
      "   macro avg       0.95      0.88      0.91     17373\n",
      "weighted avg       0.97      0.97      0.97     17373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred_logi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本向量大小貌似对结果影响不大。\n",
    "\n",
    "判0的召回率低，意味着当0为positive时，预测结果与实际结果同为0的例数占实际结果的比例偏低，即实际为0，成功预测为0的比例偏低。\n",
    "召回率低而精确度高，意味着在判为0的结果中，混入少部分被误判为0的1数据，而正确判0的数据，只占实际为0的数据一小部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step8: 不断改变参数，直到性能达到“某个”点。问：“某个”怎么定义？\n",
    "训练集的误差会随着训练逐渐减少，验证集的误差会随着模型调整出现先减小，后上升的过程，转折点为模型开始出现过拟合的时刻。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用GridSearchCV寻找模型最优参数时，数据可以只分train和test，因为传入参数的train会被GridSearchCV分成train和CV两部分进行参数最优寻找。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C':[.01, .03, .1, .3, 1, 3, 10], 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "clf_logi = LogisticRegression(solver='lbfgs')\n",
    "clf = GridSearchCV(clf_logi, params, cv=5)\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12.122041</td>\n",
       "      <td>0.487327</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>10</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.980622</td>\n",
       "      <td>0.983404</td>\n",
       "      <td>0.984459</td>\n",
       "      <td>0.981579</td>\n",
       "      <td>0.981002</td>\n",
       "      <td>0.982213</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.806591</td>\n",
       "      <td>0.156656</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.980622</td>\n",
       "      <td>0.983404</td>\n",
       "      <td>0.984459</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.981002</td>\n",
       "      <td>0.982194</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.363001</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>10</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'solver': 'liblinear'}</td>\n",
       "      <td>0.980526</td>\n",
       "      <td>0.983404</td>\n",
       "      <td>0.984459</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>0.981002</td>\n",
       "      <td>0.982213</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14.128601</td>\n",
       "      <td>1.809070</td>\n",
       "      <td>0.016202</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>10</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 10, 'solver': 'sag'}</td>\n",
       "      <td>0.980526</td>\n",
       "      <td>0.983404</td>\n",
       "      <td>0.984459</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>0.981002</td>\n",
       "      <td>0.982213</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>22.189801</td>\n",
       "      <td>0.604848</td>\n",
       "      <td>0.016202</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>10</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'solver': 'saga'}</td>\n",
       "      <td>0.980622</td>\n",
       "      <td>0.983404</td>\n",
       "      <td>0.984459</td>\n",
       "      <td>0.981579</td>\n",
       "      <td>0.981002</td>\n",
       "      <td>0.982213</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "30      12.122041      0.487327         0.019001        0.000633      10   \n",
       "31       4.806591      0.156656         0.017799        0.000749      10   \n",
       "32       1.363001      0.013709         0.017002        0.000631      10   \n",
       "33      14.128601      1.809070         0.016202        0.000399      10   \n",
       "34      22.189801      0.604848         0.016202        0.000746      10   \n",
       "\n",
       "   param_solver                            params  split0_test_score  \\\n",
       "30    newton-cg  {'C': 10, 'solver': 'newton-cg'}           0.980622   \n",
       "31        lbfgs      {'C': 10, 'solver': 'lbfgs'}           0.980622   \n",
       "32    liblinear  {'C': 10, 'solver': 'liblinear'}           0.980526   \n",
       "33          sag        {'C': 10, 'solver': 'sag'}           0.980526   \n",
       "34         saga       {'C': 10, 'solver': 'saga'}           0.980622   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "30           0.983404           0.984459           0.981579   \n",
       "31           0.983404           0.984459           0.981483   \n",
       "32           0.983404           0.984459           0.981675   \n",
       "33           0.983404           0.984459           0.981675   \n",
       "34           0.983404           0.984459           0.981579   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "30           0.981002         0.982213        0.001474                1  \n",
       "31           0.981002         0.982194        0.001483                5  \n",
       "32           0.981002         0.982213        0.001488                1  \n",
       "33           0.981002         0.982213        0.001488                1  \n",
       "34           0.981002         0.982213        0.001474                1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'solver': 'newton-cg'}, 0.9822130974538058)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9827893858285845, 0.983652794566281)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_clf = LogisticRegression(C=10, solver='newton-cg')\n",
    "logi_clf.fit(Xtrain, ytrain)\n",
    "logi_clf.score(Xcv, ycv), logi_clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      1699\n",
      "           1       0.99      0.99      0.99     15674\n",
      "\n",
      "    accuracy                           0.98     17373\n",
      "   macro avg       0.96      0.94      0.95     17373\n",
      "weighted avg       0.98      0.98      0.98     17373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = logi_clf.predict(Xtest)\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非新华社文章的判准率还行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step9: 找出所有预测为 1， 但是实际为 0 的文章。 作为抄袭的候选者。\n",
    "这个标准需要有较高的判0 f1分数支持，否则会出现过多误判的文章。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      8391\n",
      "           1       0.99      0.99      0.99     78472\n",
      "\n",
      "    accuracy                           0.99     86863\n",
      "   macro avg       0.97      0.95      0.96     86863\n",
      "weighted avg       0.99      0.99      0.99     86863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = logi_clf.predict(X2)\n",
    "print(classification_report(y, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定用LogisticRegression模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 异或找出所有预测和实际不同的结果，再和预测相与，得到的结果中为1的即为预测为1，实际为0的索引\n",
    "result = (y ^ ypred) & ypred\n",
    "index = np.ravel(np.argwhere(result))\n",
    "[(ypred[i], y[i]) for i in index][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [df.content[i] for i in index]\n",
    "candidates_clean = [df.content_cut[i] for i in index]\n",
    "candidates_vector = [df.doc_vector[i] for i in index]\n",
    "choice = np.random.choice(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('新华社北京6月19日电（记者 许可）金砖国家外长会晤19日在北京钓鱼台国宾馆举行。外交部长王毅主持会晤，南非国际关系与合作部长马沙巴内、巴西外长努内斯、俄罗斯外长拉夫罗夫、印度外交国务部长辛格出席。\\r\\n王毅表示，金砖合作机制成立十年来，在五国领导人有力指引下，各方秉持开放、包容、合作、共赢的金砖精神，推动金砖合作从无到有，由浅入深，取得长足发展。五国经济总量占全球比重上升，贸易投资大幅提升，在重要国际金融机构中发言权迈上新层次；合作领域全面拓展，形成全范围、宽领域、多层次的合作架构；在联合国、二十国集团等国际组织中紧密协作，维护广大发展中国家团结和利益，共同应对全球性挑战。\\r\\n王毅指出，今年是金砖国家第二个十年的开局之年，中国接任金砖国家轮值主席。中方愿同其他四国一道，继续筑牢和充实政治安全、经济金融、人文交流三大合作支柱，积极拓展更多新兴领域合作，推动金砖合作取得更多成果，开启金砖国家第二个“金色十年”。五国应深化务实合作，促进共同发展；加强全球治理，共同应对挑战；开展人文交流，夯实民意基础；推进机制建设，构建更广泛伙伴关系。\\r\\n王毅强调，金砖国家领导人第九次会晤将于9月在厦门举行，这是一次承前启后、继往开来的重要会晤，将对金砖合作的未来发展产生深远影响。中方愿同其他四国一道，积极开展相关筹备工作。\\r\\n马沙巴内、努内斯、拉夫罗夫、辛格表示，金砖国家合作强劲有力，取得重要成就。五国应继续秉持金砖精神，推动五国间合作深入发展，在全球事务中发挥更重要作用。四国高度评价中方作为金砖国家轮值主席国所做工作，承诺全力支持、配合中方筹备好领导人第九次会晤，确保会晤取得圆满成功。\\r\\n五国外长回顾总结了过去十年五国合作的成果和经验，就金砖合作下一步发展、当前国际形势和热点问题进行深入探讨。各方一致认为，金砖国家应推动新兴市场国家及发展中国家团结合作，维护和增进广大发展中国家整体利益和福祉；继续致力于维护国际公平正义、促进世界和平稳定，维护联合国在国际事务中的核心地位，推动政治解决热点问题，携手应对全球性挑战，努力构建合作共赢的新型国际关系；促进世界多极化和国际关系民主化，推动国际秩序和国际体系朝着更加公平合理方向发展，为人类社会集体繁荣进步贡献更多“金砖智慧”和“金砖方案”，为构建人类命运共同体发挥积极和建设性作用。\\r\\n会晤后，五国外长共同会见记者。\\r\\n会晤发表了《金砖国家外长会晤新闻公报》。\\r\\n',\n",
       " '新华社 北京 6月 19日 电 记者 许可 金 砖 国家 外长 会晤 19日 在 北京 钓鱼台 国宾馆 举行 外交部长 王毅 主持 会晤 南非 国际 关系 与 合作 部长 马沙巴 内 巴西 外长 努内斯 俄罗斯 外长 拉夫罗夫 印度 外交 国务 部长 辛格 出席 王毅 表示 金 砖 合作 机制 成立 十 年 来 在 五 国 领导人 有力 指引 下 各方 秉持 开放 包容 合作 共 赢 的 金 砖 精神 推动 金 砖 合作 从无到有 由 浅 入 深 取得 长足 发展 五 国 经济 总量 占 全球 比重 上升 贸易 投资 大幅 提升 在 重要 国际 金融 机构 中 发言权 迈 上 新 层次 合作 领域 全面 拓展 形成 全 范围 宽 领域 多 层次 的 合作 架构 在 联合国 二十 国 集团 等 国际 组织 中 紧密 协作 维护 广大 发展中国家 团结 和 利益 共同 应 对 全球性 挑战 王毅 指出 今年 是 金 砖 国家 第二 个 十 年 的 开局 之 年 中国 接任 金 砖 国家 轮值 主席 中方 愿 同 其他 四 国 一道 继续 筑牢 和 充实 政治 安全 经济 金融 人文 交流 三 大 合作 支柱 积极 拓展 更 多 新兴 领域 合作 推动 金 砖 合作 取得 更 多 成果 开启 金 砖 国家 第二 个 金色 十 年 五 国 应 深化 务实 合作 促进 共同 发展 加强 全球 治理 共同 应对 挑战 开展 人文 交流 夯实 民意 基础 推进 机制 建设 构建 更 广泛 伙伴 关系 王毅 强调 金 砖 国家 领导人 第九 次 会晤 将 于 9月 在 厦门 举行 这 是 一 次 承前启后 继往开来 的 重要 会晤 将 对 金 砖 合作 的 未来 发展 产生 深远 影响 中方 愿 同 其他 四 国 一道 积极 开展 相关 筹备 工作 马沙巴 内 努内斯 拉夫罗夫 辛格 表示 金 砖 国家 合作 强劲 有力 取得 重要 成就 五 国 应 继续 秉持 金 砖 精神 推动 五 国 间 合作 深入 发展 在 全球 事务 中 发挥 更 重要 作用 四 国 高度 评价 中方 作为 金 砖 国家 轮值 主席国 所 做 工作 承诺 全力 支持 配合 中方 筹备 好 领导人 第九 次 会晤 确保 会晤 取得 圆满 成功 五 国 外长 回顾 总结 了 过去 十 年 五 国 合作 的 成果 和 经验 就 金 砖 合作 下 一 步 发展 当前 国际 形势 和 热点 问题 进行 深入 探讨 各方 一致 认为 金 砖 国家 应 推动 新兴 市场 国家 及 发展中国家 团结 合作 维护 和 增进 广大 发展中国家 整体 利益 和 福祉 继续 致力 于 维护 国际 公平 正义 促进 世界 和平 稳定 维护 联合国 在 国际 事务 中 的 核心 地位 推动 政治 解决 热点 问题 携手 应 对 全球性 挑战 努力 构建 合作 共 赢 的 新型 国际 关系 促进 世界 多极化 和 国际 关系 民主化 推动 国际 秩序 和 国际 体系 朝着 更加 公平 合理 方向 发展 为 人类 社会 集体 繁荣 进步 贡献 更 多 金 砖 智慧 和 金 砖 方案 为 构建 人类 命运 共同体 发挥 积极 和 建设性 作用 会晤 后 五 国 外长 共同 会见 记者 会晤 发表 了 金 砖 国家 外长 会晤 新闻公报',\n",
       " <1x800 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 96 stored elements in Compressed Sparse Row format>,\n",
       " 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[choice], candidates_clean[choice], candidates_vector[choice], df.label[choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step10： 总结该过程，什么是数据思维？什么是机器学习思维？\n",
    "数据思维：给定模型，如何通过调整数据结构得到最优结果；\n",
    "\n",
    "机器学习思维：给定数据输入，如果通过调整参数和超参数得到最优结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional)使用第4课讲解的 edit distance，在涉嫌抄袭的文章中，找到其重复的文字与被修改过的文字。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 找出和候选文章最像的新华社文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = candidates_vector[choice].toarray()\n",
    "xinhua_news = df.doc_vector[df.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3          (0, 691)\\t0.190178084097007\\n  (0, 463)\\t0.1...\n",
       "39         (0, 691)\\t0.190178084097007\\n  (0, 463)\\t0.1...\n",
       "95         (0, 350)\\t0.12793199203520353\\n  (0, 348)\\t0...\n",
       "111        (0, 666)\\t0.10523748778563713\\n  (0, 634)\\t0...\n",
       "303        (0, 712)\\t0.11637258658237533\\n  (0, 419)\\t0...\n",
       "                               ...                        \n",
       "86858      (0, 53)\\t0.17924403286136195\\n  (0, 48)\\t0.1...\n",
       "86859      (0, 369)\\t0.189599286645538\\n  (0, 326)\\t0.1...\n",
       "86860      (0, 548)\\t0.05804414816418204\\n  (0, 34)\\t0....\n",
       "86861      (0, 519)\\t0.06651730113974776\\n  (0, 48)\\t0....\n",
       "86862      (0, 798)\\t0.0426538919698091\\n  (0, 794)\\t0....\n",
       "Name: doc_vector, Length: 78472, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xinhua_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similars(X, candidates_clean, candidates_vector, choice):\n",
    "    copy = candidates_vector[choice].toarray()\n",
    "    all_cosine = sorted([(cosine(X[i].toarray(), copy), i) for i in X.index])\n",
    "    index = all_cosine[0][1]\n",
    "    pprint(f'疑似抄袭的文章：{candidates_clean[choice]}')\n",
    "    pprint('--' * 20)\n",
    "    pprint(f'最可能被抄袭的文章：{df.content_cut[index]}')\n",
    "    pprint('**' * 50)\n",
    "    print('\\n')\n",
    "    return index, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\spatial\\distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('疑似抄袭的文章：原 标题 林郑月娥 将 香港 建设 成 朝气蓬勃 生活 富足 的 城市 新华社 香港 6月 20日 电 题 将 香港 建设 成 朝气蓬勃 '\n",
      " '生活 富足 的 城市 访 香港 特别 行政区 候任 行政 长官 林郑月娥 即将 于 7月 1日 宣誓 就职 的 香港 特区 候任 行政 长官 林郑月娥 '\n",
      " '认为 香港 回归 祖国 20 年 来 一国两制 的 成功 落实 维护 了 香港 的 繁荣 稳定 与 核心 价值 让 香港 成功 地 应对 了 困难 与 '\n",
      " '危机 林 郑月娥 步入 侯任 行政 长官 办公室 准备 接受 采访 新华社 记者 陈晔华 摄 香港 回归 祖国 20 周年 前夕 林 郑月娥 女士 在 '\n",
      " '候任 行政 长官 办公室 接受 了 新华社 记者 采访 她 表示 上任 后 将 努力 带领 特区 政府 将 香港 建设 成 国家 有 朝气 的 特别 '\n",
      " '行政区 为 市民 提供 满足 感 高 的 生活 与 香港 回归 的 两 次 结缘 1980年 加入 公职 的 林郑月娥 已经 服务 香港 市民 超过 '\n",
      " '36年 亲身 经历 并 见证 了 回归 前后 香港 的 发展 与 变迁 她 认为 过去 20 年 香港 落实 一国两制 港人治港 高度 自治 的 方针 '\n",
      " '维护 了 香港 的 繁荣 与 稳定 在 中央 的 大力 支持 下 香港 成功 处理 了 困难 与 危机 从而 能够 渡过 难关 焕发 生机 一国两制 的 '\n",
      " '落实 是 非常 成功 的 林 郑月娥 说 过去 20 年 尽管 香港 经济 发展 经历 了 起伏 但 经济 总量 累计 增长 达 82 对于 经济 社会 '\n",
      " '发展 水平 比较 高 的 经济体 而言 这 是 十分 不 容易 的 在 这 一 过程 中 一国两制 港人治港 高度 自治 的 方针 以及 香港 的 法治 '\n",
      " '自由 等 核心 价值 始终如一 这些 都 是 一国两制 的 初心 林 郑月娥 在 接受 记者 采访 新华社 记者 陈晔华 摄 林 郑月娥 曾 于 '\n",
      " '1985年 1996年 两 次 参加 中 英 联络 小组 的 工作 第一 次 是 讨论 香港 基本法 第24 条 的 有关 立法 工作 包括 签发 回归 '\n",
      " '后 新 的 香港 身份证 以及 保安 入境 等 第二 次 是 参与 编制 1997 至 1998年 财政 预算案 她 回忆 道 在 工作 中 很 高兴 '\n",
      " '结识 了 许多 内地 的 负责人 和 工作 人员 感到 大家 都 非常 专业 对 能够 参与 这项 伟大 的 事业 感到 光荣 每个 人 都 尽力 做到 '\n",
      " '最 好 能够 两 次 参与 回归 的 相关 工作 为 确保 香港 顺利 平稳 回归 作出 贡献 作为 一个 香港 人 中国 人 我 感到 很 有 意义 '\n",
      " '行政 长官 须 向 中央 和 香港 双重 负责 在 3月 举行 的 香港 特区 第五 任 行政 长官 选举 中 林郑月娥 高 票 当选 她 告诉 记者 '\n",
      " '当选 的 那 一刻 以及 后来 在 北京 从 李克强 总理 手中 接 过 中央政府 任命书 的 时候 都 感到 任重道远 她 说 香港 特区 行政 长官 '\n",
      " '既 要 向 中央政府 负责 也 要 向 香港 特区 负责 要 处理 好 中央 要求 和 香港 本地 实际 情况 这 两者 的 关系 就要 准确 地 按照 '\n",
      " '基本法 办事 因为 基本法 是 香港 的 宪制性 法律 是 行政 长官 及 特区 政府 在 香港 准确 落实 一国两制 的 依据 针对 近年来 香港 '\n",
      " '社会 出现 的 港独 言行 林郑月娥 表示 港独 在 香港 完全 没有 出路 一国两制 的 初心 和 原意 就 包含 了 香港 特别 行政区 是 国家 '\n",
      " '不可 分离 的 一 部分 并且 香港 的 回归 有利于 维护 国家 的 主权 安全 和 发展 利益 林 郑月娥 在 接受 记者 采访 时 回答 提问 '\n",
      " '新华社 记者 陈晔华 摄 我 相信 绝大部分 香港 市民 从来 没有 觉得 港独 是 一个 可以 考虑 的 方案 未来 特区 政府 将 严格 依法 办事 '\n",
      " '所有 港独 行为 都 违反 本地 法律 我们 必须 严格 执法 林郑月娥 强调 她 表示 特区 政府 还 将 做 好 教育 工作 要 向 社会 大众 '\n",
      " '说明 港独 对 香港 繁荣 稳定 的 危害性 不 能 让 港独 在 香港 传播 尤其 是 要 杜绝 港独 对 少年儿童 的 侵害 香港 情怀 国家 观念 '\n",
      " '全球 视野 林 郑月娥 在 参加 香港 第五 任 行政 长官 选举 期间 提出 希望 香港 青年 能够 被 培育 成 具备 香港 情怀 国家 观念 和 '\n",
      " '世界 视野 的 一代人 她 在 采访 中 说 香港 情怀 和 国家 观念 完全 没有 冲突 我们 既 可以 多 让 孩子 们 了解 香港 的 历史 文化 '\n",
      " '政治 社会 发展 情况 同时 也 必须 要 让 他们 有 国民 身份 的 认同 为此 特区 政府 和 社会 应该 怎么 做 林 郑月娥 认为 这 离 不 '\n",
      " '开 教育 在 幼儿 阶段 就 应该 开始 培养 我 是 中国 人 的 概念 在 中小学 阶段 林郑月娥 提出 未来 应该 将 中国 历史 纳入 初中 必 '\n",
      " '修 科目 在 学校 以外 特区 政府 要 加大 力度 让 孩子 们 能够 接触 到 更 多 的 中国 文化 让 香港 青年 了解 国家 最新 的 发展 '\n",
      " '林 郑月娥 在 接受 记者 采访 时 回答 提问 新华社 记者 陈晔华 摄 林 郑月娥 对 推动 香港 文化 事业 发展 倾注 了 大量 热情 和 努力 '\n",
      " '在 担任 本届 特区 政府 政务司 司长 期间 还 兼任 香港 在建 的 大型 项目 西九 文化区 的 管理局 主席 她 说 香港 文化 事业 正 处于 '\n",
      " '蓬勃 发展 阶段 未来 五 至 十 年 西九 文化区 和 位于 文化区 的 香港 故宫 文化 博物馆 将 相继 落成 文化 事业 对于 提高 市民 的 '\n",
      " '修养 提升 香港 的 旅游 品质 促进 经济 培养 青年 人才 都 具有 十分 重要 的 意义 特区 政府 将 更 积极 有 为 谈及 未来 五 年 '\n",
      " '特区 政府 的 施政 目标 和 她 本人 的 期许 林郑月娥 表示 愿意 用 她 丰富 的 从政 经验 秉承 自己 在 参选 行政 长官 时 提出 的 '\n",
      " '理念 努力 让 香港 成为 国家 一个 非常 有 朝气 的 城市 我 对 香港 未来 的 期盼 就 是 为 香港 市民 提供 一个 生活 满足 感 非常 '\n",
      " '高 的 地方 为 青年 提供 各展所长 的 机会 让 中年人 安居乐业 让 老年人 安享 晚年 林郑月娥 说 要 实现 这些 目标 下 一 届 特区 '\n",
      " '政府 将 优先 从 三 个 方面 加大 工作 力度 首先 是 土地 房屋 政策 解决 香港 楼价 高 买房 难 问题 第二 是 教育 将 投放 更 多 '\n",
      " '资源 培养 出 足够 的 人才 支撑 香港 未来 的 发展 第三 是 让 香港 的 经济 结构 更加 多元化 巩固 和 提升 传统 产业 开拓 创新 '\n",
      " '科技 产业 和 创意 产业 林 郑月娥 在 接受 记者 采访 时 回答 提问 新华社 记者 陈晔华 摄 林 郑月娥 认为 特区 政府 不 能 停留 在 '\n",
      " '公共 服务 提供者 和 市场 监管者 层面 要 更 有 动力 地 发展 香港 经济 就 要求 特区 政府 必须 再 进入 另外 两 个 新 角色 要 '\n",
      " '成为 许多 工作 的 促成者 和 在 全球 的 香港 推广者 根据 林郑月娥 提出 的 理财 新 理念 下届 特区 政府 在 开支 方面 尤其 是 '\n",
      " '投资性 开支 在 不 违反 基本法 的 前提 下 将 更 开放 特区 政府 计划 通过 税收 优惠 的 政策 鼓励 和 引导 企业 增加 研发 投入 '\n",
      " '此外 为 鼓励 中小微 和 初创 企业 发展 特区 政府 还 计划 降低 他们 的 企业 所得税率 回顾 过去 20 年 林郑月娥 认为 香港 的 经济 '\n",
      " '发展 和 国家 的 发展 是 分 不 开 的 在 国家 发展 的 每个 阶段 香港 都 在 国家 发展 的 大 背景 下 找到 自己 的 经济 增长点 '\n",
      " '所以 当 习 主席 提出 一带 一路 倡议 后 我们 也 希望 从中 找到 香港 新 的 经济 增长点 她 说 香港 过去 受惠 于 国家 的 改革 '\n",
      " '开放 成为 国际 金融 中心 航运 中心 贸易 物流 中心 未来 在 一带 一路 建设 中 香港 将 拥有 更 大 的 机遇')\n",
      "'----------------------------------------'\n",
      "('最可能被抄袭的文章：新华社 香港 6月 20日 电 即将 于 7月 1日 宣誓 就职 的 香港 特区 候任 行政 长官 林郑月娥 认为 香港 回归 祖国 '\n",
      " '20 年 来 一国两制 的 成功 落实 维护 了 香港 的 繁荣 稳定 与 核心 价值 让 香港 成功 地 应对 了 困难 与 危机 香港 回归 祖国 '\n",
      " '20 周年 前夕 林 郑月娥 女士 在 候任 行政 长官 办公室 接受 了 新华社 记者 采访 她 表示 上任 后 将 努力 带领 特区 政府 将 香港 '\n",
      " '建设 成 国家 有 朝气 的 特别 行政区 为 市民 提供 满足 感 高 的 生活 与 香港 回归 的 两 次 结缘 1980年 加入 公职 的 '\n",
      " '林郑月娥 已经 服务 香港 市民 超过 36年 亲身 经历 并 见证 了 回归 前后 香港 的 发展 与 变迁 她 认为 过去 20 年 香港 落实 '\n",
      " '一国两制 港人治港 高度 自治 的 方针 维护 了 香港 的 繁荣 与 稳定 在 中央 的 大力 支持 下 香港 成功 处理 了 困难 与 危机 从而 '\n",
      " '能够 渡过 难关 焕发 生机 一国两制 的 落实 是 非常 成功 的 林 郑月娥 说 过去 20 年 尽管 香港 经济 发展 经历 了 起伏 但 经济 '\n",
      " '总量 累计 增长 达 82 对于 经济 社会 发展 水平 比较 高 的 经济体 而言 这 是 十分 不 容易 的 在 这 一 过程 中 一国两制 '\n",
      " '港人治港 高度 自治 的 方针 以及 香港 的 法治 自由 等 核心 价值 始终如一 这些 都 是 一国两制 的 初心 林 郑月娥 曾 于 1985年 '\n",
      " '1996年 两 次 参加 中 英 联络 小组 的 工作 第一 次 是 讨论 香港 基本法 第24 条 的 有关 立法 工作 包括 签发 回归 后 新 的 '\n",
      " '香港 身份证 以及 保安 入境 等 第二 次 是 参与 编制 1997 至 1998年 财政 预算案 她 回忆 道 在 工作 中 很 高兴 结识 了 '\n",
      " '许多 内地 的 负责人 和 工作 人员 感到 大家 都 非常 专业 对 能够 参与 这项 伟大 的 事业 感到 光荣 每个 人 都 尽力 做到 最 好 '\n",
      " '能够 两 次 参与 回归 的 相关 工作 为 确保 香港 顺利 平稳 回归 作出 贡献 作为 一个 香港 人 中国 人 我 感到 很 有 意义 行政 '\n",
      " '长官 须 向 中央 和 香港 双重 负责 在 3月 举行 的 香港 特区 第五 任 行政 长官 选举 中 林郑月娥 高 票 当选 她 告诉 记者 当选 '\n",
      " '的 那 一刻 以及 后来 在 北京 从 李克强 总理 手中 接 过 中央政府 任命书 的 时候 都 感到 任重道远 她 说 香港 特区 行政 长官 既 '\n",
      " '要 向 中央政府 负责 也 要 向 香港 特区 负责 要 处理 好 中央 要求 和 香港 本地 实际 情况 这 两者 的 关系 就要 准确 地 按照 '\n",
      " '基本法 办事 因为 基本法 是 香港 的 宪制性 法律 是 行政 长官 及 特区 政府 在 香港 准确 落实 一国两制 的 依据 针对 近年来 香港 '\n",
      " '社会 出现 的 港独 言行 林郑月娥 表示 港独 在 香港 完全 没有 出路 一国两制 的 初心 和 原意 就 包含 了 香港 特别 行政区 是 国家 '\n",
      " '不可 分离 的 一 部分 并且 香港 的 回归 有利于 维护 国家 的 主权 安全 和 发展 利益 我 相信 绝大部分 香港 市民 从来 没有 觉得 '\n",
      " '港独 是 一个 可以 考虑 的 方案 未来 特区 政府 将 严格 依法 办事 所有 港独 行为 都 违反 本地 法律 我们 必须 严格 执法 林郑月娥 '\n",
      " '强调 她 表示 特区 政府 还 将 做 好 教育 工作 要 向 社会 大众 说明 港独 对 香港 繁荣 稳定 的 危害性 不 能 让 港独 在 香港 '\n",
      " '传播 尤其 是 要 杜绝 港独 对 少年儿童 的 侵害 香港 情怀 国家 观念 全球 视野 林 郑月娥 在 参加 香港 第五 任 行政 长官 选举 期间 '\n",
      " '提出 希望 香港 青年 能够 被 培育 成 具备 香港 情怀 国家 观念 和 世界 视野 的 一代人 她 在 采访 中 说 香港 情怀 和 国家 观念 '\n",
      " '完全 没有 冲突 我们 既 可以 多 让 孩子 们 了解 香港 的 历史 文化 政治 社会 发展 情况 同时 也 必须 要 让 他们 有 国民 身份 的 '\n",
      " '认同 为此 特区 政府 和 社会 应该 怎么 做 林 郑月娥 认为 这 离 不 开 教育 在 幼儿 阶段 就 应该 开始 培养 我 是 中国 人 的 '\n",
      " '概念 在 中小学 阶段 林郑月娥 提出 未来 应该 将 中国 历史 纳入 初中 必 修 科目 在 学校 以外 特区 政府 要 加大 力度 让 孩子 们 '\n",
      " '能够 接触 到 更 多 的 中国 文化 让 香港 青年 了解 国家 最新 的 发展 林 郑月娥 对 推动 香港 文化 事业 发展 倾注 了 大量 热情 '\n",
      " '和 努力 在 担任 本届 特区 政府 政务司 司长 期间 还 兼任 香港 在建 的 大型 项目 西九 文化区 的 管理局 主席 她 说 香港 文化 事业 '\n",
      " '正 处于 蓬勃 发展 阶段 未来 五 至 十 年 西九 文化区 和 位于 文化区 的 香港 故宫 文化 博物馆 将 相继 落成 文化 事业 对于 提高 '\n",
      " '市民 的 修养 提升 香港 的 旅游 品质 促进 经济 培养 青年 人才 都 具有 十分 重要 的 意义 特区 政府 将 更 积极 有 为 谈及 未来 '\n",
      " '五 年 特区 政府 的 施政 目标 和 她 本人 的 期许 林郑月娥 表示 愿意 用 她 丰富 的 从政 经验 秉承 自己 在 参选 行政 长官 时 '\n",
      " '提出 的 理念 努力 让 香港 成为 国家 一个 非常 有 朝气 的 城市 我 对 香港 未来 的 期盼 就 是 为 香港 市民 提供 一个 生活 满足 '\n",
      " '感 非常 高 的 地方 为 青年 提供 各展所长 的 机会 让 中年人 安居乐业 让 老年人 安享 晚年 林郑月娥 说 要 实现 这些 目标 下 一 届 '\n",
      " '特区 政府 将 优先 从 三 个 方面 加大 工作 力度 首先 是 土地 房屋 政策 解决 香港 楼价 高 买房 难 问题 第二 是 教育 将 投放 更 '\n",
      " '多 资源 培养 出 足够 的 人才 支撑 香港 未来 的 发展 第三 是 让 香港 的 经济 结构 更加 多元化 巩固 和 提升 传统 产业 开拓 创新 '\n",
      " '科技 产业 和 创意 产业 林 郑月娥 认为 特区 政府 不 能 停留 在 公共 服务 提供者 和 市场 监管者 层面 要 更 有 动力 地 发展 香港 '\n",
      " '经济 就 要求 特区 政府 必须 再 进入 另外 两 个 新 角色 要 成为 许多 工作 的 促成者 和 在 全球 的 香港 推广者 根据 林郑月娥 '\n",
      " '提出 的 理财 新 理念 下届 特区 政府 在 开支 方面 尤其 是 投资性 开支 在 不 违反 基本法 的 前提 下 将 更 开放 特区 政府 计划 '\n",
      " '通过 税收 优惠 的 政策 鼓励 和 引导 企业 增加 研发 投入 此外 为 鼓励 中小微 和 初创 企业 发展 特区 政府 还 计划 降低 他们 的 '\n",
      " '企业 所得税率 回顾 过去 20 年 林郑月娥 认为 香港 的 经济 发展 和 国家 的 发展 是 分 不 开 的 在 国家 发展 的 每个 阶段 香港 '\n",
      " '都 在 国家 发展 的 大 背景 下 找到 自己 的 经济 增长点 所以 当 习 主席 提出 一带 一路 倡议 后 我们 也 希望 从中 找到 香港 新 '\n",
      " '的 经济 增长点 她 说 香港 过去 受惠 于 国家 的 改革 开放 成为 国际 金融 中心 航运 中心 贸易 物流 中心 未来 在 一带 一路 建设 '\n",
      " '中 香港 将 拥有 更 大 的 机遇 记者 颜昊 李凯 左 为 参与 采写 李雪姣 责任 编辑 张迪')\n",
      "'****************************************************************************************************'\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5304"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similars(xinhua_news, candidates_clean, candidates_vector, 508)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "寻找相似文章的部分需要优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "origin = ''.join(df.content_cut[5304].split())\n",
    "copy = ''.join(candidates_clean[508].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编辑距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditDistance_update:\n",
    "    def __init__(self, levenshtein=True):\n",
    "        self.solution = {}\n",
    "        self.levenshtein = levenshtein\n",
    "        \n",
    "    def edit_distance_with_matrix(self, str1, str2):\n",
    "        \"\"\"\n",
    "        @levenshtein: susbstitute cost 2 steps while True, else cost 1 step.\n",
    "        \"\"\"\n",
    "        len_1, len_2 = len(str1)+1, len(str2)+1\n",
    "        matrix = np.zeros((len_2, len_1), dtype=np.int)\n",
    "        if str1 and str2:\n",
    "            matrix[0, :] = np.arange(len_1)\n",
    "            matrix[:, 0] = np.arange(len_2)\n",
    "            for i, char1 in enumerate(str2, start=1):\n",
    "                for j, char2 in enumerate(str1, start=1):\n",
    "                        \n",
    "                    left = matrix[i-1, j] + 1\n",
    "                    top = matrix[i, j-1] + 1\n",
    "                    if char1 != char2:\n",
    "                        diag = (matrix[i-1, j-1] + 2) if self.levenshtein else (matrix[i-1, j-1] + 1)\n",
    "                    else:\n",
    "                        diag = matrix[i-1, j-1]\n",
    "                    \n",
    "                    matrix[i, j] = min(left, top, diag)\n",
    "\n",
    "            return matrix[len_2-1 , len_1-1], matrix\n",
    "        else:\n",
    "            return (len_1,matrix)  if str1 else (len_2,matrix)\n",
    "        \n",
    "    def get_matrix_solution(self, matrix):\n",
    "        \"\"\"\n",
    "        Up refers to inserting; left refers to deleting; digonal refers to substituting.\n",
    "        \"\"\"\n",
    "        r, c = matrix.shape\n",
    "        if r < 2:\n",
    "            for _ in matrix[0, :c-1]:\n",
    "                self.solution[_+1] = f\"delete str1.({_})\"\n",
    "            return\n",
    "        elif c < 2:\n",
    "            for _ in matrix[:r-1, 0]:\n",
    "                self.solution[_ + 1] = f\"insert before str1.({0}) with str2.({_})\"\n",
    "            return\n",
    "\n",
    "        row, column = np.array(matrix.shape) - 1\n",
    "        target = matrix[row, column]\n",
    "        up = row - 1, column\n",
    "        left = row, column - 1\n",
    "        diag = row - 1, column - 1\n",
    "\n",
    "        temp = min(matrix[diag], matrix[up], matrix[left])\n",
    "        \n",
    "        flag = 2 if self.levenshtein else 1\n",
    "\n",
    "        if target != temp:\n",
    "            # 删除或者插入优先\n",
    "            if target == matrix[up] + 1:\n",
    "                self.solution[target] = f\"insert after str1.({column - 1}) with str2.({row - 1})\"\n",
    "                return self.get_matrix_solution(matrix[:row, :])\n",
    "            elif target == matrix[left] + 1:\n",
    "                self.solution[target] = f\"delete str1.({column - 1})\"\n",
    "                return self.get_matrix_solution(matrix[:, :column])\n",
    "            elif target == matrix[diag] + flag:\n",
    "                self.solution[target] = f\"substitute str1.({column - 1}) with str2.({row - 1})\"\n",
    "                return self.get_matrix_solution(matrix[:row,:column])\n",
    "        return self.get_matrix_solution(matrix[:row,:column])\n",
    "    \n",
    "    def get_solution(self):\n",
    "        return sorted(self.solution.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'insert before str1.(0) with str2.(0)'),\n",
       " (2, 'insert before str1.(0) with str2.(1)'),\n",
       " (3, 'insert before str1.(0) with str2.(2)'),\n",
       " (4, 'insert before str1.(0) with str2.(3)'),\n",
       " (5, 'insert before str1.(0) with str2.(4)'),\n",
       " (6, 'insert before str1.(0) with str2.(5)'),\n",
       " (7, 'insert before str1.(0) with str2.(6)'),\n",
       " (8, 'insert before str1.(0) with str2.(7)'),\n",
       " (9, 'insert before str1.(0) with str2.(8)'),\n",
       " (10, 'insert before str1.(0) with str2.(9)'),\n",
       " (11, 'insert before str1.(0) with str2.(10)'),\n",
       " (12, 'insert before str1.(0) with str2.(11)'),\n",
       " (13, 'insert before str1.(0) with str2.(12)'),\n",
       " (14, 'insert before str1.(0) with str2.(13)'),\n",
       " (15, 'insert before str1.(0) with str2.(14)'),\n",
       " (16, 'insert before str1.(0) with str2.(15)'),\n",
       " (17, 'insert before str1.(0) with str2.(16)'),\n",
       " (18, 'insert before str1.(0) with str2.(17)'),\n",
       " (19, 'insert before str1.(0) with str2.(18)'),\n",
       " (20, 'insert before str1.(0) with str2.(19)'),\n",
       " (21, 'insert before str1.(0) with str2.(20)'),\n",
       " (22, 'insert before str1.(0) with str2.(21)'),\n",
       " (23, 'insert before str1.(0) with str2.(22)'),\n",
       " (24, 'insert before str1.(0) with str2.(23)'),\n",
       " (25, 'insert after str1.(10) with str2.(35)'),\n",
       " (26, 'insert after str1.(10) with str2.(36)'),\n",
       " (27, 'insert after str1.(10) with str2.(37)'),\n",
       " (28, 'insert after str1.(10) with str2.(38)'),\n",
       " (29, 'insert after str1.(10) with str2.(39)'),\n",
       " (30, 'insert after str1.(10) with str2.(40)'),\n",
       " (31, 'insert after str1.(10) with str2.(41)'),\n",
       " (32, 'insert after str1.(10) with str2.(42)'),\n",
       " (33, 'insert after str1.(10) with str2.(43)'),\n",
       " (34, 'insert after str1.(10) with str2.(44)'),\n",
       " (35, 'insert after str1.(10) with str2.(45)'),\n",
       " (36, 'insert after str1.(10) with str2.(46)'),\n",
       " (37, 'insert after str1.(10) with str2.(47)'),\n",
       " (38, 'insert after str1.(10) with str2.(48)'),\n",
       " (39, 'insert after str1.(10) with str2.(49)'),\n",
       " (40, 'insert after str1.(10) with str2.(50)'),\n",
       " (41, 'insert after str1.(10) with str2.(51)'),\n",
       " (42, 'insert after str1.(10) with str2.(52)'),\n",
       " (43, 'insert after str1.(10) with str2.(53)'),\n",
       " (44, 'insert after str1.(10) with str2.(54)'),\n",
       " (45, 'insert after str1.(10) with str2.(55)'),\n",
       " (46, 'insert after str1.(10) with str2.(56)'),\n",
       " (47, 'insert after str1.(10) with str2.(57)'),\n",
       " (48, 'insert after str1.(10) with str2.(58)'),\n",
       " (49, 'insert after str1.(10) with str2.(59)'),\n",
       " (50, 'insert after str1.(10) with str2.(60)'),\n",
       " (51, 'insert after str1.(10) with str2.(61)'),\n",
       " (52, 'insert after str1.(10) with str2.(62)'),\n",
       " (53, 'insert after str1.(10) with str2.(63)'),\n",
       " (54, 'insert after str1.(10) with str2.(64)'),\n",
       " (55, 'insert after str1.(10) with str2.(65)'),\n",
       " (56, 'insert after str1.(10) with str2.(66)'),\n",
       " (57, 'insert after str1.(10) with str2.(67)'),\n",
       " (58, 'insert after str1.(10) with str2.(68)'),\n",
       " (59, 'insert after str1.(10) with str2.(69)'),\n",
       " (60, 'insert after str1.(10) with str2.(70)'),\n",
       " (61, 'insert after str1.(86) with str2.(147)'),\n",
       " (62, 'insert after str1.(86) with str2.(148)'),\n",
       " (63, 'insert after str1.(86) with str2.(149)'),\n",
       " (64, 'insert after str1.(86) with str2.(150)'),\n",
       " (65, 'insert after str1.(86) with str2.(151)'),\n",
       " (66, 'insert after str1.(86) with str2.(152)'),\n",
       " (67, 'insert after str1.(86) with str2.(153)'),\n",
       " (68, 'insert after str1.(86) with str2.(154)'),\n",
       " (69, 'insert after str1.(86) with str2.(155)'),\n",
       " (70, 'insert after str1.(86) with str2.(156)'),\n",
       " (71, 'insert after str1.(86) with str2.(157)'),\n",
       " (72, 'insert after str1.(86) with str2.(158)'),\n",
       " (73, 'insert after str1.(86) with str2.(159)'),\n",
       " (74, 'insert after str1.(86) with str2.(160)'),\n",
       " (75, 'insert after str1.(86) with str2.(161)'),\n",
       " (76, 'insert after str1.(86) with str2.(162)'),\n",
       " (77, 'insert after str1.(86) with str2.(163)'),\n",
       " (78, 'insert after str1.(86) with str2.(164)'),\n",
       " (79, 'insert after str1.(86) with str2.(165)'),\n",
       " (80, 'insert after str1.(86) with str2.(166)'),\n",
       " (81, 'insert after str1.(86) with str2.(167)'),\n",
       " (82, 'insert after str1.(86) with str2.(168)'),\n",
       " (83, 'insert after str1.(86) with str2.(169)'),\n",
       " (84, 'insert after str1.(86) with str2.(170)'),\n",
       " (85, 'insert after str1.(86) with str2.(171)'),\n",
       " (86, 'insert after str1.(86) with str2.(172)'),\n",
       " (87, 'insert after str1.(86) with str2.(173)'),\n",
       " (88, 'insert after str1.(86) with str2.(174)'),\n",
       " (89, 'insert after str1.(86) with str2.(175)'),\n",
       " (90, 'insert after str1.(86) with str2.(176)'),\n",
       " (91, 'insert after str1.(425) with str2.(516)'),\n",
       " (92, 'insert after str1.(425) with str2.(517)'),\n",
       " (93, 'insert after str1.(425) with str2.(518)'),\n",
       " (94, 'insert after str1.(425) with str2.(519)'),\n",
       " (95, 'insert after str1.(425) with str2.(520)'),\n",
       " (96, 'insert after str1.(425) with str2.(521)'),\n",
       " (97, 'insert after str1.(425) with str2.(522)'),\n",
       " (98, 'insert after str1.(425) with str2.(523)'),\n",
       " (99, 'insert after str1.(425) with str2.(524)'),\n",
       " (100, 'insert after str1.(425) with str2.(525)'),\n",
       " (101, 'insert after str1.(425) with str2.(526)'),\n",
       " (102, 'insert after str1.(425) with str2.(527)'),\n",
       " (103, 'insert after str1.(425) with str2.(528)'),\n",
       " (104, 'insert after str1.(425) with str2.(529)'),\n",
       " (105, 'insert after str1.(425) with str2.(530)'),\n",
       " (106, 'insert after str1.(425) with str2.(531)'),\n",
       " (107, 'insert after str1.(425) with str2.(532)'),\n",
       " (108, 'insert after str1.(425) with str2.(533)'),\n",
       " (109, 'insert after str1.(425) with str2.(534)'),\n",
       " (110, 'insert after str1.(425) with str2.(535)'),\n",
       " (111, 'insert after str1.(901) with str2.(1012)'),\n",
       " (112, 'insert after str1.(901) with str2.(1013)'),\n",
       " (113, 'insert after str1.(901) with str2.(1014)'),\n",
       " (114, 'insert after str1.(901) with str2.(1015)'),\n",
       " (115, 'insert after str1.(901) with str2.(1016)'),\n",
       " (116, 'insert after str1.(901) with str2.(1017)'),\n",
       " (117, 'insert after str1.(901) with str2.(1018)'),\n",
       " (118, 'insert after str1.(901) with str2.(1019)'),\n",
       " (119, 'insert after str1.(901) with str2.(1020)'),\n",
       " (120, 'insert after str1.(901) with str2.(1021)'),\n",
       " (121, 'insert after str1.(901) with str2.(1022)'),\n",
       " (122, 'insert after str1.(901) with str2.(1023)'),\n",
       " (123, 'insert after str1.(901) with str2.(1024)'),\n",
       " (124, 'insert after str1.(901) with str2.(1025)'),\n",
       " (125, 'insert after str1.(901) with str2.(1026)'),\n",
       " (126, 'insert after str1.(901) with str2.(1027)'),\n",
       " (127, 'insert after str1.(901) with str2.(1028)'),\n",
       " (128, 'insert after str1.(901) with str2.(1029)'),\n",
       " (129, 'insert after str1.(901) with str2.(1030)'),\n",
       " (130, 'insert after str1.(901) with str2.(1031)'),\n",
       " (131, 'insert after str1.(901) with str2.(1032)'),\n",
       " (132, 'insert after str1.(901) with str2.(1033)'),\n",
       " (133, 'insert after str1.(901) with str2.(1034)'),\n",
       " (134, 'insert after str1.(901) with str2.(1035)'),\n",
       " (135, 'insert after str1.(901) with str2.(1036)'),\n",
       " (136, 'insert after str1.(1285) with str2.(1421)'),\n",
       " (137, 'insert after str1.(1285) with str2.(1422)'),\n",
       " (138, 'insert after str1.(1285) with str2.(1423)'),\n",
       " (139, 'insert after str1.(1285) with str2.(1424)'),\n",
       " (140, 'insert after str1.(1285) with str2.(1425)'),\n",
       " (141, 'insert after str1.(1285) with str2.(1426)'),\n",
       " (142, 'insert after str1.(1285) with str2.(1427)'),\n",
       " (143, 'insert after str1.(1285) with str2.(1428)'),\n",
       " (144, 'insert after str1.(1285) with str2.(1429)'),\n",
       " (145, 'insert after str1.(1285) with str2.(1430)'),\n",
       " (146, 'insert after str1.(1285) with str2.(1431)'),\n",
       " (147, 'insert after str1.(1285) with str2.(1432)'),\n",
       " (148, 'insert after str1.(1285) with str2.(1433)'),\n",
       " (149, 'insert after str1.(1285) with str2.(1434)'),\n",
       " (150, 'insert after str1.(1285) with str2.(1435)'),\n",
       " (151, 'insert after str1.(1285) with str2.(1436)'),\n",
       " (152, 'insert after str1.(1285) with str2.(1437)'),\n",
       " (153, 'insert after str1.(1285) with str2.(1438)'),\n",
       " (154, 'insert after str1.(1285) with str2.(1439)'),\n",
       " (155, 'insert after str1.(1285) with str2.(1440)'),\n",
       " (156, 'insert after str1.(1285) with str2.(1441)'),\n",
       " (157, 'insert after str1.(1285) with str2.(1442)'),\n",
       " (158, 'insert after str1.(1285) with str2.(1443)'),\n",
       " (159, 'insert after str1.(1285) with str2.(1444)'),\n",
       " (160, 'insert after str1.(1285) with str2.(1445)'),\n",
       " (161, 'insert after str1.(1705) with str2.(1866)'),\n",
       " (162, 'insert after str1.(1705) with str2.(1867)'),\n",
       " (163, 'insert after str1.(1705) with str2.(1868)'),\n",
       " (164, 'insert after str1.(1705) with str2.(1869)'),\n",
       " (165, 'insert after str1.(1705) with str2.(1870)'),\n",
       " (166, 'insert after str1.(1705) with str2.(1871)'),\n",
       " (167, 'insert after str1.(1705) with str2.(1872)'),\n",
       " (168, 'insert after str1.(1705) with str2.(1873)'),\n",
       " (169, 'insert after str1.(1705) with str2.(1874)'),\n",
       " (170, 'insert after str1.(1705) with str2.(1875)'),\n",
       " (171, 'insert after str1.(1705) with str2.(1876)'),\n",
       " (172, 'insert after str1.(1705) with str2.(1877)'),\n",
       " (173, 'insert after str1.(1705) with str2.(1878)'),\n",
       " (174, 'insert after str1.(1705) with str2.(1879)'),\n",
       " (175, 'insert after str1.(1705) with str2.(1880)'),\n",
       " (176, 'insert after str1.(1705) with str2.(1881)'),\n",
       " (177, 'insert after str1.(1705) with str2.(1882)'),\n",
       " (178, 'insert after str1.(1705) with str2.(1883)'),\n",
       " (179, 'insert after str1.(1705) with str2.(1884)'),\n",
       " (180, 'insert after str1.(1705) with str2.(1885)'),\n",
       " (181, 'insert after str1.(1705) with str2.(1886)'),\n",
       " (182, 'insert after str1.(1705) with str2.(1887)'),\n",
       " (183, 'insert after str1.(1705) with str2.(1888)'),\n",
       " (184, 'insert after str1.(1705) with str2.(1889)'),\n",
       " (185, 'insert after str1.(1705) with str2.(1890)'),\n",
       " (186, 'delete str1.(2044)'),\n",
       " (187, 'delete str1.(2045)'),\n",
       " (188, 'delete str1.(2046)'),\n",
       " (189, 'delete str1.(2047)'),\n",
       " (190, 'delete str1.(2048)'),\n",
       " (191, 'delete str1.(2049)'),\n",
       " (192, 'delete str1.(2050)'),\n",
       " (193, 'delete str1.(2051)'),\n",
       " (194, 'delete str1.(2052)'),\n",
       " (195, 'delete str1.(2053)'),\n",
       " (196, 'delete str1.(2054)'),\n",
       " (197, 'delete str1.(2055)'),\n",
       " (198, 'delete str1.(2056)'),\n",
       " (199, 'delete str1.(2057)'),\n",
       " (200, 'delete str1.(2058)'),\n",
       " (201, 'delete str1.(2059)'),\n",
       " (202, 'delete str1.(2060)'),\n",
       " (203, 'delete str1.(2061)'),\n",
       " (204, 'delete str1.(2062)'),\n",
       " (205, 'delete str1.(2063)'),\n",
       " (206, 'delete str1.(2064)')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_update = EditDistance_update()\n",
    "step, matrix_ = test_update.edit_distance_with_matrix(origin, copy)\n",
    "test_update.get_matrix_solution(matrix_)\n",
    "test_update.get_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 2229)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(origin), len(copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两千字出头的文章，更改两百个字就成为另一篇文章，重复度还是很高的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step11: 利用第8课讲述的新模型，进行操作，感受其中不同的参数、模型对性能的影响。\n",
    "见第八课assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
