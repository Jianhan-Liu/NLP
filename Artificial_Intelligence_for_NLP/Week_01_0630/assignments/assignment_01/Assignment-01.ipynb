{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Chat-bot, machine interpreter,auto-drive,android service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Store and share projects for everyone; efficiency is upmost reason to use these two IDEs in a way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Something to describe the probability of A's happening under B(/C/D...)'s condition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Android service like auto-stock buy & sell; machine interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Better solution compare to linguistic defination. As programming based on parsing you need to highly abstract the problem and take as more as possible the chance of all posibilities into consideration. And yet, it still can't do better in ambiguous case and take much more time in computational complexity way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Something describes the posibility of strings in certain content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Machine interpreter, merchant's AI operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Model that only take posibility of single word into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Language is something that context sensitive case, it's hard to understand someone's sentence just look into the very word in it without considering word's sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Model that describes the posibility of a word is related to it's subsequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 \n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 需要根据训练数据构想较近的应用场景么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = '''\n",
    "client = 时间 地点 列车号 故障 结尾\n",
    "时间 = 今早 | 昨晚 | 昨天 | 检修时\n",
    "地点 = 库里 | 地铁站 | 牵引线\n",
    "地铁站 = 地铁站 | 岩内站 | 诚毅大街站 | 集美学村站 | 乌石浦站 | 园博苑站\n",
    "列车号 = 列车号 | TS001 | TS002 | TS003 | TS004 | TS005\n",
    "故障 = 故障 | 牵引封锁 | 辅助过温 | 受电弓异常 | 速传故障 | 高压系统故障\n",
    "结尾 = 。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = '''\n",
    "worker = 人物 疑问 动作 处理 结尾\n",
    "人物 = 你们 | 其他供应商 | 检修班组\n",
    "疑问 = 有没有 | 是不是 | 是否\n",
    "动作 = 做过 | 干过 | 处理过 |\n",
    "处理 = 软件更新 | 硬件保养 | 系统校正 | 库内检修\n",
    "结尾 = ?\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): \n",
    "            continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar\n",
    "\n",
    "def generate(gram, target):\n",
    "    if target not in gram:\n",
    "        return target\n",
    "    expanded = [generate(gram ,t) for t in random.choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expanded if e != 'null'])\n",
    "\n",
    "client_gram = create_grammar(client)\n",
    "worker_gram = create_grammar(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client': [['时间', '地点', '列车号', '故障', '结尾']],\n",
       " '时间': [['今早'], ['昨晚'], ['昨天'], ['检修时']],\n",
       " '地点': [['库里'], ['地铁站'], ['牵引线']],\n",
       " '地铁站': [['地铁站'], ['岩内站'], ['诚毅大街站'], ['集美学村站'], ['乌石浦站'], ['园博苑站']],\n",
       " '列车号': [['列车号'], ['TS001'], ['TS002'], ['TS003'], ['TS004'], ['TS005']],\n",
       " '故障': [['故障'], ['牵引封锁'], ['辅助过温'], ['受电弓异常'], ['速传故障'], ['高压系统故障']],\n",
       " '结尾': [['。']]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'worker': [['人物', '疑问', '动作', '处理', '结尾']],\n",
       " '人物': [['你们'], ['其他供应商'], ['检修班组']],\n",
       " '疑问': [['有没有'], ['是不是'], ['是否']],\n",
       " '动作': [['做过'], ['干过'], ['处理过'], []],\n",
       " '处理': [['软件更新'], ['硬件保养'], ['系统校正'], ['库内检修']],\n",
       " '结尾': [['?']]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你们是否做过系统校正?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(worker_gram, 'worker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(grammar_string=client_gram, target='client',n=10):\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(generate(grammar_string, target))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['昨晚库里TS004牵引封锁。',\n",
       " '检修时库里TS003受电弓异常。',\n",
       " '今早乌石浦站TS005速传故障。',\n",
       " '昨晚牵引线TS003辅助过温。',\n",
       " '今早库里TS005受电弓异常。',\n",
       " '昨天牵引线TS003高压系统故障。',\n",
       " '昨晚牵引线TS004速传故障。',\n",
       " '今早诚毅大街站TS005受电弓异常。',\n",
       " '今早库里TS005受电弓异常。',\n",
       " '昨晚牵引线TS005高压系统故障。']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你们是不是硬件保养?',\n",
       " '其他供应商有没有处理过硬件保养?',\n",
       " '检修班组有没有处理过硬件保养?',\n",
       " '检修班组有没有处理过系统校正?',\n",
       " '其他供应商有没有处理过软件更新?',\n",
       " '其他供应商是否做过软件更新?',\n",
       " '其他供应商是否干过系统校正?',\n",
       " '检修班组是否干过硬件保养?',\n",
       " '检修班组有没有系统校正?',\n",
       " '其他供应商是不是处理过硬件保养?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(worker_gram, 'worker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本1处理\n",
    "import re\n",
    "with open('train.txt', encoding='utf-8') as f:\n",
    "    with open('train_pure.txt', 'w', encoding='utf-8') as f2:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.replace('？', '?')\n",
    "            line = re.findall('\\+\\s\\w+\\?', line)\n",
    "            if line:\n",
    "                f2.write(str(line[0][2:-1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本2处理\n",
    "import pandas as pd\n",
    "content = pd.read_csv('movie_comments.csv', encoding='utf-8')\n",
    "content.head()\n",
    "articles = content['comment'].tolist()\n",
    "len(articles)  # -> 261497\n",
    "for i, article in enumerate(articles):\n",
    "    try:\n",
    "        new_article = re.findall('\\w+', article)\n",
    "        if new_article:\n",
    "            articles[i] = ''.join(new_article)\n",
    "    except TypeError:\n",
    "        pass\n",
    "with open('movie_comment_pure.txt', 'w', encoding='utf-8') as f:\n",
    "    for article in articles:\n",
    "        f.write(str(article) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_MOVIE = []\n",
    "for i, line in enumerate((open('movie_comment_pure.txt', encoding='utf-8'))):\n",
    "    TOKEN_MOVIE = cut(line)\n",
    "TOKEN_MOVIE = [str(t) for t in TOKEN_MOVIE]\n",
    "TOKEN_2_MOVIE_GRAM = [''.join(TOKEN_MOVIE[i:i+2]) for i in range(len(TOKEN_MOVIE[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['除了主人公',\n",
       " '主人公都',\n",
       " '都不帅',\n",
       " '不帅女主挺',\n",
       " '女主挺漂亮',\n",
       " '漂亮之外',\n",
       " '之外唯一',\n",
       " '唯一的',\n",
       " '的感觉',\n",
       " '感觉就是']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_2_MOVIE_GRAM[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('除了主人公', 1),\n",
       " ('主人公都', 1),\n",
       " ('都不帅', 1),\n",
       " ('不帅女主挺', 1),\n",
       " ('女主挺漂亮', 1),\n",
       " ('漂亮之外', 1),\n",
       " ('之外唯一', 1),\n",
       " ('唯一的', 1),\n",
       " ('的感觉', 1),\n",
       " ('感觉就是', 1)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_movie = Counter(TOKEN_2_MOVIE_GRAM)\n",
    "words_count_movie.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.807 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "count = -1\n",
    "TOKEN = []\n",
    "for i, line in enumerate((open('train_pure.txt', encoding='utf-8'))):\n",
    "    count += 1\n",
    "    TOKEN += cut(line)\n",
    "TOKEN = [str(t) for t in TOKEN]\n",
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['法律要求', '要求残疾', '残疾保险', '保险吗', '吗\\n', '\\n债权人', '债权人可以', '可以在', '在死', '死后']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_2_GRAM[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('吗\\n', 2217),\n",
       " ('保险\\n', 1541),\n",
       " ('\\n什么', 1479),\n",
       " ('健康保险', 1287),\n",
       " ('什么是', 1089),\n",
       " ('\\n我', 1000),\n",
       " ('保险是否', 943),\n",
       " ('人寿保险\\n', 864),\n",
       " ('什么\\n', 696),\n",
       " ('\\n如何', 665)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_2_gram(w1, w2, token=TOKEN_2_GRAM):\n",
    "    combine = w1+w2\n",
    "    length = len(token)\n",
    "    if combine in words_count:\n",
    "        return words_count[combine] / length\n",
    "    else:\n",
    "        return 1 / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.478682170542636e-05"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_2_gram('法律', '要求')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005656492248062015"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_2_gram('保险', '吗')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(sentence, token=TOKEN_2_MOVIE_GRAM):\n",
    "    words = cut(sentence)   \n",
    "    sentence_pro = 1 \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        probability = probability_2_gram(word, next_, token)\n",
    "        sentence_pro *= probability\n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2439100800989337e-14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('法律要求就行么')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4671030887566852e-10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('今天天气真好啊')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.174266240650136e-14"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('我有一个飞机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4671030887566852e-10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('晚上吃晚饭呀')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.777014400141334e-15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model('晚上吃早饭呀')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: 检修时集美学村站TS002高压系统故障。 with probability: 9.486450616421968e-09\n",
      "Condition: 今早牵引线TS003受电弓异常。 with probability: 1.3281030862990755e-07\n",
      "Condition: 昨天牵引线TS001受电弓异常。 with probability: 1.3281030862990755e-07\n",
      "Condition: 昨晚集美学村站TS004受电弓异常。 with probability: 1.3281030862990755e-07\n",
      "Condition: 检修时诚毅大街站TS004高压系统故障。 with probability: 9.486450616421968e-09\n",
      "Condition: 昨晚集美学村站TS003速传故障。 with probability: 1.3281030862990755e-07\n",
      "Condition: 检修时牵引线TS003辅助过温。 with probability: 9.486450616421968e-09\n",
      "Condition: 昨晚库里TS001速传故障。 with probability: 1.859344320818706e-06\n",
      "Condition: 今早乌石浦站TS002受电弓异常。 with probability: 9.486450616421968e-09\n",
      "Condition: 今早牵引线TS002高压系统故障。 with probability: 1.3281030862990755e-07\n",
      "Condition: 昨天乌石浦站TS003牵引封锁。 with probability: 9.486450616421968e-09\n",
      "Condition: 今早岩内站TS004高压系统故障。 with probability: 1.3281030862990755e-07\n",
      "Condition: 昨晚库里TS005高压系统故障。 with probability: 1.859344320818706e-06\n",
      "Condition: 昨天牵引线TS005牵引封锁。 with probability: 1.3281030862990755e-07\n",
      "Condition: 昨天乌石浦站TS004牵引封锁。 with probability: 9.486450616421968e-09\n",
      "Condition: 检修时集美学村站TS003受电弓异常。 with probability: 9.486450616421968e-09\n",
      "Condition: 今早库里TS003受电弓异常。 with probability: 1.859344320818706e-06\n",
      "Condition: 昨晚园博苑站TS004速传故障。 with probability: 1.3281030862990755e-07\n",
      "Condition: 昨晚牵引线TS003高压系统故障。 with probability: 1.3281030862990755e-07\n",
      "Condition: 检修时集美学村站TS004受电弓异常。 with probability: 9.486450616421968e-09\n"
     ]
    }
   ],
   "source": [
    "for sen in generate_n(n=20):\n",
    "    print(f\"Condition: {sen} with probability: {language_model(sen, token=TOKEN_2_MOVIE_GRAM)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: 昨天牵引线TS004高压系统故障。 with probability: 3.157780178309664e-30\n",
      "Condition: 昨天岩内站TS001速传故障。 with probability: 3.157780178309664e-30\n",
      "Condition: 检修时库里TS005高压系统故障。 with probability: 3.157780178309664e-30\n",
      "Condition: 昨天库里TS004受电弓异常。 with probability: 2.607063315212459e-25\n",
      "Condition: 检修时库里TS002牵引封锁。 with probability: 3.157780178309664e-30\n",
      "Condition: 今早牵引线TS001速传故障。 with probability: 3.157780178309664e-30\n",
      "Condition: 昨晚牵引线TS005速传故障。 with probability: 3.157780178309664e-30\n",
      "Condition: 昨天库里TS001受电弓异常。 with probability: 2.607063315212459e-25\n",
      "Condition: 昨天库里TS001高压系统故障。 with probability: 2.607063315212459e-25\n",
      "Condition: 检修时牵引线TS002速传故障。 with probability: 3.824830642332442e-35\n",
      "Condition: 今早牵引线TS003高压系统故障。 with probability: 3.157780178309664e-30\n",
      "Condition: 检修时牵引线TS004速传故障。 with probability: 3.824830642332442e-35\n",
      "Condition: 检修时库里TS003牵引封锁。 with probability: 3.157780178309664e-30\n",
      "Condition: 昨晚库里TS005高压系统故障。 with probability: 2.607063315212459e-25\n",
      "Condition: 今早乌石浦站TS002牵引封锁。 with probability: 3.824830642332442e-35\n",
      "Condition: 昨天集美学村站TS005高压系统故障。 with probability: 3.157780178309664e-30\n",
      "Condition: 今早牵引线TS003辅助过温。 with probability: 3.157780178309664e-30\n",
      "Condition: 昨晚库里TS004高压系统故障。 with probability: 2.607063315212459e-25\n",
      "Condition: 检修时牵引线TS005牵引封锁。 with probability: 3.824830642332442e-35\n",
      "Condition: 检修时集美学村站TS004辅助过温。 with probability: 3.824830642332442e-35\n"
     ]
    }
   ],
   "source": [
    "for sen in generate_n(n=20):\n",
    "    print(f\"Condition: {sen} with probability: {language_model(sen)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **大**数据的作用↑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar_string=client_gram, language_model=language_model, n=20):\n",
    "    sentences = generate_n(grammar_string=grammar_string, n=n)\n",
    "    probability = list(map(language_model, sentences))\n",
    "    result = sorted(list(zip(sentences, probability)), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"The most probability condition is : {result[0][0]} with probability: {result[0][1]}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most probability condition is : 昨晚库里TS001速传故障。 with probability: 1.859344320818706e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('昨晚库里TS001速传故障。', 1.859344320818706e-06),\n",
       " ('今早库里TS001高压系统故障。', 1.859344320818706e-06),\n",
       " ('昨晚库里TS004速传故障。', 1.859344320818706e-06),\n",
       " ('昨晚库里TS005高压系统故障。', 1.859344320818706e-06),\n",
       " ('昨晚库里TS003辅助过温。', 1.859344320818706e-06),\n",
       " ('昨天库里TS001速传故障。', 1.859344320818706e-06),\n",
       " ('今早牵引线TS002速传故障。', 1.3281030862990755e-07),\n",
       " ('昨天牵引线TS001牵引封锁。', 1.3281030862990755e-07),\n",
       " ('今早牵引线TS002受电弓异常。', 1.3281030862990755e-07),\n",
       " ('昨晚牵引线TS004受电弓异常。', 1.3281030862990755e-07),\n",
       " ('昨晚牵引线TS004牵引封锁。', 1.3281030862990755e-07),\n",
       " ('检修时库里TS004高压系统故障。', 1.3281030862990755e-07),\n",
       " ('昨晚集美学村站TS002辅助过温。', 1.3281030862990755e-07),\n",
       " ('昨晚牵引线TS001受电弓异常。', 1.3281030862990755e-07),\n",
       " ('昨晚牵引线TS005牵引封锁。', 1.3281030862990755e-07),\n",
       " ('今早岩内站TS003牵引封锁。', 1.3281030862990755e-07),\n",
       " ('检修时库里TS002辅助过温。', 1.3281030862990755e-07),\n",
       " ('检修时园博苑站TS001受电弓异常。', 9.486450616421968e-09),\n",
       " ('检修时集美学村站TS001高压系统故障。', 9.486450616421968e-09),\n",
       " ('昨晚乌石浦站TS002辅助过温。', 9.486450616421968e-09)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 应用场景过于专业性，模型训练材料必须有针对性才能进行训练，否则得出的结果是没有参考依据的。即：需要根据模型的应用场景选择对应场景的语言材料进行针对性训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
