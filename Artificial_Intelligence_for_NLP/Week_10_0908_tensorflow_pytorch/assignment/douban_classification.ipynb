{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "from datetime import datetime\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, scale, normalize, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movie_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>261497</td>\n",
       "      <td>261497</td>\n",
       "      <td>261497</td>\n",
       "      <td>261495</td>\n",
       "      <td>261497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>260150</td>\n",
       "      <td>2761</td>\n",
       "      <td>2760</td>\n",
       "      <td>213970</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>12</td>\n",
       "      <td>https://movie.douban.com/subject/1849031/</td>\n",
       "      <td>当幸福来敲门 The Pursuit of Happyness</td>\n",
       "      <td>经典</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>396</td>\n",
       "      <td>396</td>\n",
       "      <td>200</td>\n",
       "      <td>43002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       link  \\\n",
       "count   261497                                     261497   \n",
       "unique  260150                                       2761   \n",
       "top         12  https://movie.douban.com/subject/1849031/   \n",
       "freq         6                                        396   \n",
       "\n",
       "                                   name comment    star  \n",
       "count                            261497  261495  261497  \n",
       "unique                             2760  213970      11  \n",
       "top     当幸福来敲门 The Pursuit of Happyness      经典       4  \n",
       "freq                                396     200   43002  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"对数损失度量（Logarithmic Loss  Metric）的多分类版本。\n",
    "    :param actual: 包含actual target classes的数组\n",
    "    :param predicted: 分类预测结果矩阵, 每个类别都有一个概率\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评论的句子有点儿短，去掉一些停用词后可能丢失信息，试试不用停用词，简单去掉标点后分词\n",
    "with open('data/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    STOPWORDS = set([line[:-1] for line in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence_drop_stopwords(sentence):\n",
    "    return list(set(jieba.cut(sentence)) - STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    result = []\n",
    "    segment = re.findall('\\d*\\w+', sentence)\n",
    "    result += [jieba.lcut(x) for x in segment]\n",
    "    return [x for each in result for x in each if not x.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model\n",
    "wiki_model_path = r\"D:\\Github\\NLP\\Artificial_Intelligence_for_NLP\\Week_04_0727_word2vec\\Assignment\\word2vec_wiki.model\"\n",
    "wiki_model = Word2Vec.load(wiki_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用句子中词汇的平均词向量作为句子词向量\n",
    "def sentence_vector(sentence):\n",
    "    flag = 0\n",
    "    sentence_vec = np.zeros(wiki_model.vector_size)\n",
    "    nums = len(sentence)\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            sentence_vec += wiki_model.wv[word]\n",
    "            flag = 1\n",
    "        except KeyError:\n",
    "            nums -= 1\n",
    "    return np.nan if not flag else sentence_vec / nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### star 属性应该只有1-5数字或者字符串选其一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '4', '5', '3', 'star', 4, 3, 5, 2, 1], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.star.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除空评论与重复评论行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 5, 3], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "df_new.drop(df_new[df_new.star=='star'].index, inplace=True)\n",
    "df_new.dropna(subset=['comment'],inplace=True)\n",
    "df_new.drop_duplicates(subset=['comment'], inplace=True)\n",
    "df_new.star = df_new.star.apply(lambda x: int(x))\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "df_new.star.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0913 22:28:41.598145 13540 __init__.py:111] Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "I0913 22:28:41.602144 13540 __init__.py:131] Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.909 seconds.\n",
      "I0913 22:28:42.510141 13540 __init__.py:163] Loading model cost 0.909 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "I0913 22:28:42.513142 13540 __init__.py:164] Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "df_new['clean_comment'] = df_new.comment.apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从用平均词向量构建句子向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['comment_vec'] = df_new.clean_comment.apply(sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>comment_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213964</th>\n",
       "      <td>260145</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>内容只能说一般。。女性角色怎么都这么悲催啊！！不过男猪脚很帅</td>\n",
       "      <td>3</td>\n",
       "      <td>[内容, 只能, 说, 一般, 女性, 角色, 怎么, 都, 这么, 悲, 催, 啊, 不过...</td>\n",
       "      <td>[-0.9653091602958739, -0.5943305254913867, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213965</th>\n",
       "      <td>260146</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>翘了三天班就窝在家里看小基片惹（手动拜拜.gif</td>\n",
       "      <td>3</td>\n",
       "      <td>[翘, 了, 三天, 班, 就, 窝, 在, 家里, 看小, 基片, 惹, 手动, 拜拜, ...</td>\n",
       "      <td>[-0.1373161240057512, -0.9519095800139687, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213966</th>\n",
       "      <td>260147</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>我喜欢女主角，希腊雕塑一般的面庞与身体。（在一部同志题材的电影中迷恋女主角好像很不应该吧）</td>\n",
       "      <td>2</td>\n",
       "      <td>[我, 喜欢, 女主角, 希腊, 雕塑, 一般, 的, 面庞, 与, 身体, 在, 一部, ...</td>\n",
       "      <td>[-0.49309063826998073, -0.4821888374475141, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213967</th>\n",
       "      <td>260148</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>冲着颜值还可以看下去</td>\n",
       "      <td>3</td>\n",
       "      <td>[冲着, 颜值, 还, 可以, 看, 下去]</td>\n",
       "      <td>[-0.23062036807338396, -0.8813576425115267, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213968</th>\n",
       "      <td>260149</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>除了主人公都不帅，女主挺漂亮之外……唯一的感觉就是他男朋友真让人恶心</td>\n",
       "      <td>3</td>\n",
       "      <td>[除了, 主人公, 都, 不帅, 女主挺, 漂亮, 之外, 唯一, 的, 感觉, 就是, 他...</td>\n",
       "      <td>[-1.4769697139660518, 0.1903096747895082, -0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       link  \\\n",
       "213964  260145  https://movie.douban.com/subject/1441763/   \n",
       "213965  260146  https://movie.douban.com/subject/1441763/   \n",
       "213966  260147  https://movie.douban.com/subject/1441763/   \n",
       "213967  260148  https://movie.douban.com/subject/1441763/   \n",
       "213968  260149  https://movie.douban.com/subject/1441763/   \n",
       "\n",
       "                             name  \\\n",
       "213964  不羁美少年 À cause d'un garçon   \n",
       "213965  不羁美少年 À cause d'un garçon   \n",
       "213966  不羁美少年 À cause d'un garçon   \n",
       "213967  不羁美少年 À cause d'un garçon   \n",
       "213968  不羁美少年 À cause d'un garçon   \n",
       "\n",
       "                                              comment  star  \\\n",
       "213964                 内容只能说一般。。女性角色怎么都这么悲催啊！！不过男猪脚很帅     3   \n",
       "213965                       翘了三天班就窝在家里看小基片惹（手动拜拜.gif     3   \n",
       "213966  我喜欢女主角，希腊雕塑一般的面庞与身体。（在一部同志题材的电影中迷恋女主角好像很不应该吧）     2   \n",
       "213967                                     冲着颜值还可以看下去     3   \n",
       "213968             除了主人公都不帅，女主挺漂亮之外……唯一的感觉就是他男朋友真让人恶心     3   \n",
       "\n",
       "                                            clean_comment  \\\n",
       "213964  [内容, 只能, 说, 一般, 女性, 角色, 怎么, 都, 这么, 悲, 催, 啊, 不过...   \n",
       "213965  [翘, 了, 三天, 班, 就, 窝, 在, 家里, 看小, 基片, 惹, 手动, 拜拜, ...   \n",
       "213966  [我, 喜欢, 女主角, 希腊, 雕塑, 一般, 的, 面庞, 与, 身体, 在, 一部, ...   \n",
       "213967                             [冲着, 颜值, 还, 可以, 看, 下去]   \n",
       "213968  [除了, 主人公, 都, 不帅, 女主挺, 漂亮, 之外, 唯一, 的, 感觉, 就是, 他...   \n",
       "\n",
       "                                              comment_vec  \n",
       "213964  [-0.9653091602958739, -0.5943305254913867, -0....  \n",
       "213965  [-0.1373161240057512, -0.9519095800139687, 1.0...  \n",
       "213966  [-0.49309063826998073, -0.4821888374475141, -0...  \n",
       "213967  [-0.23062036807338396, -0.8813576425115267, -0...  \n",
       "213968  [-1.4769697139660518, 0.1903096747895082, -0.6...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除转化后comment_vec为nan的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>comment_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206863</th>\n",
       "      <td>260145</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>内容只能说一般。。女性角色怎么都这么悲催啊！！不过男猪脚很帅</td>\n",
       "      <td>3</td>\n",
       "      <td>[内容, 只能, 说, 一般, 女性, 角色, 怎么, 都, 这么, 悲, 催, 啊, 不过...</td>\n",
       "      <td>[-0.9653091602958739, -0.5943305254913867, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206864</th>\n",
       "      <td>260146</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>翘了三天班就窝在家里看小基片惹（手动拜拜.gif</td>\n",
       "      <td>3</td>\n",
       "      <td>[翘, 了, 三天, 班, 就, 窝, 在, 家里, 看小, 基片, 惹, 手动, 拜拜, ...</td>\n",
       "      <td>[-0.1373161240057512, -0.9519095800139687, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206865</th>\n",
       "      <td>260147</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>我喜欢女主角，希腊雕塑一般的面庞与身体。（在一部同志题材的电影中迷恋女主角好像很不应该吧）</td>\n",
       "      <td>2</td>\n",
       "      <td>[我, 喜欢, 女主角, 希腊, 雕塑, 一般, 的, 面庞, 与, 身体, 在, 一部, ...</td>\n",
       "      <td>[-0.49309063826998073, -0.4821888374475141, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206866</th>\n",
       "      <td>260148</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>冲着颜值还可以看下去</td>\n",
       "      <td>3</td>\n",
       "      <td>[冲着, 颜值, 还, 可以, 看, 下去]</td>\n",
       "      <td>[-0.23062036807338396, -0.8813576425115267, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206867</th>\n",
       "      <td>260149</td>\n",
       "      <td>https://movie.douban.com/subject/1441763/</td>\n",
       "      <td>不羁美少年 À cause d'un garçon</td>\n",
       "      <td>除了主人公都不帅，女主挺漂亮之外……唯一的感觉就是他男朋友真让人恶心</td>\n",
       "      <td>3</td>\n",
       "      <td>[除了, 主人公, 都, 不帅, 女主挺, 漂亮, 之外, 唯一, 的, 感觉, 就是, 他...</td>\n",
       "      <td>[-1.4769697139660518, 0.1903096747895082, -0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       link  \\\n",
       "206863  260145  https://movie.douban.com/subject/1441763/   \n",
       "206864  260146  https://movie.douban.com/subject/1441763/   \n",
       "206865  260147  https://movie.douban.com/subject/1441763/   \n",
       "206866  260148  https://movie.douban.com/subject/1441763/   \n",
       "206867  260149  https://movie.douban.com/subject/1441763/   \n",
       "\n",
       "                             name  \\\n",
       "206863  不羁美少年 À cause d'un garçon   \n",
       "206864  不羁美少年 À cause d'un garçon   \n",
       "206865  不羁美少年 À cause d'un garçon   \n",
       "206866  不羁美少年 À cause d'un garçon   \n",
       "206867  不羁美少年 À cause d'un garçon   \n",
       "\n",
       "                                              comment  star  \\\n",
       "206863                 内容只能说一般。。女性角色怎么都这么悲催啊！！不过男猪脚很帅     3   \n",
       "206864                       翘了三天班就窝在家里看小基片惹（手动拜拜.gif     3   \n",
       "206865  我喜欢女主角，希腊雕塑一般的面庞与身体。（在一部同志题材的电影中迷恋女主角好像很不应该吧）     2   \n",
       "206866                                     冲着颜值还可以看下去     3   \n",
       "206867             除了主人公都不帅，女主挺漂亮之外……唯一的感觉就是他男朋友真让人恶心     3   \n",
       "\n",
       "                                            clean_comment  \\\n",
       "206863  [内容, 只能, 说, 一般, 女性, 角色, 怎么, 都, 这么, 悲, 催, 啊, 不过...   \n",
       "206864  [翘, 了, 三天, 班, 就, 窝, 在, 家里, 看小, 基片, 惹, 手动, 拜拜, ...   \n",
       "206865  [我, 喜欢, 女主角, 希腊, 雕塑, 一般, 的, 面庞, 与, 身体, 在, 一部, ...   \n",
       "206866                             [冲着, 颜值, 还, 可以, 看, 下去]   \n",
       "206867  [除了, 主人公, 都, 不帅, 女主挺, 漂亮, 之外, 唯一, 的, 感觉, 就是, 他...   \n",
       "\n",
       "                                              comment_vec  \n",
       "206863  [-0.9653091602958739, -0.5943305254913867, -0....  \n",
       "206864  [-0.1373161240057512, -0.9519095800139687, 1.0...  \n",
       "206865  [-0.49309063826998073, -0.4821888374475141, -0...  \n",
       "206866  [-0.23062036807338396, -0.8813576425115267, -0...  \n",
       "206867  [-1.4769697139660518, 0.1903096747895082, -0.6...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.dropna(subset=['comment_vec'], inplace=True)\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "df_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all datasets:\t\t (206868, 200) (206868,)\n",
      "train_valid_datasets:\t (165494, 200) (165494,)\n",
      "test_datasets:\t\t (41374, 200) (41374,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_new.comment_vec.tolist())\n",
    "y = df_new.star\n",
    "train_valid_X, test_X, train_valid_y, test_y = train_test_split(X, y, test_size=.2)\n",
    "print('all datasets:\\t\\t', X.shape, y.shape)\n",
    "print('train_valid_datasets:\\t', train_valid_X.shape, train_valid_y.shape)\n",
    "print('test_datasets:\\t\\t', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(train_valid_X, train_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.23      0.28     15753\n",
      "           2       0.30      0.02      0.03     18277\n",
      "           3       0.36      0.34      0.35     41924\n",
      "           4       0.37      0.70      0.49     52972\n",
      "           5       0.43      0.21      0.28     36568\n",
      "\n",
      "    accuracy                           0.38    165494\n",
      "   macro avg       0.37      0.30      0.29    165494\n",
      "weighted avg       0.38      0.38      0.34    165494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = log_clf.predict(train_valid_X)\n",
    "print(classification_report(train_valid_y, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(train_valid_y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mat, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.20      0.23     15753\n",
      "           2       0.15      0.05      0.08     18277\n",
      "           3       0.27      0.80      0.41     41924\n",
      "           4       0.41      0.12      0.18     52972\n",
      "           5       0.40      0.11      0.17     36568\n",
      "\n",
      "    accuracy                           0.29    165494\n",
      "   macro avg       0.30      0.26      0.21    165494\n",
      "weighted avg       0.33      0.29      0.23    165494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(train_valid_X, train_valid_y)\n",
    "ypred_sgd = sgd_clf.predict(train_valid_X)\n",
    "print(classification_report(train_valid_y, ypred_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(train_valid_X, train_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.97      0.98     15753\n",
      "           2       0.98      0.97      0.97     18277\n",
      "           3       0.97      0.98      0.98     41924\n",
      "           4       0.97      0.98      0.98     52972\n",
      "           5       0.98      0.97      0.97     36568\n",
      "\n",
      "    accuracy                           0.98    165494\n",
      "   macro avg       0.98      0.97      0.98    165494\n",
      "weighted avg       0.98      0.98      0.98    165494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred_rf = rf_clf.predict(train_valid_X)\n",
    "print(classification_report(train_valid_y, ypred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 5, 3, 5, 2, 3, 4, 5, 3, 2, 4, 4, 4, 3, 3, 3, 5, 3, 1, 4, 1, 2,\n",
       "        1, 5, 4, 5, 1, 2, 4, 1], dtype=int64),\n",
       " array([2, 5, 3, 5, 2, 3, 4, 5, 3, 2, 4, 4, 4, 3, 3, 3, 5, 3, 1, 4, 1, 2,\n",
       "        1, 5, 4, 5, 1, 2, 4, 1], dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_rf[:30], train_valid_y[:30].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 严重过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.306, 0.305, 0.307, 0.31 , 0.305])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf_clf, train_valid_X, train_valid_y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.17      0.20      3931\n",
      "           2       0.16      0.10      0.13      4631\n",
      "           3       0.29      0.36      0.32     10311\n",
      "           4       0.35      0.42      0.38     13232\n",
      "           5       0.31      0.22      0.26      9269\n",
      "\n",
      "    accuracy                           0.30     41374\n",
      "   macro avg       0.27      0.26      0.26     41374\n",
      "weighted avg       0.29      0.30      0.29     41374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred_test_rf = rf_clf.predict(test_X)\n",
    "print(classification_report(test_y, ypred_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看预测与实际不符的评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_star = pd.DataFrame(ypred_test_rf, columns=['predict_star'])\n",
    "origin_df = df_new.iloc[test_y.index][['comment', 'star']]\n",
    "origin_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "      <th>predict_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>很不错的老片子，值得一看</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一般，小猪很可爱</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>影片一般吧，可能大了不怎么喜欢</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>不太喜欢这种主题，并不touchme!</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>画面很美。青涩的恋歌</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>哈哈，从小看到大永不厌倦的好片</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>看到最后虽然没有哭，但是还是有点心痛啊，嗯，泰语是真的不好听……</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>小羅莉能搞定壞叔叔?~存疑~</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>后面那段矿道追车戏很不错</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>最新清一色的5星水军，夸得好尴尬</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>如果不是看到阿德琳妮·帕里奇，我应该是不会看这个片。我现在之所以来登陆豆瓣，是因为电影看到1...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>青春照相馆，给我也来一张！近期看的韩国电影都还不错，影运上升的节奏。</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>看在某些景还可以的份上给两星</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>平淡之美</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>杜琪峰+刘青云，银河映像。</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>没上映就请这么多水郡，这是对自己的片的质量多没信心啊，不用看就是烂片</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>143分钟的华丽不知疲倦中，我没看到任何原著中的那种夜色、缄言和孤独。</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>打两星是因为我真的特别讨厌李连杰说教的嘴脸。</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>鸟枪换炮的华彩乐章。虽然相生相杀的内斗戏变成了相亲相爱的肉麻情，旋律也拨乱反正，但是各位主角...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@今敏 /8.0/</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>发哥，当年，很吸引人啊</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>除了打打杀杀，难道真没有别的事情可以追求了吗</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>什么是夏天，这几就是F**k的夏天，比猥野牛A多了！</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>想不笑，打麻药</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>故事性稍弱了点。不过我也是比较喜欢看体育励志片的，三星半比较合适。</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>我真的看不懂。。</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>直男癌晚期YY，确实是。段子仅能支撑10分钟，其他差评。</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>太可爱了那孩子，还有那孩子的爷爷</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2012June24，上海影城，上海国际电影节。</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>血与冰激凌三部曲简直是神一般的存在</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41333</th>\n",
       "      <td>没有了黎姿总觉得缺了点什么</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41334</th>\n",
       "      <td>在宿舍和室友一起看的，最后室友看不下去，大骂谢霆锋混蛋，把人家小女孩的初吻夺走了......</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41336</th>\n",
       "      <td>充满讽刺意味的成人童话 引人入胜 画面 音乐配合的很好</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41337</th>\n",
       "      <td>上飞机前翘班看的 imax 就是好 靠的很舒服 KA</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41338</th>\n",
       "      <td>这个系列越来越暮光之城，虽然和第一部完全不能相提并论，某些情节简直简单幼稚粗暴，部分画面还算...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41339</th>\n",
       "      <td>🐼生不逢時啊，看看仲代達矢。</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41340</th>\n",
       "      <td>白老师变身俄国佬，那俄式英文发音真不赖。</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41341</th>\n",
       "      <td>沒有3D照樣好看！劇本過硬，特效場面雖然不多但依然很震撼，演員群戲很到位，最重要的是敘事非常...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41342</th>\n",
       "      <td>淡淡地忧伤。有点唯。美的。</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41344</th>\n",
       "      <td>本片超级被忽视啊~~~绝对有意思~这个剧情布置在后部制造了很大的压力，让你在最后半个小时简直...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41346</th>\n",
       "      <td>我最喜欢的都市题材一个是欲望都市 一个就是麻将这种。前者适合绝望的时候看，后者适合得意忘形的...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41350</th>\n",
       "      <td>很早以前看的了 很温情</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41351</th>\n",
       "      <td>每个人要走的路，都是自己选的。PS：被小孩子的眼睛萌到。XD。</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41353</th>\n",
       "      <td>不好看 剧情很烂</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41354</th>\n",
       "      <td>重温完这个又让我想去订圆神的手办了。</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41356</th>\n",
       "      <td>萌片！从服装 布景到小孩子们 ！</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41357</th>\n",
       "      <td>一个女人的成功史</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41358</th>\n",
       "      <td>也可以改名叫:男女暧昧面面观</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41359</th>\n",
       "      <td>一如既往的好品质，中文嘴形好评。</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41360</th>\n",
       "      <td>中规中矩的剧情片。自从辛德勒的名单之后，这二十年来连姆大叔杀的坏人估计要比那次救的人还要多了~</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41361</th>\n",
       "      <td>真正催泪的情节只有最后几分钟，之前的故事和表演，让人觉得怪怪的。</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41362</th>\n",
       "      <td>最烦上纲上线的了，你有讨厌一姐的权利就不能剥夺别人讨厌你哈的星的权利。讨厌你中意的就都是一姐...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41363</th>\n",
       "      <td>烂尾啊，烂成了两星。</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41364</th>\n",
       "      <td>你让我激动十年并且一直持续</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41366</th>\n",
       "      <td>延续了上篇精美清新的画面和稀碎成渣的剧情风格，结局爱酱又回到了城市仿佛一巴掌打翻了前几个小时...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41367</th>\n",
       "      <td>这部电影是小成本的伊战中的一个小小的插曲，虽然该片的格局不大但是这是美军伊拉克战争中最重大的...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41368</th>\n",
       "      <td>就俩字  无趣</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41369</th>\n",
       "      <td>蓝色雨下不停，死亡不过是一次旅行。</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41371</th>\n",
       "      <td>黑和白就是该在一起的。黑好帅。。安心安心。</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41373</th>\n",
       "      <td>一个谎言代价如此之大，看完心里很堵……配乐和前半部的画面美呆了</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28852 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  star  predict_star\n",
       "1                                           很不错的老片子，值得一看     4             5\n",
       "2                                               一般，小猪很可爱     2             3\n",
       "3                                        影片一般吧，可能大了不怎么喜欢     2             3\n",
       "6                                    不太喜欢这种主题，并不touchme!     2             3\n",
       "7                                             画面很美。青涩的恋歌     3             5\n",
       "...                                                  ...   ...           ...\n",
       "41367  这部电影是小成本的伊战中的一个小小的插曲，虽然该片的格局不大但是这是美军伊拉克战争中最重大的...     2             3\n",
       "41368                                            就俩字  无趣     2             1\n",
       "41369                                  蓝色雨下不停，死亡不过是一次旅行。     3             5\n",
       "41371                              黑和白就是该在一起的。黑好帅。。安心安心。     5             4\n",
       "41373                    一个谎言代价如此之大，看完心里很堵……配乐和前半部的画面美呆了     4             3\n",
       "\n",
       "[28852 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.concat([origin_df, predict_star], axis=1)\n",
    "temp_df[(temp_df.star != temp_df.predict_star)]                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析错判的可能原因：\n",
    "\n",
    "讽刺的语句无法判定\n",
    "\n",
    "简短的评论无法提取有效情感信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(train_valid_X, train_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ypred_xgb = xgb_clf.predict(train_valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.16      0.24     15753\n",
      "           2       0.33      0.00      0.00     18277\n",
      "           3       0.36      0.35      0.35     41924\n",
      "           4       0.37      0.73      0.50     52972\n",
      "           5       0.45      0.19      0.27     36568\n",
      "\n",
      "    accuracy                           0.38    165494\n",
      "   macro avg       0.39      0.29      0.27    165494\n",
      "weighted avg       0.39      0.38      0.33    165494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_valid_y, ypred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuralNetwork with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir(prefix=''):\n",
    "    now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    root_logdir = 'tf_logs'\n",
    "    if prefix:\n",
    "        prefix += '-'\n",
    "    name = prefix + 'run_' + now\n",
    "    return os.path.join(root_logdir, name)\n",
    "\n",
    "\n",
    "logdir = log_dir('douban_comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_flatten, train_labels, test_flatten, test_labels):\n",
    "    reset_graph()\n",
    "    checkpoint_path = 'tmp/douban_comment'\n",
    "    units = 200\n",
    "    initial_learning_rate = .1\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                                 decay_steps=10000,\n",
    "                                                                 decay_rate=.96,\n",
    "                                                                 staircase=True)\n",
    "\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                     monitor='val_acc',\n",
    "                                                     verbose=1,\n",
    "                                                     save_best_only=True,\n",
    "                                                     load_weights_on_restart=True)\n",
    "    stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                                     mode='max',\n",
    "                                                     patience=3)\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger('csv_logger')\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(logdir)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(4 * units, activation=tf.nn.relu, input_shape=(200, )),\n",
    "        tf.keras.layers.Dropout(.5),\n",
    "        tf.keras.layers.Dense(2 * units, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(.5),\n",
    "        tf.keras.layers.Dense(units, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(.5),\n",
    "        tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr_schedule),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_flatten, train_labels, validation_split=.2,\n",
    "              epochs=100, batch_size=1024, callbacks=[cp_callback,\n",
    "                                     stop_callback,\n",
    "                                     csv_logger,\n",
    "                                     tensorboard])\n",
    "\n",
    "    print(\"Model's performance on test dataset:\")\n",
    "    print(f\"Test accuracy: {model.evaluate(test_flatten, test_labels)[1] * 100:.3f}%\")\n",
    "    model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((196272, 5), (49069, 5))"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "train_valid_y_1hot = encoder.fit_transform(train_valid_y.to_numpy().reshape(-1,1))\n",
    "test_y_1hot = encoder.fit_transform(test_y.to_numpy().reshape(-1,1))\n",
    "train_valid_y_1hot.shape, test_y_1hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157017 samples, validate on 39255 samples\n",
      "Epoch 1/100\n",
      "156672/157017 [============================>.] - ETA: 0s - loss: 1.5631 - acc: 0.3093\n",
      "Epoch 00001: val_acc improved from -inf to 0.31988, saving model to tmp/douban_comment\n",
      "157017/157017 [==============================] - 11s 72us/sample - loss: 1.5629 - acc: 0.3093 - val_loss: 1.5183 - val_acc: 0.3199\n",
      "Epoch 2/100\n",
      "156672/157017 [============================>.] - ETA: 0s - loss: 1.5180 - acc: 0.3215\n",
      "Epoch 00002: val_acc improved from 0.31988 to 0.31996, saving model to tmp/douban_comment\n",
      "157017/157017 [==============================] - 11s 71us/sample - loss: 1.5180 - acc: 0.3215 - val_loss: 1.5156 - val_acc: 0.3200\n",
      "Epoch 3/100\n",
      "156672/157017 [============================>.] - ETA: 0s - loss: 1.5138 - acc: 0.3220- ETA: 1s - \n",
      "Epoch 00003: val_acc did not improve from 0.31996\n",
      "157017/157017 [==============================] - 10s 63us/sample - loss: 1.5139 - acc: 0.3221 - val_loss: 1.5148 - val_acc: 0.3198\n",
      "Epoch 4/100\n",
      "156672/157017 [============================>.] - ETA: 0s - loss: 1.5125 - acc: 0.3223\n",
      "Epoch 00004: val_acc did not improve from 0.31996\n",
      "157017/157017 [==============================] - 10s 63us/sample - loss: 1.5125 - acc: 0.3223 - val_loss: 1.5144 - val_acc: 0.3198\n",
      "Epoch 5/100\n",
      "156672/157017 [============================>.] - ETA: 0s - loss: 1.5118 - acc: 0.3228\n",
      "Epoch 00005: val_acc did not improve from 0.31996\n",
      "157017/157017 [==============================] - 10s 63us/sample - loss: 1.5119 - acc: 0.3227 - val_loss: 1.5143 - val_acc: 0.3198\n",
      "Model's performance on test dataset:\n",
      "49069/49069 [==============================] - 3s 56us/sample - loss: 1.5147 - acc: 0.3189\n",
      "Test accuracy: 31.886%\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "train(train_valid_X, train_valid_y_1hot, test_X, test_y_1hot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
