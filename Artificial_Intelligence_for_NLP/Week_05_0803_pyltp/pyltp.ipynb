{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Install with wheel file -- python3.6 needed](./pyltp-0.2.1-cp36-cp36m-win_amd64.whl)\n",
    "![语言云架构](./ltp_framework.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyltp import Segmentor, SentenceSplitter\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'D:\\\\Tutorials\\\\0.NLP_Stanford_Daniel_Jurasfky\\\\ltp_data_v3.4.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元芳你怎么看？\n",
      "我就趴窗口上看呗！\n",
      "我也想这么看哟~\n"
     ]
    }
   ],
   "source": [
    "sents = SentenceSplitter.split('元芳你怎么看？我就趴窗口上看呗！我也想这么看哟~')\n",
    "print('\\n'.join(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cws_model_path = os.path.join(model_path, 'cws.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词\n",
    "> 比较jieba和pyltp的分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "segmentor = Segmentor()\n",
    "segmentor.load(cws_model_path)\n",
    "words = segmentor.segment('国务院总理李克强调研上海外高桥时提出，支持上海积极探索新机制。')\n",
    "words_ = jieba.cut('国务院总理李克强调研上海外高桥时提出，支持上海积极探索新机制。')\n",
    "print('\\t'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.526 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['国务院', '总理', '李克强', '调研', '上海', '外高桥', '时', '提出', '，', '支持', '上海', '积极探索', '新机制', '。']\n"
     ]
    }
   ],
   "source": [
    "print(list(words))\n",
    "print(list(words_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 个性化分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性标注 - POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_model_path = os.path.join(model_path, 'pos.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('国务院', 'ni'), ('总理', 'n'), ('李克强', 'nh'), ('调研', 'v'), ('上海', 'ns'), ('外高桥', 'ns'), ('时', 'n'), ('提出', 'v'), ('，', 'wp'), ('支持', 'v'), ('上海', 'ns'), ('积极', 'a'), ('探索', 'v'), ('新', 'a'), ('机制', 'n'), ('。', 'wp')]\n"
     ]
    }
   ],
   "source": [
    "from pyltp import Postagger\n",
    "postagger= Postagger()  # load, load_with_lexicon, postag, release\n",
    "postagger.load(pos_model_path)\n",
    "postags = postagger.postag(words)\n",
    "postags_ = zip(words, postags)\n",
    "# print('\\t'.join(postags_))\n",
    "print([x for x in postags_])\n",
    "postagger.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命名实体识别 - NER\n",
    "> * 三种实体，Ni，Nh，Ns：机构名，人名，地名\n",
    "> * S,B,I,E,O：单独，开始，中间，结束，非命名实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('国务院', 'S-Ni'), ('总理', 'O'), ('李克强', 'S-Nh'), ('调研', 'O'), ('上海', 'B-Ns'), ('外高桥', 'E-Ns'), ('时', 'O'), ('提出', 'O'), ('，', 'O'), ('支持', 'O'), ('上海', 'S-Ns'), ('积极', 'O'), ('探索', 'O'), ('新', 'O'), ('机制', 'O'), ('。', 'O')]\n"
     ]
    }
   ],
   "source": [
    "ner_model_path = os.path.join(model_path, 'ner.model')\n",
    "from pyltp import NamedEntityRecognizer\n",
    "\n",
    "recognizer = NamedEntityRecognizer()\n",
    "recognizer.load(ner_model_path)\n",
    "netags = recognizer.recognize(words, postags)\n",
    "netags_=zip(words,netags)\n",
    "# print('\\t'.join(netags))\n",
    "print(list(netags_))\n",
    "recognizer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依存句法分析 - DP\n",
    "![](./依存句法分析.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:ATT\t3:ATT\t4:SBV\t7:ATT\t6:ATT\t4:VOB\t8:ADV\t0:HED\t8:WP\t8:COO\t13:SBV\t13:ADV\t10:VOB\t15:ATT\t13:VOB\t8:WP\n"
     ]
    }
   ],
   "source": [
    "par_model_path = os.path.join(model_path, 'parser.model')\n",
    "from pyltp import Parser\n",
    "parser = Parser()\n",
    "parser.load(par_model_path)\n",
    "arcs = parser.parse(words, postags)\n",
    "print('\\t'.join(f\"{arc.head}:{arc.relation}\" for arc in arcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语义角色标注 - SRL\n",
    "> 3.4.0 版本 SRL模型 pisrl.model 如在windows系统下不可用，可以到[此链接](http://model.scir.yunfutech.com/server/3.4.0/pisrl_win.model)下载支持windows的语义角色标注模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['国务院', '总理', '李克强', '调研', '上海', '外高桥', '时', '提出', '，', '支持', '上海', '积极', '探索', '新', '机制', '。']\n",
      "7 TMP:(0,6)A1:(9,14)\n",
      "9 A1:(10,10)\n"
     ]
    }
   ],
   "source": [
    "srl_model_path = os.path.join(model_path, 'pisrl_win.model')\n",
    "from pyltp import SementicRoleLabeller\n",
    "labeller = SementicRoleLabeller()\n",
    "labeller.load(srl_model_path)\n",
    "roles = labeller.label(words, postags, arcs)\n",
    "print(list(words))\n",
    "for role in roles:\n",
    "    print(role.index, ''.join([f\"{arg.name}:({arg.range.start},{arg.range.end})\" for arg in role\n",
    "                             .arguments]))\n",
    "labeller.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语义依存分析\n",
    "> pyltp不提供，可使用[语言云](http://www.ltp-cloud.com/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
