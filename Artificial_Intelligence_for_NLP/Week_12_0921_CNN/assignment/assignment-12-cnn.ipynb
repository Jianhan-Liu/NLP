{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = r\"D:\\Github\\NLP\\Artificial_Intelligence_for_NLP\\Week_09_0831_kmeans_NN\\assignments\\notMNIST.pickle\"\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "# filter numbers\n",
    "depth = 16\n",
    "# full connection layers neuron number\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    \n",
    "    layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "    layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "    # Model.\n",
    "    def model(data):\n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.151056\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 8.7%\n",
      "Test accuracy: 8.5%\n",
      "Minibatch loss at step 50: 2.040035\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 48.3%\n",
      "Test accuracy: 53.3%\n",
      "Minibatch loss at step 100: 1.271775\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 70.9%\n",
      "Test accuracy: 78.0%\n",
      "Minibatch loss at step 150: 1.246942\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 74.5%\n",
      "Test accuracy: 81.8%\n",
      "Minibatch loss at step 200: 0.548821\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.7%\n",
      "Test accuracy: 84.8%\n",
      "Minibatch loss at step 250: 0.885539\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.7%\n",
      "Test accuracy: 85.0%\n",
      "Minibatch loss at step 300: 1.440071\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 78.6%\n",
      "Test accuracy: 86.2%\n",
      "Minibatch loss at step 350: 0.947232\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 78.9%\n",
      "Test accuracy: 86.1%\n",
      "Minibatch loss at step 400: 0.848926\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.5%\n",
      "Test accuracy: 87.0%\n",
      "Minibatch loss at step 450: 0.351126\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.3%\n",
      "Test accuracy: 87.2%\n",
      "Minibatch loss at step 500: 0.530491\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.7%\n",
      "Test accuracy: 86.9%\n",
      "Minibatch loss at step 550: 0.745018\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "Test accuracy: 86.2%\n",
      "Minibatch loss at step 600: 0.924703\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.5%\n",
      "Minibatch loss at step 650: 0.515112\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.6%\n",
      "Minibatch loss at step 700: 0.807125\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.5%\n",
      "Minibatch loss at step 750: 0.168780\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.7%\n",
      "Test accuracy: 88.5%\n",
      "Minibatch loss at step 800: 1.036486\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.5%\n",
      "Minibatch loss at step 850: 0.370531\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.0%\n",
      "Test accuracy: 88.7%\n",
      "Minibatch loss at step 900: 0.140178\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 82.5%\n",
      "Test accuracy: 89.2%\n",
      "Minibatch loss at step 950: 0.962624\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.5%\n",
      "Test accuracy: 89.1%\n",
      "Minibatch loss at step 1000: 0.783010\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.3%\n",
      "Test accuracy: 88.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 50 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "            print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 28, 28, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    tf.reset_default_graph()\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(depth, (patch_size, patch_size), strides=(2, 2), padding='same',\n",
    "                           activation='relu', kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1), \n",
    "                            input_shape=(28,28,1)),\n",
    "        keras.layers.Conv2D(depth, (patch_size, patch_size), (2,2), 'same', activation='relu',\n",
    "                           kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1),\n",
    "                           bias_initializer='ones'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(num_hidden, activation='relu',kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1),\n",
    "                          bias_initializer='ones'),\n",
    "        keras.layers.Dense(num_labels, activation='softmax', kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1),\n",
    "                          bias_initializer='ones')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.SGD(.05),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(train_dataset, train_labels, validation_data=(valid_dataset, valid_labels), epochs=1, \n",
    "              batch_size=batch_size)\n",
    "    print(\"Model's performance on test dataset:\")\n",
    "    print(f\"Test accuracy: {model.evaluate(test_dataset, test_labels)[1] * 100:.3f}%\")\n",
    "#     model.save('final_model.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 10000 samples\n",
      "200000/200000 [==============================] - 58s 288us/sample - loss: 0.4458 - acc: 0.8651 - val_loss: 0.3458 - val_acc: 0.8935\n",
      "Model's performance on test dataset:\n",
      "10000/10000 [==============================] - 1s 70us/sample - loss: 0.1696 - acc: 0.9497\n",
      "Test accuracy: 94.970%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x271a8a8a4a8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth,patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    tf.reset_default_graph()\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(depth, (patch_size, patch_size), padding='same',\n",
    "                           activation='relu', kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1), \n",
    "                            input_shape=(28,28,1)),\n",
    "        keras.layers.MaxPooling2D(strides=2),\n",
    "        keras.layers.Conv2D(depth, (patch_size, patch_size), padding='same', activation='relu',\n",
    "                           kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1),\n",
    "                           bias_initializer='ones'),\n",
    "        keras.layers.MaxPooling2D(strides=2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(num_hidden, activation='relu',kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1),\n",
    "                          bias_initializer='ones'),\n",
    "        keras.layers.Dense(num_labels, activation='softmax', kernel_initializer=keras.initializers.TruncatedNormal(stddev=.1),\n",
    "                          bias_initializer='ones')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.SGD(.05),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(train_dataset, train_labels, validation_data=(valid_dataset, valid_labels), epochs=1, \n",
    "              batch_size=batch_size)\n",
    "    print(\"Model's performance on test dataset:\")\n",
    "    print(f\"Test accuracy: {model.evaluate(test_dataset, test_labels)[1] * 100:.3f}%\")\n",
    "#     model.save('final_model.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 10000 samples\n",
      "200000/200000 [==============================] - 133s 666us/sample - loss: 0.4233 - acc: 0.8714 - val_loss: 0.3331 - val_acc: 0.8992\n",
      "Model's performance on test dataset:\n",
      "10000/10000 [==============================] - 1s 141us/sample - loss: 0.1650 - acc: 0.9525\n",
      "Test accuracy: 95.250%\n"
     ]
    }
   ],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 57,722\n",
      "Trainable params: 57,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 28*28\n",
    "kernel_init = keras.initializers.TruncatedNormal(stddev=.1)\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(.1,\n",
    "                                                         decay_steps=10000,\n",
    "                                                         decay_rate=.96,\n",
    "                                                         staircase=True)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('csv_logger')\n",
    "stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                                     mode='max',\n",
    "                                                     patience=3)\n",
    "checkpoint_path = 'tmp/notMNIST.cpt'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                     monitor='val_acc',\n",
    "                                                     verbose=1,\n",
    "                                                     save_best_only=True,\n",
    "                                                     load_weights_on_restart=True)\n",
    "\n",
    "def train():\n",
    "    tf.reset_default_graph()\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(16, (5, 5), padding='same',\n",
    "                           activation='relu', kernel_initializer=kernel_init, \n",
    "                            input_shape=(28,28,1)),\n",
    "        keras.layers.MaxPooling2D(strides=2),\n",
    "        keras.layers.Dropout(.25),\n",
    "        keras.layers.Conv2D(16, (5, 5), padding='same', activation='relu',\n",
    "                           kernel_initializer=kernel_init,\n",
    "                           bias_initializer='ones'),\n",
    "        keras.layers.MaxPooling2D(strides=2),\n",
    "        keras.layers.Dropout(.25),\n",
    "        keras.layers.Flatten(),\n",
    "#         keras.layers.Dense(120, activation='relu',kernel_initializer=kernel_init,\n",
    "#                           bias_initializer='ones'),\n",
    "#         keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(64, activation='relu',kernel_initializer=kernel_init,\n",
    "                          bias_initializer='ones'),\n",
    "        keras.layers.Dropout(.3),\n",
    "#         keras.layers.Dense(N, activation='relu',kernel_initializer=kernel_init,\n",
    "#                           bias_initializer='ones'),\n",
    "#         keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(10, activation='softmax', kernel_initializer=kernel_init,\n",
    "                          bias_initializer='ones')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr_schedule),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(train_dataset, train_labels, validation_data=(valid_dataset, valid_labels), epochs=100, \n",
    "              batch_size=1024, callbacks=[cp_callback,\n",
    "                                     stop_callback,\n",
    "                                     csv_logger])\n",
    "    print(\"Model's performance on test dataset:\")\n",
    "    print(f\"Test accuracy: {model.evaluate(test_dataset, test_labels)[1] * 100:.3f}%\")\n",
    "#     model.save('final_model.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.7003 - acc: 0.7815\n",
      "Epoch 00001: val_acc improved from -inf to 0.88360, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 398us/sample - loss: 0.7001 - acc: 0.7816 - val_loss: 0.3807 - val_acc: 0.8836\n",
      "Epoch 2/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.5690 - acc: 0.8260\n",
      "Epoch 00002: val_acc improved from 0.88360 to 0.88430, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 399us/sample - loss: 0.5690 - acc: 0.8260 - val_loss: 0.3776 - val_acc: 0.8843\n",
      "Epoch 3/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.5313 - acc: 0.8379\n",
      "Epoch 00003: val_acc improved from 0.88430 to 0.88530, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 79s 397us/sample - loss: 0.5314 - acc: 0.8379 - val_loss: 0.3737 - val_acc: 0.8853\n",
      "Epoch 4/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.5114 - acc: 0.8445\n",
      "Epoch 00004: val_acc improved from 0.88530 to 0.88730, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 79s 397us/sample - loss: 0.5115 - acc: 0.8445 - val_loss: 0.3677 - val_acc: 0.8873\n",
      "Epoch 5/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4945 - acc: 0.8494\n",
      "Epoch 00005: val_acc improved from 0.88730 to 0.89050, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 398us/sample - loss: 0.4946 - acc: 0.8494 - val_loss: 0.3599 - val_acc: 0.8905\n",
      "Epoch 6/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.8535\n",
      "Epoch 00006: val_acc improved from 0.89050 to 0.89130, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 398us/sample - loss: 0.4848 - acc: 0.8535 - val_loss: 0.3583 - val_acc: 0.8913\n",
      "Epoch 7/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4745 - acc: 0.8560\n",
      "Epoch 00007: val_acc improved from 0.89130 to 0.89300, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 399us/sample - loss: 0.4745 - acc: 0.8560 - val_loss: 0.3532 - val_acc: 0.8930\n",
      "Epoch 8/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.8588\n",
      "Epoch 00008: val_acc improved from 0.89300 to 0.89330, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 79s 397us/sample - loss: 0.4656 - acc: 0.8588 - val_loss: 0.3526 - val_acc: 0.8933\n",
      "Epoch 9/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8610\n",
      "Epoch 00009: val_acc improved from 0.89330 to 0.89410, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 79s 397us/sample - loss: 0.4597 - acc: 0.8610 - val_loss: 0.3505 - val_acc: 0.8941\n",
      "Epoch 10/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8635\n",
      "Epoch 00010: val_acc improved from 0.89410 to 0.89490, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.4525 - acc: 0.8635 - val_loss: 0.3472 - val_acc: 0.8949\n",
      "Epoch 11/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8641\n",
      "Epoch 00011: val_acc improved from 0.89490 to 0.89510, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.4499 - acc: 0.8641 - val_loss: 0.3450 - val_acc: 0.8951\n",
      "Epoch 12/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8653\n",
      "Epoch 00012: val_acc improved from 0.89510 to 0.89690, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 81s 407us/sample - loss: 0.4447 - acc: 0.8653 - val_loss: 0.3406 - val_acc: 0.8969\n",
      "Epoch 13/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8664\n",
      "Epoch 00013: val_acc did not improve from 0.89690\n",
      "200000/200000 [==============================] - 80s 398us/sample - loss: 0.4409 - acc: 0.8665 - val_loss: 0.3418 - val_acc: 0.8966\n",
      "Epoch 14/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4353 - acc: 0.8676\n",
      "Epoch 00014: val_acc improved from 0.89690 to 0.89700, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 82s 412us/sample - loss: 0.4352 - acc: 0.8677 - val_loss: 0.3394 - val_acc: 0.8970\n",
      "Epoch 15/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4332 - acc: 0.8690\n",
      "Epoch 00015: val_acc improved from 0.89700 to 0.89760, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.4331 - acc: 0.8690 - val_loss: 0.3371 - val_acc: 0.8976\n",
      "Epoch 16/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4290 - acc: 0.8700\n",
      "Epoch 00016: val_acc improved from 0.89760 to 0.89850, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.4291 - acc: 0.8700 - val_loss: 0.3357 - val_acc: 0.8985\n",
      "Epoch 17/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4247 - acc: 0.8712\n",
      "Epoch 00017: val_acc did not improve from 0.89850\n",
      "200000/200000 [==============================] - 80s 401us/sample - loss: 0.4247 - acc: 0.8712 - val_loss: 0.3355 - val_acc: 0.8973\n",
      "Epoch 18/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4241 - acc: 0.8712\n",
      "Epoch 00018: val_acc did not improve from 0.89850\n",
      "200000/200000 [==============================] - 80s 401us/sample - loss: 0.4242 - acc: 0.8712 - val_loss: 0.3339 - val_acc: 0.8982\n",
      "Epoch 19/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4218 - acc: 0.8719\n",
      "Epoch 00019: val_acc improved from 0.89850 to 0.89870, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 399us/sample - loss: 0.4217 - acc: 0.8719 - val_loss: 0.3302 - val_acc: 0.8987\n",
      "Epoch 20/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4172 - acc: 0.8726\n",
      "Epoch 00020: val_acc improved from 0.89870 to 0.89900, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.4173 - acc: 0.8726 - val_loss: 0.3310 - val_acc: 0.8990\n",
      "Epoch 21/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4153 - acc: 0.8736\n",
      "Epoch 00021: val_acc improved from 0.89900 to 0.89930, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 81s 404us/sample - loss: 0.4155 - acc: 0.8735 - val_loss: 0.3278 - val_acc: 0.8993\n",
      "Epoch 22/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8748\n",
      "Epoch 00022: val_acc improved from 0.89930 to 0.90040, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 401us/sample - loss: 0.4128 - acc: 0.8748 - val_loss: 0.3268 - val_acc: 0.9004\n",
      "Epoch 23/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4113 - acc: 0.8750\n",
      "Epoch 00023: val_acc improved from 0.90040 to 0.90150, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 402us/sample - loss: 0.4113 - acc: 0.8751 - val_loss: 0.3238 - val_acc: 0.9015\n",
      "Epoch 24/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8758\n",
      "Epoch 00024: val_acc did not improve from 0.90150\n",
      "200000/200000 [==============================] - 80s 399us/sample - loss: 0.4100 - acc: 0.8758 - val_loss: 0.3232 - val_acc: 0.9011\n",
      "Epoch 25/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8768\n",
      "Epoch 00025: val_acc did not improve from 0.90150\n",
      "200000/200000 [==============================] - 80s 401us/sample - loss: 0.4072 - acc: 0.8768 - val_loss: 0.3230 - val_acc: 0.9006\n",
      "Epoch 26/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4069 - acc: 0.8766\n",
      "Epoch 00026: val_acc improved from 0.90150 to 0.90210, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 82s 408us/sample - loss: 0.4069 - acc: 0.8767 - val_loss: 0.3221 - val_acc: 0.9021\n",
      "Epoch 27/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4048 - acc: 0.8774\n",
      "Epoch 00027: val_acc did not improve from 0.90210\n",
      "200000/200000 [==============================] - 80s 401us/sample - loss: 0.4050 - acc: 0.8773 - val_loss: 0.3211 - val_acc: 0.9020\n",
      "Epoch 28/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.8776\n",
      "Epoch 00028: val_acc did not improve from 0.90210\n",
      "200000/200000 [==============================] - 80s 399us/sample - loss: 0.4030 - acc: 0.8776 - val_loss: 0.3212 - val_acc: 0.9007\n",
      "Epoch 29/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.4012 - acc: 0.8782\n",
      "Epoch 00029: val_acc improved from 0.90210 to 0.90330, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 401us/sample - loss: 0.4012 - acc: 0.8782 - val_loss: 0.3172 - val_acc: 0.9033\n",
      "Epoch 30/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3993 - acc: 0.8794\n",
      "Epoch 00030: val_acc improved from 0.90330 to 0.90340, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3993 - acc: 0.8794 - val_loss: 0.3167 - val_acc: 0.9034\n",
      "Epoch 31/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3970 - acc: 0.8801\n",
      "Epoch 00031: val_acc improved from 0.90340 to 0.90370, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3970 - acc: 0.8801 - val_loss: 0.3158 - val_acc: 0.9037\n",
      "Epoch 32/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8803\n",
      "Epoch 00032: val_acc did not improve from 0.90370\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3964 - acc: 0.8804 - val_loss: 0.3164 - val_acc: 0.9029\n",
      "Epoch 33/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8809\n",
      "Epoch 00033: val_acc did not improve from 0.90370\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3937 - acc: 0.8809 - val_loss: 0.3149 - val_acc: 0.9034\n",
      "Epoch 34/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3928 - acc: 0.8807\n",
      "Epoch 00034: val_acc improved from 0.90370 to 0.90450, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3927 - acc: 0.8807 - val_loss: 0.3134 - val_acc: 0.9045\n",
      "Epoch 35/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3919 - acc: 0.8807\n",
      "Epoch 00035: val_acc improved from 0.90450 to 0.90500, saving model to tmp/notMNIST.cpt\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3919 - acc: 0.8807 - val_loss: 0.3136 - val_acc: 0.9050\n",
      "Epoch 36/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3915 - acc: 0.8819\n",
      "Epoch 00036: val_acc did not improve from 0.90500\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3915 - acc: 0.8819 - val_loss: 0.3124 - val_acc: 0.9035\n",
      "Epoch 37/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3900 - acc: 0.8814\n",
      "Epoch 00037: val_acc did not improve from 0.90500\n",
      "200000/200000 [==============================] - 80s 401us/sample - loss: 0.3901 - acc: 0.8814 - val_loss: 0.3112 - val_acc: 0.9041\n",
      "Epoch 38/100\n",
      "199680/200000 [============================>.] - ETA: 0s - loss: 0.3882 - acc: 0.8815\n",
      "Epoch 00038: val_acc did not improve from 0.90500\n",
      "200000/200000 [==============================] - 80s 400us/sample - loss: 0.3883 - acc: 0.8815 - val_loss: 0.3125 - val_acc: 0.9043\n",
      "Model's performance on test dataset:\n",
      "10000/10000 [==============================] - 2s 151us/sample - loss: 0.1476 - acc: 0.9552\n",
      "Test accuracy: 95.520%\n"
     ]
    }
   ],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with dropout\n",
    "df = pd.read_csv('csv_logger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='epoch', y=['acc','loss','val_acc','val_loss'],grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without dropout\n",
    "df = pd.read_csv('csv_logger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.681140</td>\n",
       "      <td>1.093023</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.636180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.840655</td>\n",
       "      <td>0.555267</td>\n",
       "      <td>0.8526</td>\n",
       "      <td>0.518596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.485368</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>0.466082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.868665</td>\n",
       "      <td>0.450360</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0.451560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.875260</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.421431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       acc      loss  val_acc  val_loss\n",
       "0      0  0.681140  1.093023   0.8172  0.636180\n",
       "1      1  0.840655  0.555267   0.8526  0.518596\n",
       "2      2  0.859570  0.485368   0.8661  0.466082\n",
       "3      3  0.868665  0.450360   0.8690  0.451560\n",
       "4      4  0.875260  0.426966   0.8768  0.421431"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='epoch', y=['acc','loss','val_acc','val_loss'],grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more computional resources needed to train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 28*28\n",
    "kernel_init = keras.initializers.TruncatedNormal(stddev=.1)\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(.1,\n",
    "                                                         decay_steps=10000,\n",
    "                                                         decay_rate=.96,\n",
    "                                                         staircase=True)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('csv_logger')\n",
    "stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                                     mode='max',\n",
    "                                                     patience=3)\n",
    "checkpoint_path = 'tmp/notMNIST.cpk'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                     monitor='val_acc',\n",
    "                                                     verbose=1,\n",
    "                                                     save_best_only=True,\n",
    "                                                     load_weights_on_restart=True)\n",
    "\n",
    "def train():\n",
    "    tf.reset_default_graph()\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, (3, 3), padding='same',\n",
    "                           activation='relu', kernel_initializer=kernel_init, \n",
    "                            input_shape=(28,28,1)),\n",
    "        keras.layers.MaxPooling2D(strides=2),\n",
    "        keras.layers.Dropout(.25),\n",
    "        keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "                           kernel_initializer=kernel_init,\n",
    "                           bias_initializer='ones'),\n",
    "        keras.layers.MaxPooling2D(strides=2),\n",
    "        keras.layers.Dropout(.25),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(4*N, activation='relu',kernel_initializer=kernel_init,\n",
    "                          bias_initializer='ones'),\n",
    "        keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(2*N, activation='relu',kernel_initializer=kernel_init,\n",
    "                          bias_initializer='ones'),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.Dense(N, activation='relu',kernel_initializer=kernel_init,\n",
    "                          bias_initializer='ones'),\n",
    "        keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(10, activation='softmax', kernel_initializer=kernel_init,\n",
    "                          bias_initializer='ones')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr_schedule),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(train_dataset, train_labels, validation_data=(valid_dataset, valid_labels), epochs=100, \n",
    "              batch_size=1024, callbacks=[cp_callback,\n",
    "                                     stop_callback,\n",
    "                                     csv_logger])\n",
    "    print(\"Model's performance on test dataset:\")\n",
    "    print(f\"Test accuracy: {model.evaluate(test_dataset, test_labels)[1] * 100:.3f}%\")\n",
    "#     model.save('final_model.h5')\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
