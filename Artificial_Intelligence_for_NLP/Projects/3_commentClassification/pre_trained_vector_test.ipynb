{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# google news vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 21:27:25.600454  4292 utils_any2vec.py:341] loading projection weights from D:\\Github\\NLP\\Projects\\data\\pre_trained_vectors\\GoogleNews-vectors-negative300.bin\n",
      "I1029 21:30:07.764456  4292 utils_any2vec.py:405] loaded (3000000, 300) matrix from D:\\Github\\NLP\\Projects\\data\\pre_trained_vectors\\GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "google_wv_filename = r\"D:\\Github\\NLP\\Projects\\data\\pre_trained_vectors\\GoogleNews-vectors-negative300.bin\"\n",
    "google_wv = KeyedVectors.load_word2vec_format(google_wv_filename, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 百度百科"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 21:35:10.806174  4292 utils_any2vec.py:341] loading projection weights from D:\\Github\\NLP\\Projects\\data\\pre_trained_vectors\\baike_26g_news_13g_novel_229g.bin\n",
      "I1029 21:40:26.757173  4292 utils_any2vec.py:405] loaded (6400505, 128) matrix from D:\\Github\\NLP\\Projects\\data\\pre_trained_vectors\\baike_26g_news_13g_novel_229g.bin\n"
     ]
    }
   ],
   "source": [
    "baike_wv_filename = r\"D:\\Github\\NLP\\Projects\\data\\pre_trained_vectors\\baike_26g_news_13g_novel_229g.bin\"\n",
    "baike_wv = KeyedVectors.load_word2vec_format(baike_wv_filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('讲', 0.6345256567001343),\n",
       " ('问', 0.6092720031738281),\n",
       " ('没说', 0.5879335403442383),\n",
       " ('没说的', 0.5767871141433716),\n",
       " ('刚说', 0.5705879926681519),\n",
       " ('直说', 0.557326078414917),\n",
       " ('真说', 0.5523277521133423),\n",
       " ('胡扯', 0.5383740663528442),\n",
       " ('瞎扯', 0.5360615849494934),\n",
       " ('听', 0.5272223353385925),\n",
       " ('要说', 0.5225738286972046),\n",
       " ('小七说', 0.5091441869735718),\n",
       " ('没问', 0.5081528425216675),\n",
       " ('慢慢说', 0.5059524774551392),\n",
       " ('没有说的', 0.5027167797088623),\n",
       " ('没答', 0.4999498426914215),\n",
       " ('嗦', 0.4983299970626831),\n",
       " ('说个', 0.49799156188964844),\n",
       " ('小四说', 0.49772530794143677),\n",
       " ('没聊', 0.49739447236061096),\n",
       " ('洛洛说', 0.49544787406921387),\n",
       " ('敷衍', 0.4926813840866089),\n",
       " ('解释', 0.49222949147224426),\n",
       " ('文说', 0.490719199180603),\n",
       " ('讲些', 0.4864034950733185),\n",
       " ('时说', 0.4855092167854309),\n",
       " ('说了半天', 0.4854474663734436),\n",
       " ('回着', 0.4820387661457062),\n",
       " ('说点', 0.4807654917240143),\n",
       " ('乱说', 0.4786990284919739),\n",
       " ('没句', 0.47843724489212036),\n",
       " ('抱怨', 0.4769146144390106),\n",
       " ('鬼扯', 0.47632184624671936),\n",
       " ('道歉', 0.47617805004119873),\n",
       " ('听不进去', 0.4740089774131775),\n",
       " ('阿九说', 0.4739168882369995),\n",
       " ('刚一说', 0.4737130403518677),\n",
       " ('磨叽', 0.4723018705844879),\n",
       " ('小九说', 0.47223788499832153),\n",
       " ('胡说', 0.4720418155193329)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baike_wv.wv.most_similar(['说'], topn=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400505"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(baike_wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wiki fasttext word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\nlp\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7c5de29e2337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcc_zh_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"D:/Github/NLP/Artificial_Intelligence_for_NLP/Projects/3_commentClassification/data/cc.zh.300.vec/cc.zh.300.vec\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcc_zh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcc_zh_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1492\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1493\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1494\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mline_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cc_zh_filename = r\"D:/Github/NLP/Artificial_Intelligence_for_NLP/Projects/3_commentClassification/data/cc.zh.300.vec/cc.zh.300.vec\"\n",
    "cc_zh = KeyedVectors.load_word2vec_format(cc_zh_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
