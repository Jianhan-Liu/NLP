{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹 'D:\\Github\\NLP\\Artificial_Intelligence_for_NLP\\Projects\\3_commentClassification\\temp' 将被用来存储语料和临时性字典\n",
      "2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1110 23:09:09.120841 15152 textcleaner.py:37] 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from smart_open import smart_open\n",
    "\n",
    "TEMP_FOLDER = os.path.abspath('./temp/')\n",
    "print(f\"文件夹 '{TEMP_FOLDER}' 将被用来存储语料和临时性字典\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s: %(levelname)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as  plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, SpatialDropout1D, add, concatenate\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stopwords(filename):\n",
    "    stopwords = [line.strip() for line in smart_open(filename, 'r', encoding='utf-8')]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '（', '）', '(']\n"
     ]
    }
   ],
   "source": [
    "stopwords = fetch_stopwords('data/stopwords.txt')\n",
    "stopwords.append('\\n')\n",
    "print(stopwords[:10])\n",
    "# 提高查询速度\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(content):\n",
    "    content = jieba.cut(content)\n",
    "    return [word for word in content if word not in stopwords if word.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(word_index, model):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, model.wv.vectors.shape[1]))\n",
    "    for word, index in word_index.items():\n",
    "        try:\n",
    "            embedding_matrix[index] = model.wv[word.lower()]\n",
    "        except:\n",
    "            pass\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词向量的选择\n",
    "- 已有的\n",
    "- 针对项目内容训练的（词频大于5的不存在OOV问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/training.csv')\n",
    "validation_df = pd.read_csv('data/validation.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"之前评价了莫名其妙被删 果断继续差评！ 换了菜单 价格更低 开始砸牌子 但套餐还是有150...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"出乎意料地惊艳，椰子鸡清热降火，美容养颜，大大满足了爱吃火锅怕上火星人。椰子冻是帅帅的老板...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content  \\\n",
       "0   0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "1   1  \"第三次参加大众点评网霸王餐的活动。这家店给人整体感觉一般。首先环境只能算中等，其次霸王餐提...   \n",
       "2   2  \"4人同行 点了10个小吃\\n榴莲酥 榴莲味道不足 松软 奶味浓\\n虾饺 好吃 两颗大虾仁\\...   \n",
       "3   3  \"之前评价了莫名其妙被删 果断继续差评！ 换了菜单 价格更低 开始砸牌子 但套餐还是有150...   \n",
       "4   4  \"出乎意料地惊艳，椰子鸡清热降火，美容养颜，大大满足了爱吃火锅怕上火星人。椰子冻是帅帅的老板...   \n",
       "\n",
       "   location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                            -2                                        -2   \n",
       "1                            -2                                        -2   \n",
       "2                            -2                                        -2   \n",
       "3                            -2                                        -2   \n",
       "4                            -2                                        -2   \n",
       "\n",
       "   location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                     -2                 -2                         1   \n",
       "1                     -2                 -2                        -2   \n",
       "2                     -2                 -2                         0   \n",
       "3                     -2                 -2                        -2   \n",
       "4                     -2                 -2                        -2   \n",
       "\n",
       "   service_parking_convenience  service_serving_speed  price_level  ...  \\\n",
       "0                           -2                     -2           -2  ...   \n",
       "1                           -2                     -2            0  ...   \n",
       "2                           -2                      1            0  ...   \n",
       "3                           -2                     -2            0  ...   \n",
       "4                           -2                     -2           -2  ...   \n",
       "\n",
       "   environment_decoration  environment_noise  environment_space  \\\n",
       "0                      -2                 -2                 -2   \n",
       "1                       0                  0                  0   \n",
       "2                      -2                 -2                  1   \n",
       "3                      -2                 -2                 -2   \n",
       "4                      -2                 -2                 -2   \n",
       "\n",
       "   environment_cleaness  dish_portion  dish_taste  dish_look  \\\n",
       "0                    -2            -2          -2          1   \n",
       "1                     0             1          -2         -2   \n",
       "2                    -2             0           1         -2   \n",
       "3                    -2            -2          -1         -2   \n",
       "4                    -2            -2           1          1   \n",
       "\n",
       "   dish_recommendation  others_overall_experience  \\\n",
       "0                   -2                          1   \n",
       "1                   -2                          1   \n",
       "2                   -2                          0   \n",
       "3                   -2                         -1   \n",
       "4                   -2                          1   \n",
       "\n",
       "   others_willing_to_consume_again  \n",
       "0                               -2  \n",
       "1                               -2  \n",
       "2                               -2  \n",
       "3                               -1  \n",
       "4                               -2  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'content', 'location_traffic_convenience',\n",
       "       'location_distance_from_business_district', 'location_easy_to_find',\n",
       "       'service_wait_time', 'service_waiters_attitude',\n",
       "       'service_parking_convenience', 'service_serving_speed', 'price_level',\n",
       "       'price_cost_effective', 'price_discount', 'environment_decoration',\n",
       "       'environment_noise', 'environment_space', 'environment_cleaness',\n",
       "       'dish_portion', 'dish_taste', 'dish_look', 'dish_recommendation',\n",
       "       'others_overall_experience', 'others_willing_to_consume_again'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, validation_size, test_size = len(train_df), len(validation_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134995</th>\n",
       "      <td>\"杭州大厦周围的日料店有三上、山葵这样的连锁店，听说三上除了C座地下一楼的那家以外还要在D座...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134996</th>\n",
       "      <td>\"非常物美价廉的一家自助餐厅，虽是中午，之前担心的货少量不足的问题完全没出现，最爱的三文鱼、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134997</th>\n",
       "      <td>\"生日的时候不知道去吃什么，偶然在大牌抢购里发现了这家店～感觉团购很给力，就果断团了一份～地...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134998</th>\n",
       "      <td>\"每次来大理都有不一样的感动，还记得上次来大理遇到一个特别好的出租车司机，这次来大理同样是这...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134999</th>\n",
       "      <td>\"这家店位于城中湖码头，靠近广场非常近，离我们的住处比较近，开车过来只要几分钟的时间就好了。...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content\n",
       "134995  \"杭州大厦周围的日料店有三上、山葵这样的连锁店，听说三上除了C座地下一楼的那家以外还要在D座...\n",
       "134996  \"非常物美价廉的一家自助餐厅，虽是中午，之前担心的货少量不足的问题完全没出现，最爱的三文鱼、...\n",
       "134997  \"生日的时候不知道去吃什么，偶然在大牌抢购里发现了这家店～感觉团购很给力，就果断团了一份～地...\n",
       "134998  \"每次来大理都有不一样的感动，还记得上次来大理遇到一个特别好的出租车司机，这次来大理同样是这...\n",
       "134999  \"这家店位于城中湖码头，靠近广场非常近，离我们的住处比较近，开车过来只要几分钟的时间就好了。..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_content = pd.concat([train_df.content, validation_df.content, test_df.content],\n",
    "                        axis=0, ignore_index=True).to_frame()\n",
    "full_content.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 40s\n"
     ]
    }
   ],
   "source": [
    "%time full_content['clean_content'] = full_content.content.apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_content.to_csv('data/full_clean_content.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 23:43:59.048060  4732 word2vec.py:1587] collecting all words and their counts\n",
      "I1029 23:43:59.053062  4732 word2vec.py:1572] PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "I1029 23:43:59.325059  4732 word2vec.py:1572] PROGRESS: at sentence #10000, processed 1018024 words, keeping 65721 word types\n",
      "I1029 23:43:59.589059  4732 word2vec.py:1572] PROGRESS: at sentence #20000, processed 2026955 words, keeping 94570 word types\n",
      "I1029 23:43:59.857060  4732 word2vec.py:1572] PROGRESS: at sentence #30000, processed 3032507 words, keeping 116549 word types\n",
      "I1029 23:44:00.138061  4732 word2vec.py:1572] PROGRESS: at sentence #40000, processed 4046062 words, keeping 135322 word types\n",
      "I1029 23:44:00.424062  4732 word2vec.py:1572] PROGRESS: at sentence #50000, processed 5054530 words, keeping 152216 word types\n",
      "I1029 23:44:00.697063  4732 word2vec.py:1572] PROGRESS: at sentence #60000, processed 6062940 words, keeping 167689 word types\n",
      "I1029 23:44:00.980059  4732 word2vec.py:1572] PROGRESS: at sentence #70000, processed 7072938 words, keeping 181741 word types\n",
      "I1029 23:44:01.250059  4732 word2vec.py:1572] PROGRESS: at sentence #80000, processed 8078823 words, keeping 194323 word types\n",
      "I1029 23:44:01.528058  4732 word2vec.py:1572] PROGRESS: at sentence #90000, processed 9084002 words, keeping 206733 word types\n",
      "I1029 23:44:01.802057  4732 word2vec.py:1572] PROGRESS: at sentence #100000, processed 10086774 words, keeping 218386 word types\n",
      "I1029 23:44:02.076057  4732 word2vec.py:1572] PROGRESS: at sentence #110000, processed 11091249 words, keeping 229633 word types\n",
      "I1029 23:44:02.350058  4732 word2vec.py:1572] PROGRESS: at sentence #120000, processed 12090823 words, keeping 239808 word types\n",
      "I1029 23:44:02.634057  4732 word2vec.py:1572] PROGRESS: at sentence #130000, processed 13107554 words, keeping 249966 word types\n",
      "I1029 23:44:02.773067  4732 word2vec.py:1595] collected 254899 word types from a corpus of 13608626 raw words and 135000 sentences\n",
      "I1029 23:44:02.774060  4732 word2vec.py:1646] Loading a fresh vocabulary\n",
      "I1029 23:44:03.058058  4732 word2vec.py:1670] effective_min_count=5 retains 68209 unique words (26% of original 254899, drops 186690)\n",
      "I1029 23:44:03.059057  4732 word2vec.py:1676] effective_min_count=5 leaves 13323530 word corpus (97% of original 13608626, drops 285096)\n",
      "I1029 23:44:03.471061  4732 word2vec.py:1735] deleting the raw counts dictionary of 254899 items\n",
      "I1029 23:44:03.479063  4732 word2vec.py:1738] sample=0.001 downsamples 29 most-common words\n",
      "I1029 23:44:03.481059  4732 word2vec.py:1741] downsampling leaves estimated 12336090 word corpus (92.6% of prior 13323530)\n",
      "I1029 23:44:03.829062  4732 base_any2vec.py:1022] estimated required memory for 68209 words and 300 dimensions: 197806100 bytes\n",
      "I1029 23:44:03.830061  4732 word2vec.py:1887] resetting layer weights\n",
      "I1029 23:44:23.844063  4732 base_any2vec.py:1210] training model with 3 workers on 68209 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "I1029 23:44:24.894057  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 4.27% examples, 508717 words/s, in_qsize 6, out_qsize 2\n",
      "I1029 23:44:25.897060  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 8.76% examples, 532114 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:26.943061  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 13.07% examples, 523833 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:27.950065  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 17.28% examples, 522411 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:28.996061  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 21.53% examples, 517828 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:44:30.036058  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 25.87% examples, 518160 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:44:31.045058  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 30.12% examples, 518123 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:44:32.050059  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 34.35% examples, 518409 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:44:33.068065  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 38.83% examples, 520773 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:34.082062  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 42.89% examples, 518346 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:44:35.142057  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 47.32% examples, 518326 words/s, in_qsize 6, out_qsize 2\n",
      "I1029 23:44:36.160064  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 51.85% examples, 520872 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:37.163059  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 56.16% examples, 521541 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:44:38.197066  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 60.64% examples, 522271 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:44:39.200061  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 64.89% examples, 522181 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:40.200060  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 69.20% examples, 522728 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:44:41.211057  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 73.45% examples, 522355 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:44:42.224056  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 77.74% examples, 522000 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:44:43.239062  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 82.21% examples, 523029 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:44:44.288058  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 86.67% examples, 522609 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:44:45.299058  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 90.94% examples, 522769 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:44:46.303060  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 95.26% examples, 523486 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:47.331058  4732 base_any2vec.py:1305] EPOCH 1 - PROGRESS: at 99.65% examples, 523598 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:44:47.370061  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I1029 23:44:47.372058  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I1029 23:44:47.384059  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I1029 23:44:47.385059  4732 base_any2vec.py:1346] EPOCH - 1 : training on 13608626 raw words (12335822 effective words) took 23.5s, 524164 effective words/s\n",
      "I1029 23:44:48.402057  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 4.28% examples, 525667 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:49.420058  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 8.54% examples, 523814 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:50.448059  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 13.08% examples, 530037 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:44:51.460061  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 17.50% examples, 533194 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:52.464059  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 21.98% examples, 536027 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:53.476059  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 26.01% examples, 529863 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:44:54.494057  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 30.04% examples, 523683 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:44:55.534058  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 34.27% examples, 520968 words/s, in_qsize 6, out_qsize 2\n",
      "I1029 23:44:56.555058  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 38.62% examples, 520952 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:57.557061  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 42.97% examples, 522687 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:44:58.557057  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 47.17% examples, 522635 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:44:59.590065  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 51.48% examples, 521982 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:00.611057  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 55.72% examples, 521185 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:01.613059  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 60.05% examples, 521864 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:02.646058  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 64.60% examples, 523140 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:03.663058  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 68.69% examples, 521457 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:45:04.690059  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 73.01% examples, 521184 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:05.737056  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 77.50% examples, 521401 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:45:06.742060  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 81.76% examples, 521314 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:45:07.771058  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 86.07% examples, 520627 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:08.781060  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 90.43% examples, 521285 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:09.789061  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 94.89% examples, 522766 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:10.814060  4732 base_any2vec.py:1305] EPOCH 2 - PROGRESS: at 99.21% examples, 522593 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:10.945059  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I1029 23:45:10.967060  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I1029 23:45:10.981059  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I1029 23:45:10.983056  4732 base_any2vec.py:1346] EPOCH - 2 : training on 13608626 raw words (12335985 effective words) took 23.6s, 522931 effective words/s\n",
      "I1029 23:45:11.992058  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 4.14% examples, 512109 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:13.005057  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 8.26% examples, 509678 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:14.030060  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 12.56% examples, 512357 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:45:15.042062  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 16.83% examples, 515554 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:16.068057  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 21.09% examples, 514465 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:45:17.084058  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 25.37% examples, 515845 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:18.092059  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 29.83% examples, 520121 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:19.094059  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 33.82% examples, 516995 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:20.103059  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 38.16% examples, 518093 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:21.111059  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 42.61% examples, 520684 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:22.115057  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 46.95% examples, 522253 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:23.125057  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 51.05% examples, 520371 words/s, in_qsize 6, out_qsize 2\n",
      "I1029 23:45:24.127058  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 55.06% examples, 518356 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:45:25.141058  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 59.31% examples, 518178 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:26.197058  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 63.66% examples, 517105 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:45:27.235057  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 67.88% examples, 516219 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:28.237059  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 72.15% examples, 516499 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:29.267059  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 76.26% examples, 515017 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:30.268059  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 80.67% examples, 516285 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:31.272057  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 84.96% examples, 516506 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:32.275058  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 89.18% examples, 516716 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:33.275058  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 93.22% examples, 516151 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:34.319056  4732 base_any2vec.py:1305] EPOCH 3 - PROGRESS: at 97.53% examples, 515852 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:45:34.854058  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I1029 23:45:34.855057  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I1029 23:45:34.877061  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I1029 23:45:34.878060  4732 base_any2vec.py:1346] EPOCH - 3 : training on 13608626 raw words (12336728 effective words) took 23.9s, 516462 effective words/s\n",
      "I1029 23:45:35.892058  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 4.28% examples, 527917 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:36.893060  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 8.69% examples, 538288 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:37.906059  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 12.93% examples, 530516 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:45:38.910061  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 17.27% examples, 532428 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:39.947057  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 21.46% examples, 524867 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:45:40.954059  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 25.73% examples, 525373 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:45:41.961060  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 29.68% examples, 519440 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:42.987059  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 33.67% examples, 514810 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:44.007057  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 37.50% examples, 508589 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:45.057058  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 41.51% examples, 504789 words/s, in_qsize 5, out_qsize 2\n",
      "I1029 23:45:46.088060  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 45.79% examples, 505657 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:47.119059  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 49.87% examples, 504324 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:48.176059  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 53.91% examples, 501435 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:45:49.199059  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 57.84% examples, 499635 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:50.218059  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 62.19% examples, 501060 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:51.241058  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 66.34% examples, 501121 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:52.259057  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 70.70% examples, 502359 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:53.265056  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 74.87% examples, 502765 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:45:54.279056  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 78.90% examples, 502037 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:55.289061  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 83.25% examples, 503219 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:56.295058  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 87.55% examples, 503993 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:45:57.320058  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 91.72% examples, 504225 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:45:58.336062  4732 base_any2vec.py:1305] EPOCH 4 - PROGRESS: at 95.83% examples, 504289 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:45:59.306058  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I1029 23:45:59.309061  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I1029 23:45:59.311060  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I1029 23:45:59.312061  4732 base_any2vec.py:1346] EPOCH - 4 : training on 13608626 raw words (12336134 effective words) took 24.4s, 505040 effective words/s\n",
      "I1029 23:46:00.332056  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 4.20% examples, 515135 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:01.355061  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 8.69% examples, 530622 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:02.361065  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 13.01% examples, 529376 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:46:03.373059  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 17.27% examples, 528322 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:04.381058  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 21.31% examples, 521126 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:46:05.387058  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 25.87% examples, 528310 words/s, in_qsize 6, out_qsize 1\n",
      "I1029 23:46:06.397060  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 30.42% examples, 531826 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:07.411066  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 35.02% examples, 535340 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:08.434059  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 39.28% examples, 532593 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:46:09.435057  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 43.40% examples, 530543 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:46:10.464058  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 47.83% examples, 530841 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:46:11.489063  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 52.14% examples, 529798 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:46:12.510057  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 56.46% examples, 529102 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:46:13.521061  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 60.65% examples, 527584 words/s, in_qsize 6, out_qsize 2\n",
      "I1029 23:46:14.539058  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 65.11% examples, 528392 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:46:15.570057  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 69.42% examples, 527588 words/s, in_qsize 4, out_qsize 1\n",
      "I1029 23:46:16.570058  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 73.74% examples, 527745 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:17.574060  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 78.10% examples, 527875 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:18.592064  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 82.28% examples, 526620 words/s, in_qsize 6, out_qsize 2\n",
      "I1029 23:46:19.593058  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 86.81% examples, 527717 words/s, in_qsize 6, out_qsize 0\n",
      "I1029 23:46:20.636058  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 91.22% examples, 527675 words/s, in_qsize 3, out_qsize 2\n",
      "I1029 23:46:21.650057  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 95.62% examples, 528350 words/s, in_qsize 5, out_qsize 0\n",
      "I1029 23:46:22.643058  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I1029 23:46:22.667061  4732 base_any2vec.py:1305] EPOCH 5 - PROGRESS: at 99.93% examples, 527956 words/s, in_qsize 1, out_qsize 1\n",
      "I1029 23:46:22.668058  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I1029 23:46:22.681058  4732 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I1029 23:46:22.683059  4732 base_any2vec.py:1346] EPOCH - 5 : training on 13608626 raw words (12335496 effective words) took 23.4s, 527978 effective words/s\n",
      "I1029 23:46:22.684063  4732 base_any2vec.py:1382] training on a 68043130 raw words (61680165 effective words) took 118.8s, 519020 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%time model = models.Word2Vec(full_content.clean_content, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 23:47:41.675059  4732 utils.py:542] saving Word2Vec object under data/full_content_wv.model, separately None\n",
      "I1029 23:47:41.677059  4732 utils.py:616] storing np array 'vectors' to data/full_content_wv.model.wv.vectors.npy\n",
      "I1029 23:47:42.356058  4732 utils.py:648] not storing attribute vectors_norm\n",
      "I1029 23:47:42.358058  4732 utils.py:616] storing np array 'syn1neg' to data/full_content_wv.model.trainables.syn1neg.npy\n",
      "I1029 23:47:42.863063  4732 utils.py:648] not storing attribute cum_table\n",
      "I1029 23:47:43.109059  4732 utils.py:556] saved data/full_content_wv.model\n"
     ]
    }
   ],
   "source": [
    "model.save('data/full_content_wv.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68209, 300)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=len(model.wv.vocab), oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(full_content.clean_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequences = tokenizer.texts_to_sequences(full_content.clean_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = sequence.pad_sequences(full_sequences, maxlen=500,\n",
    "                                         padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = build_matrix(word_index, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252717, 300)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105000, 500), (15000, 500), (15000, 500), (105000, 20), (15000, 20))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = padded_sequences[:train_size,:]\n",
    "train_label = train_df.drop(['id', 'content'], axis=1).values\n",
    "\n",
    "validation_data = padded_sequences[train_size:train_size+validation_size,:]\n",
    "validation_label = validation_df.drop(['id', 'content'], axis=1).values\n",
    "\n",
    "test_data = padded_sequences[-test_size:, :]\n",
    "\n",
    "train_data.shape, validation_data.shape, test_data.shape, train_label.shape, validation_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(.1,\n",
    "                                                         decay_steps=10000,\n",
    "                                                         decay_rate=.96,\n",
    "                                                         staircase=True)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('temp/csv_logger')\n",
    "stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                                     mode='max',\n",
    "                                                     patience=2)\n",
    "checkpoint_dir = 'temp/training_checkpoints/'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                     monitor='val_acc',\n",
    "                                                     verbose=1,\n",
    "                                                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Embedding(*embedding_matrix.shape, weights=[embedding_matrix], \n",
    "                  trainable=False, input_length=500),\n",
    "        SpatialDropout1D(.2),\n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(4*128, activation='relu'),\n",
    "        Dense(4*64, activation='relu'),\n",
    "        Dense(20, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optiizer=tf.keras.optimizers.SGD(lr_schedule), \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 500, 300)          75815100  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_10 (Spatia (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 500, 256)          439296    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 76,522,448\n",
      "Trainable params: 707,348\n",
      "Non-trainable params: 75,815,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cl_model = build_model()\n",
    "cl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cl_model.fit(train_data, train_label, batch_size=128, \n",
    "            epochs=20, validation_data=(validation_data, validation_label),\n",
    "            callbacks=[csv_logger, stop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
